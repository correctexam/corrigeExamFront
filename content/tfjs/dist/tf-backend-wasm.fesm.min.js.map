{"version":3,"file":"tf-backend-wasm.fesm.min.js","sources":["../../../../tfjs-backend-wasm/src/kernels/types.ts","../../../../tfjs-backend-wasm/src/kernels/_FusedMatMul.ts","../../../../tfjs-backend-wasm/src/kernels/unary_kernel.ts","../../../../tfjs-backend-wasm/src/kernels/Abs.ts","../../../../tfjs-backend-wasm/src/kernels/Acos.ts","../../../../tfjs-backend-wasm/src/kernels/Acosh.ts","../../../../tfjs-backend-wasm/src/kernels/binary_kernel.ts","../../../../tfjs-backend-wasm/src/kernels/Add.ts","../../../../tfjs-backend-wasm/src/kernels/AddN.ts","../../../../tfjs-backend-wasm/src/kernels/Identity.ts","../../../../tfjs-backend-wasm/src/kernels/Transpose.ts","../../../../tfjs-backend-wasm/src/kernels/kernel_utils.ts","../../../../tfjs-backend-wasm/src/kernels/All.ts","../../../../tfjs-backend-wasm/src/kernels/Any.ts","../../../../tfjs-backend-wasm/src/kernels/argminmax_kernel.ts","../../../../tfjs-backend-wasm/src/kernels/ArgMax.ts","../../../../tfjs-backend-wasm/src/kernels/ArgMin.ts","../../../../tfjs-backend-wasm/src/kernels/Asin.ts","../../../../tfjs-backend-wasm/src/kernels/Asinh.ts","../../../../tfjs-backend-wasm/src/kernels/Atan.ts","../../../../tfjs-backend-wasm/src/kernels/Atan2.ts","../../../../tfjs-backend-wasm/src/kernels/Atanh.ts","../../../../tfjs-backend-wasm/src/kernels/AvgPool.ts","../../../../tfjs-backend-wasm/src/kernels/AvgPool3D.ts","../../../../tfjs-backend-wasm/src/kernels/AvgPool3DGrad.ts","../../../../tfjs-backend-wasm/src/kernels/AvgPoolGrad.ts","../../../../tfjs-backend-wasm/src/kernels/Reshape.ts","../../../../tfjs-backend-wasm/src/kernels/BatchMatMul.ts","../../../../../tfjs-backend-cpu/src/kernels/Slice.ts","../../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringNGrams_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringSplit_impl.ts","../../../../tfjs-backend-wasm/src/kernels/Slice.ts","../../../../tfjs-backend-wasm/src/kernels/BatchToSpaceND.ts","../../../../tfjs-backend-wasm/src/kernels/Bincount.ts","../../../../tfjs-backend-wasm/src/kernels/BitwiseAnd.ts","../../../../tfjs-backend-wasm/src/kernels/BroadcastArgs.ts","../../../../tfjs-backend-wasm/src/kernels/Cast.ts","../../../../tfjs-backend-wasm/src/kernels/Ceil.ts","../../../../tfjs-backend-wasm/src/kernels/ClipByValue.ts","../../../../tfjs-backend-wasm/src/kernels/Concat.ts","../../../../../tfjs-backend-cpu/src/kernels/Concat_impl.ts","../../../../tfjs-backend-wasm/src/kernels/Conv2D.ts","../../../../tfjs-backend-wasm/src/kernels/Conv2DBackpropInput.ts","../../../../tfjs-backend-wasm/src/kernels/Conv3D.ts","../../../../tfjs-backend-wasm/src/kernels/Conv3DBackpropFilterV2.ts","../../../../tfjs-backend-wasm/src/kernels/Conv3DBackpropInputV2.ts","../../../../tfjs-backend-wasm/src/kernels/Cos.ts","../../../../tfjs-backend-wasm/src/kernels/Cosh.ts","../../../../tfjs-backend-wasm/src/kernels/CropAndResize.ts","../../../../tfjs-backend-wasm/src/kernels/Cumprod.ts","../../../../tfjs-backend-wasm/src/kernels/Cumsum.ts","../../../../tfjs-backend-wasm/src/kernels/DenseBincount.ts","../../../../tfjs-backend-wasm/src/kernels/DepthToSpace.ts","../../../../tfjs-backend-wasm/src/kernels/DepthwiseConv2dNative.ts","../../../../tfjs-backend-wasm/src/kernels/Diag.ts","../../../../tfjs-backend-wasm/src/kernels/Dilation2D.ts","../../../../tfjs-backend-wasm/src/kernels/Dilation2DBackpropFilter.ts","../../../../tfjs-backend-wasm/src/kernels/Dilation2DBackpropInput.ts","../../../../tfjs-backend-wasm/src/kernels/Elu.ts","../../../../tfjs-backend-wasm/src/kernels/EluGrad.ts","../../../../tfjs-backend-wasm/src/kernels/Equal.ts","../../../../tfjs-backend-wasm/src/kernels/Erf.ts","../../../../tfjs-backend-wasm/src/kernels/Exp.ts","../../../../tfjs-backend-wasm/src/kernels/ExpandDims.ts","../../../../tfjs-backend-wasm/src/kernels/Expm1.ts","../../../../tfjs-backend-wasm/src/kernels/Fill.ts","../../../../tfjs-backend-wasm/src/kernels/FlipLeftRight.ts","../../../../tfjs-backend-wasm/src/kernels/Floor.ts","../../../../tfjs-backend-wasm/src/kernels/FloorDiv.ts","../../../../tfjs-backend-wasm/src/kernels/FusedBatchNorm.ts","../../../../tfjs-backend-wasm/src/kernels/FusedConv2D.ts","../../../../tfjs-backend-wasm/src/kernels/FusedDepthwiseConv2D.ts","../../../../tfjs-backend-wasm/src/kernels/GatherNd.ts","../../../../tfjs-backend-wasm/src/kernels/GatherV2.ts","../../../../tfjs-backend-wasm/src/kernels/Greater.ts","../../../../tfjs-backend-wasm/src/kernels/GreaterEqual.ts","../../../../tfjs-backend-wasm/src/kernels/IsFinite.ts","../../../../tfjs-backend-wasm/src/kernels/IsInf.ts","../../../../tfjs-backend-wasm/src/kernels/IsNan.ts","../../../../tfjs-backend-wasm/src/kernels/LeakyRelu.ts","../../../../tfjs-backend-wasm/src/kernels/Less.ts","../../../../tfjs-backend-wasm/src/kernels/LessEqual.ts","../../../../tfjs-backend-wasm/src/kernels/LinSpace.ts","../../../../tfjs-backend-wasm/src/kernels/Log.ts","../../../../tfjs-backend-wasm/src/kernels/Log1p.ts","../../../../tfjs-backend-wasm/src/kernels/LogicalAnd.ts","../../../../tfjs-backend-wasm/src/kernels/LogicalNot.ts","../../../../tfjs-backend-wasm/src/kernels/LogicalOr.ts","../../../../tfjs-backend-wasm/src/kernels/LogicalXor.ts","../../../../tfjs-backend-wasm/src/kernels/LRN.ts","../../../../tfjs-backend-wasm/src/kernels/LRNGrad.ts","../../../../tfjs-backend-wasm/src/kernels/Max.ts","../../../../tfjs-backend-wasm/src/kernels/Maximum.ts","../../../../tfjs-backend-wasm/src/kernels/MaxPool.ts","../../../../tfjs-backend-wasm/src/kernels/MaxPool3D.ts","../../../../tfjs-backend-wasm/src/kernels/MaxPool3DGrad.ts","../../../../tfjs-backend-wasm/src/kernels/MaxPoolGrad.ts","../../../../tfjs-backend-wasm/src/kernels/MaxPoolWithArgmax.ts","../../../../tfjs-backend-wasm/src/kernels/Mean.ts","../../../../tfjs-backend-wasm/src/kernels/Min.ts","../../../../tfjs-backend-wasm/src/kernels/Minimum.ts","../../../../tfjs-backend-wasm/src/kernels/MirrorPad.ts","../../../../tfjs-backend-wasm/src/kernels/Softmax.ts","../../../../tfjs-backend-wasm/src/kernels/Multinomial.ts","../../../../tfjs-backend-wasm/src/kernels/Mod.ts","../../../../tfjs-backend-wasm/src/kernels/Multiply.ts","../../../../tfjs-backend-wasm/src/kernels/Neg.ts","../../../../tfjs-backend-wasm/src/kernels/NonMaxSuppression_util.ts","../../../../tfjs-backend-wasm/src/kernels/NonMaxSuppressionV3.ts","../../../../tfjs-backend-wasm/src/kernels/NonMaxSuppressionV4.ts","../../../../tfjs-backend-wasm/src/kernels/NonMaxSuppressionV5.ts","../../../../tfjs-backend-wasm/src/kernels/NotEqual.ts","../../../../tfjs-backend-wasm/src/kernels/OneHot.ts","../../../../tfjs-backend-wasm/src/kernels/OnesLike.ts","../../../../tfjs-backend-wasm/src/kernels/Pack.ts","../../../../tfjs-backend-wasm/src/kernels/PadV2.ts","../../../../tfjs-backend-wasm/src/kernels/Pow.ts","../../../../tfjs-backend-wasm/src/kernels/Prelu.ts","../../../../tfjs-backend-wasm/src/kernels/Prod.ts","../../../../tfjs-backend-wasm/src/kernels/Range.ts","../../../../../tfjs-backend-cpu/src/kernels/Range_impl.ts","../../../../tfjs-backend-wasm/src/kernels/RealDiv.ts","../../../../tfjs-backend-wasm/src/kernels/Reciprocal.ts","../../../../tfjs-backend-wasm/src/kernels/Relu.ts","../../../../tfjs-backend-wasm/src/kernels/Relu6.ts","../../../../tfjs-backend-wasm/src/kernels/ResizeBilinear.ts","../../../../tfjs-backend-wasm/src/kernels/ResizeBilinearGrad.ts","../../../../tfjs-backend-wasm/src/kernels/ResizeNearestNeighbor.ts","../../../../tfjs-backend-wasm/src/kernels/ResizeNearestNeighborGrad.ts","../../../../tfjs-backend-wasm/src/kernels/Reverse.ts","../../../../tfjs-backend-wasm/src/kernels/RotateWithOffset.ts","../../../../tfjs-backend-wasm/src/kernels/Round.ts","../../../../tfjs-backend-wasm/src/kernels/Rsqrt.ts","../../../../tfjs-backend-wasm/src/kernels/ScatterNd.ts","../../../../tfjs-backend-wasm/src/kernels/SearchSorted.ts","../../../../tfjs-backend-wasm/src/kernels/Select.ts","../../../../tfjs-backend-wasm/src/kernels/Selu.ts","../../../../tfjs-backend-wasm/src/kernels/Sigmoid.ts","../../../../tfjs-backend-wasm/src/kernels/Sign.ts","../../../../tfjs-backend-wasm/src/kernels/Sin.ts","../../../../tfjs-backend-wasm/src/kernels/Sinh.ts","../../../../tfjs-backend-wasm/src/kernels/Softplus.ts","../../../../tfjs-backend-wasm/src/kernels/SpaceToBatchND.ts","../../../../tfjs-backend-wasm/src/kernels/SparseFillEmptyRows.ts","../../../../tfjs-backend-wasm/src/kernels/SparseReshape.ts","../../../../tfjs-backend-wasm/src/kernels/SparseSegmentReduction.ts","../../../../tfjs-backend-wasm/src/kernels/SparseSegmentMean.ts","../../../../tfjs-backend-wasm/src/kernels/SparseSegmentSum.ts","../../../../tfjs-backend-wasm/src/kernels/SparseToDense.ts","../../../../tfjs-backend-wasm/src/kernels/SplitV.ts","../../../../tfjs-backend-wasm/src/kernels/Sqrt.ts","../../../../tfjs-backend-wasm/src/kernels/Square.ts","../../../../tfjs-backend-wasm/src/kernels/SquaredDifference.ts","../../../../tfjs-backend-wasm/src/kernels/Step.ts","../../../../tfjs-backend-wasm/src/kernels/StridedSlice.ts","../../../../tfjs-backend-wasm/src/kernels/StringNGrams.ts","../../../../tfjs-backend-wasm/src/kernels/StringSplit.ts","../../../../tfjs-backend-wasm/src/kernels/StringToHashBucketFast.ts","../../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast_impl.ts","../../../../tfjs-backend-wasm/src/kernels/Sub.ts","../../../../tfjs-backend-wasm/src/kernels/Sum.ts","../../../../tfjs-backend-wasm/src/kernels/Tan.ts","../../../../tfjs-backend-wasm/src/kernels/Tanh.ts","../../../../tfjs-backend-wasm/src/kernels/TensorScatterUpdate.ts","../../../../tfjs-backend-wasm/src/kernels/Tile.ts","../../../../tfjs-backend-wasm/src/kernels/TopK.ts","../../../../tfjs-backend-wasm/src/kernels/Transform.ts","../../../../tfjs-backend-wasm/src/kernels/ZerosLike.ts","../../../../tfjs-backend-wasm/src/register_all_kernels.ts","../../../../tfjs-backend-wasm/src/kernels/Unique.ts","../../../../../tfjs-backend-cpu/src/kernels/Unique_impl.ts","../../../../tfjs-backend-wasm/src/kernels/Unpack.ts","../../../../tfjs-backend-wasm/src/flags_wasm.ts","wasm-out/tfjs-backend-wasm-threaded-simd.js","wasm-out/tfjs-backend-wasm-threaded-simd.worker.js","wasm-out/tfjs-backend-wasm.js","../../../../tfjs-backend-wasm/src/backend_wasm.ts","../../../../tfjs-backend-wasm/src/version.ts","../../../../tfjs-backend-wasm/src/base.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// This enum must align with the enum defined in cc/backend.h.\nexport enum CppDType {\n  float32 = 0,\n  int32 = 1,\n  bool = 2,\n  string = 3,\n  complex64 = 4\n}\n\n// Must match enum in cc/fusable_activations.h.\nexport enum FusableActivation {\n  linear = 0,\n  relu = 1,\n  relu6 = 2,\n  prelu = 3,\n  leakyrelu = 4,\n  sigmoid = 5,\n  elu = 6\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, broadcast_util, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {FusableActivation} from './types';\n\nlet wasmFusedMatMul:\n    (aId: number, aShape: Uint8Array, aShapeSize: number, bId: number,\n     bShape: Uint8Array, bShapeSize: number, transposeA: boolean,\n     transposeB: boolean, activation: number, biasId: number,\n     preluActivationWeightsId: number, leakyreluAlpha: number, outId: number) =>\n        void;\n\nfunction setup(backend: BackendWasm) {\n  wasmFusedMatMul = backend.wasm.cwrap(_FusedMatMul, null /* void */, [\n    'number',  // a_id\n    'array',   // a_shape\n    'number',  // a_shape.length\n    'number',  // b_id\n    'array',   // b_shape\n    'number',  // b_shape.length\n    'number',  // transpose_a\n    'number',  // transpose_b\n    'number',  // activation\n    'number',  // biasId\n    'number',  // preluActivationWeightsId\n    'number',  // leakyreluAlpha\n    'number'   // out_id\n  ]);\n}\n\nfunction fusedBatchMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  backend: BackendWasm,\n  attrs: _FusedMatMulAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(\n        `_FusedMatMul for non non-float32 tensors not yet supported.`);\n  }\n\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n  const aId = backend.dataIdMap.get(a.dataId).id;\n  const bId = backend.dataIdMap.get(b.dataId).id;\n\n  let biasId = 0;\n  if (bias != null) {\n    const biasData = backend.dataIdMap.get(bias.dataId);\n    if (biasData.shape.length !== 1) {\n      throw new Error(\n          `_FusedMatMul only supports rank-1 bias but got ` +\n          `rank ${biasData.shape.length}.`);\n    }\n    biasId = biasData.id;\n  }\n  const preluActivationWeightsId = preluActivationWeights == null ?\n      0 :\n      backend.dataIdMap.get(preluActivationWeights.dataId).id;\n  const fusedActivation =\n      FusableActivation[activation as unknown as\n                        keyof typeof FusableActivation];\n  if (fusedActivation == null) {\n    throw new Error(\n        `${activation} activation not yet supported for FusedConv2D ` +\n        `in the wasm backend.`);\n  }\n\n  const leftDim = transposeA ? a.shape[2] : a.shape[1];\n  const rightDim = transposeB ? b.shape[1] : b.shape[2];\n  const batchDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n\n  const out = backend.makeOutput([...batchDims, leftDim, rightDim], a.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);\n\n  wasmFusedMatMul(\n      aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length,\n      transposeA, transposeB, fusedActivation, biasId, preluActivationWeightsId,\n      leakyreluAlpha || 0, outId);\n\n  return out;\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: fusedBatchMatMul as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, TensorInfo, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nexport function createUnaryKernelConfig(\n    kernelName: string, outType?: DataType): KernelConfig {\n  let wasmFunc: (xId: number, dtype: number, outId: number) => void;\n\n  function setupFunc(backend: BackendWasm): void {\n    wasmFunc = backend.wasm.cwrap(kernelName, null /* void */, [\n      'number',  // x_id\n      'number',  // dtype\n      'number',  // out_id\n    ]);\n  }\n\n  function kernelFunc(args: {backend: BackendWasm, inputs: UnaryInputs}):\n      TensorInfo {\n    const {backend, inputs: {x}} = args;\n    const xId = backend.dataIdMap.get(x.dataId).id;\n    const out = backend.makeOutput(x.shape, outType || x.dtype);\n    const outId = backend.dataIdMap.get(out.dataId).id;\n\n    // Short-circuit zero-sized tensors.\n    if (util.sizeFromShape(out.shape) === 0) {\n      return out;\n    }\n\n    wasmFunc(xId, CppDType[x.dtype], outId);\n    return out;\n  }\n\n  return {kernelName, backendName: 'wasm', setupFunc, kernelFunc};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Abs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const absConfig: KernelConfig = createUnaryKernelConfig(Abs);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const acosConfig: KernelConfig = createUnaryKernelConfig(Acos);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const acoshConfig: KernelConfig = createUnaryKernelConfig(Acosh);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelConfig, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nexport function createBinaryKernelConfig(\n    kernelName: string, supportsFullBroadcast: boolean,\n    dtype?: DataType): KernelConfig {\n  let wasmFunc:\n      (aId: number, aShape: Uint8Array, aShapeLen: number, bId: number,\n       bShape: Uint8Array, bShapeLen: number, dtype: number, outId: number) =>\n          void;\n\n  function setupFunc(backend: BackendWasm): void {\n    wasmFunc = backend.wasm.cwrap(kernelName, null /* void */, [\n      'number',  // a_id,\n      'array',   // a_shape\n      'number',  // a_shape.length\n      'number',  // b_id\n      'array',   // b_shape\n      'number',  // b_shape.length\n      'number',  // dtype\n      'number'   // out_id\n    ]);\n  }\n\n  function kernelFunc(args: {backend: BackendWasm, inputs: BinaryInputs}):\n      TensorInfo {\n    const {backend, inputs} = args;\n    const {a, b} = inputs;\n    const aId = backend.dataIdMap.get(a.dataId).id;\n    const bId = backend.dataIdMap.get(b.dataId).id;\n\n    const outputType = dtype != null ? dtype : a.dtype;\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const out = backend.makeOutput(newShape, outputType);\n\n    // Short-circuit zero-sized tensors.\n    if (util.sizeFromShape(newShape) === 0) {\n      return out;\n    }\n\n    const aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);\n    const bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    const kernelFunc = () => wasmFunc(\n        aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length,\n        CppDType[a.dtype], outId);\n\n    kernelFunc();\n    return out;\n  }\n\n  return {kernelName, backendName: 'wasm', setupFunc, kernelFunc};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = true;\n\nexport const addConfig: KernelConfig =\n    createBinaryKernelConfig(Add, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmFunc:\n    (inputIds: Uint8Array, inputIdsLen: number, dtype: number, outId: number) =>\n        void;\n\nfunction setupFunc(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(AddN, null /* void */, [\n    'array',   // input_ids\n    'number',  // input_ids.length\n    'number',  // dtype\n    'number',  // out_id\n  ]);\n}\n\nfunction addn(args: {inputs: TensorInfo[], backend: BackendWasm}) {\n  const {inputs, backend} = args;\n  const out = backend.makeOutput(inputs[0].shape, inputs[0].dtype);\n\n  // Short-circuit zero-sized tensors.\n  if (util.sizeFromShape(out.shape) === 0) {\n    return out;\n  }\n\n  const inputIds = inputs.map(x => backend.dataIdMap.get(x.dataId).id);\n  const inputIdsBytes = new Uint8Array(new Int32Array(inputIds).buffer);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmFunc(inputIdsBytes, inputIds.length, CppDType[out.dtype], outId);\n\n  return out;\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'wasm',\n  setupFunc,\n  kernelFunc: addn as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, tensor} from '@tensorflow/tfjs-core';\nimport {TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nexport function identity(args: {inputs: IdentityInputs, backend: BackendWasm}):\n    TensorInfo {\n  const {inputs: {x}, backend} = args;\n\n  if (x.dtype === 'string') {\n    return tensor(backend.readSync(x.dataId), x.shape, x.dtype);\n  }\n\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const inVals = backend.typedArrayFromHeap(x);\n  const outVals = backend.typedArrayFromHeap(out);\n  outVals.set(inVals);\n  return out;\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'wasm',\n  kernelFunc: identity as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {identity} from './Identity';\nimport {CppDType} from './types';\n\nlet wasmTranspose: (\n    xId: number, xShape: Uint8Array, xShapeLength: number, dtype: CppDType,\n    outId: number, perm: Uint8Array, permLength: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmTranspose = backend.wasm.cwrap(Transpose, null /* void */, [\n    'number',  // xId\n    'array',   // x.shape\n    'number',  // x.shape.length\n    'number',  // dtype\n    'number',  // outId\n    'array',   // perm\n    'number',  // perm.length\n  ]);\n}\n\nexport function transpose(\n    args:\n        {inputs: TransposeInputs, backend: BackendWasm, attrs: TransposeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  // Reduce any dimensions with size one. Lower-rank transpose kernel performs\n  // better due to simpler memory access pattern.\n  const [reducedShape, perm] = removeOneSizeDims(inputs.x.shape, attrs.perm);\n\n  let permIsNoOp = true;\n  for (let i = 0; i < perm.length; i++) {\n    if (perm[i] !== i) {\n      permIsNoOp = false;\n    }\n  }\n  const outShape = computeOutShape(inputs.x.shape, attrs.perm);\n  const x = {\n    dataId: inputs.x.dataId,\n    shape: reducedShape,\n    dtype: inputs.x.dtype\n  };\n\n  if (permIsNoOp) {\n    const cloned = identity({inputs, backend});\n    cloned.shape = outShape;\n    return cloned;\n  }\n\n  const out = backend.makeOutput(outShape, x.dtype);\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const permBytes = new Uint8Array(new Int32Array(perm).buffer);\n  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n\n  wasmTranspose(\n      xId, xShapeBytes, x.shape.length, CppDType[x.dtype], outId, permBytes,\n      perm.length);\n  return out;\n}\n\nfunction computeOutShape(inShape: number[], perm: number[]): number[] {\n  const outShape = new Array(inShape.length);\n  for (let i = 0; i < outShape.length; i++) {\n    outShape[i] = inShape[perm[i]];\n  }\n  return outShape;\n}\n\nfunction removeOneSizeDims(\n    shape: number[], perm: number[]): [number[], number[]] {\n  const newShape: number[] = [];\n  const newPerm: number[] = [];\n  for (let i = 0; i < shape.length; ++i) {\n    if (shape[i] !== 1) {\n      newShape.push(shape[i]);\n    }\n    if (shape[perm[i]] !== 1) {\n      newPerm.push(perm[i]);\n    }\n  }\n  for (let i = 0; i < newPerm.length; ++i) {\n    let minValIdx = -1;\n    for (let j = 0; j < newPerm.length; ++j) {\n      if (newPerm[j] >= i &&\n          (minValIdx === -1 || newPerm[minValIdx] > newPerm[j])) {\n        minValIdx = j;\n      }\n    }\n    newPerm[minValIdx] = i;\n  }\n  return [newShape, newPerm];\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'wasm',\n  kernelFunc: transpose as unknown as KernelFunc,\n  setupFunc: setup,\n};\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\nimport {BackendWasm} from '../backend_wasm';\nimport {transpose} from './Transpose';\n\n/**\n * Compute permutation axes and do a transpose if necessary.\n *\n * Used by reduction ops.\n * @param x input TensorInfo\n * @param axis reduction axes\n * @param backend wasm backend instance\n */\nexport function permuteAxesAndTranspose(\n    x: TensorInfo, axis: number|number[], backend: BackendWasm): {\n  transposed: TensorInfo|null,\n  axes: number[],\n  originalAxes: number[],\n  inputWasTransposed: boolean\n} {\n  const xShape = x.shape;\n  const xRank = x.shape.length;\n\n  const originalAxes = util.parseAxisParam(axis, xShape);\n  let axes = originalAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xTransposed = null;\n  let inputWasTransposed = false;\n  if (permutedAxes != null) {\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    xTransposed =\n        transpose({inputs: {x}, attrs: {perm: permutedAxes}, backend});\n\n    const xId = backend.dataIdMap.get(x.dataId).id;\n    const transposedId = backend.dataIdMap.get(xTransposed.dataId).id;\n    if (transposedId !== xId) {\n      inputWasTransposed = true;\n    }\n  }\n\n  return {transposed: xTransposed, originalAxes, axes, inputWasTransposed};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {All, AllAttrs, AllInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\n\nlet wasmAll: (xId: number, reduceSize: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmAll = backend.wasm.cwrap(All, null /*void*/, ['number, number, number']);\n}\n\nfunction all(args: {backend: BackendWasm, inputs: AllInputs, attrs: AllAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    input = transposed;\n    inputId = transposedId;\n  }\n\n  const inputRank = input.shape.length;\n  backend_util.assertAxesAreInnerMostDims('all', axes, inputRank);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, x.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmAll(inputId, reduceSize, outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const allConfig: KernelConfig = {\n  kernelName: All,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: all as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Any, AnyAttrs, AnyInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\n\nlet wasmAny: (xId: number, reduceSize: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmAny = backend.wasm.cwrap(Any, null /*void*/, ['number, number, number']);\n}\n\nfunction any(args: {backend: BackendWasm, inputs: AnyInputs, attrs: AnyAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    input = transposed;\n    inputId = transposedId;\n  }\n\n  const inputRank = input.shape.length;\n  backend_util.assertAxesAreInnerMostDims('any', axes, inputRank);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, x.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmAny(inputId, reduceSize, outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const anyConfig: KernelConfig = {\n  kernelName: Any,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: any as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ArgMaxAttrs, ArgMaxInputs, ArgMinAttrs, ArgMinInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\nimport {CppDType} from './types';\n\nexport function createArgMinMaxKernelConfig(kernelName: 'ArgMin'|\n                                            'ArgMax'): KernelConfig {\n  let wasmFunc: (\n      xId: number, dtype: number, outerSize: number, innerSize: number,\n      outId: number) => void;\n\n  function setupFunc(backend: BackendWasm) {\n    wasmFunc = backend.wasm.cwrap(kernelName, null /* void */, [\n      'number',  // x_id\n      'number',  // dtype\n      'number',  // outer_size\n      'number',  // inner_size\n      'number'   // out_id\n    ]);\n  }\n\n  function kernelFunc(args: {\n    backend: BackendWasm,\n    inputs: ArgMinInputs&ArgMaxInputs,\n    attrs: ArgMinAttrs&ArgMaxAttrs,\n  }): TensorInfo {\n    const {backend, inputs, attrs} = args;\n    const {axis} = attrs;\n    const {x} = inputs;\n    const xId = backend.dataIdMap.get(x.dataId).id;\n    let inputId = xId;\n    let input = x;\n\n    const {transposed, axes, inputWasTransposed} =\n        permuteAxesAndTranspose(x, axis, backend);\n\n    if (inputWasTransposed) {\n      const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n      if (transposedId !== xId) {\n        // transpose was not a no-op. We will need to dispose of this\n        // once we are done.\n        input = transposed;\n        inputId = transposedId;\n      }\n    }\n\n    const outShape = input.shape.slice(0, -1);\n    const out = backend.makeOutput(outShape, 'int32');\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    const outerSize = util.sizeFromShape(out.shape);\n    const innerSize = input.shape[axes[0]];\n    wasmFunc(inputId, CppDType[input.dtype], outerSize, innerSize, outId);\n\n    if (inputWasTransposed) {\n      // dispose of the transposed tensor.\n      backend.disposeData(transposed.dataId);\n    }\n\n    return out;\n  }\n\n  return {\n    kernelName,\n    backendName: 'wasm',\n    setupFunc,\n    kernelFunc: kernelFunc as unknown as KernelFunc,\n  };\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createArgMinMaxKernelConfig} from './argminmax_kernel';\n\nexport const argMaxConfig: KernelConfig = createArgMinMaxKernelConfig(ArgMax);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createArgMinMaxKernelConfig} from './argminmax_kernel';\n\nexport const argMinConfig: KernelConfig = createArgMinMaxKernelConfig(ArgMin);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const asinConfig: KernelConfig = createUnaryKernelConfig(Asin);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const asinhConfig: KernelConfig = createUnaryKernelConfig(Asinh);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const atanConfig: KernelConfig = createUnaryKernelConfig(Atan);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nexport const atan2Config: KernelConfig =\n    createBinaryKernelConfig(Atan2, /*supportsFullBroadcast=*/false);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const atanhConfig: KernelConfig = createUnaryKernelConfig(Atanh);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, Tensor4D} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmAvgPool: (\n    xId: number, batchSize: number, inputHeight: number, inputWidth: number,\n    filterHeight: number, filterWidth: number, padTop: number, padRight: number,\n    padBottom: number, padLeft: number, strideHeight: number,\n    strideWidth: number, channels: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmAvgPool = backend.wasm.cwrap(AvgPool, null /* void */, [\n    'number',  // xId\n    'number',  // batchSize\n    'number',  // inputHeight\n    'number',  // inputWidth\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // padTop\n    'number',  // padRight\n    'number',  // padBottom\n    'number',  // padLeft\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // channels\n    'number',  // outId\n  ]);\n}\n\nfunction avgPool(\n    args: {inputs: AvgPoolInputs, backend: BackendWasm, attrs: AvgPoolAttrs}) {\n  const {inputs, attrs, backend} = args;\n\n  const x = inputs.x as Tensor4D;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padRight = convInfo.padInfo.right;\n  const padBottom = convInfo.padInfo.bottom;\n  const padLeft = convInfo.padInfo.left;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const channels = convInfo.inChannels;\n\n  if (convInfo.dataFormat !== 'channelsLast') {\n    throw new Error(\n        `wasm backend does not support dataFormat:'` +\n        `${convInfo.dataFormat}'. Please use 'channelsLast'.`);\n  }\n\n  if (convInfo.dilationWidth !== 1 || convInfo.dilationHeight !== 1) {\n    throw new Error(\n        `was backend only supports average pooling with dilation = [1, 1], ` +\n        `got [${convInfo.dilationHeight}, ${convInfo.dilationWidth}].`);\n  }\n\n  const out = backend.makeOutput(convInfo.outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  wasmAvgPool(\n      xId, x.shape[0], x.shape[1], x.shape[2], filterHeight, filterWidth,\n      padTop, padRight, padBottom, padLeft, strideHeight, strideWidth, channels,\n      outId);\n  return out;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: avgPool as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmAvgPool3D: (\n    xId: number, outId: number, batchSize: number, channelSize: number,\n    inDepth: number, inHeight: number, inWidth: number, outDepth: number,\n    outHeight: number, outWidth: number, strideDepth: number,\n    strideHeight: number, strideWidth: number, dilationDepth: number,\n    dilationHeight: number, dilationWidth: number, effectiveFilterDepth: number,\n    effectiveFilterHeight: number, effectiveFilterWidth: number,\n    padFront: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmAvgPool3D = backend.wasm.cwrap('AvgPool3D', null, [\n    'number',  // xId\n    'number',  // outId\n    'number',  // batchSize\n    'number',  // channelSize\n    'number',  // inDepth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outDepth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideDepth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationDepth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // effectiveFilterDepth\n    'number',  // effectiveFilterHeight\n    'number',  // effectiveFilterWidth\n    'number',  // padFront\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function avgPool3D(args: {\n  inputs: AvgPool3DInputs,\n  attrs: AvgPool3DAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      /*dilations=*/1, pad, dimRoundingMode, dataFormat);\n  const out = backend.makeOutput(convInfo.outShape, x.dtype);\n\n  wasmAvgPool3D(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(out.dataId).id,\n      convInfo.batchSize,\n      // Since Pool3D ops (AvgPool3D and MaxPool3D) support 3D filter only, in\n      // channels should always equal to out channels.\n      /*channelSize=*/convInfo.inChannels,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterDepth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return out;\n}\n\nexport const avgPool3DConfig: KernelConfig = {\n  kernelName: AvgPool3D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: avgPool3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3DGrad, AvgPool3DGradAttrs, AvgPool3DGradInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmAvgPool3DGrad: (\n    dyId: number, dxId: number, batchSize: number, channelSize: number,\n    inDepth: number, inHeight: number, inWidth: number, outDepth: number,\n    outHeight: number, outWidth: number, strideDepth: number,\n    strideHeight: number, strideWidth: number, dilationDepth: number,\n    dilationHeight: number, dilationWidth: number, effectiveFilterDepth: number,\n    effectiveFilterHeight: number, effectiveFilterWidth: number,\n    padFront: number, padTop: number, padLeft: number, filterDepth: number,\n    filterHeight: number, filterWidth: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmAvgPool3DGrad = backend.wasm.cwrap('AvgPool3DGrad', null, [\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // batchSize\n    'number',  // channelSize\n    'number',  // inDepth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outDepth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideDepth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationDepth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // effectiveFilterDepth\n    'number',  // effectiveFilterHeight\n    'number',  // effectiveFilterWidth\n    'number',  // padFront\n    'number',  // padTop\n    'number',  // padLeft\n    'number',  // filterDepth\n    'number',  // filterHeight\n    'number',  // filterWidth\n  ]);\n}\n\nexport function avgPool3DGrad(args: {\n  inputs: AvgPool3DGradInputs,\n  attrs: AvgPool3DGradAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, /*dilations=*/1, pad, dimRoundingMode);\n  const dx = backend.makeOutput(input.shape, input.dtype);\n\n  wasmAvgPool3DGrad(\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      convInfo.batchSize,\n      // Since Pool3D ops (AvgPool3D and MaxPool3D) support 3D filter only, in\n      // channels should always equal to out channels.\n      /*channelSize=*/convInfo.inChannels,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterDepth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n      convInfo.filterDepth,\n      convInfo.filterHeight,\n      convInfo.filterWidth,\n  );\n  return dx;\n}\n\nexport const avgPool3DGradConfig: KernelConfig = {\n  kernelName: AvgPool3DGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: avgPool3DGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPoolGrad, AvgPoolGradAttrs, AvgPoolGradInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmAvgPoolGrad: (\n    dyId: number, dxId: number, batchSize: number, channelSize: number,\n    inHeight: number, inWidth: number, outHeight: number, outWidth: number,\n    strideHeight: number, strideWidth: number, dilationHeight: number,\n    dilationWidth: number, effectiveFilterHeight: number,\n    effectiveFilterWidth: number, padTop: number, padLeft: number,\n    filterHeight: number, filterWidth: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmAvgPoolGrad = backend.wasm.cwrap('AvgPoolGrad', null, [\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // batchSize\n    'number',  // channelSize\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // effectiveFilterHeight\n    'number',  // effectiveFilterWidth\n    'number',  // padTop\n    'number',  // padLeft\n    'number',  // filterHeight\n    'number',  // filterWidth\n  ]);\n}\n\nexport function avgPoolGrad(args: {\n  inputs: AvgPoolGradInputs,\n  attrs: AvgPoolGradAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      input.shape as [number, number, number, number], filterSize, strides,\n      /*dilations=*/1, pad);\n  const dx = backend.makeOutput(input.shape, input.dtype);\n\n  wasmAvgPoolGrad(\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      convInfo.batchSize,\n      // Since Pool ops (AvgPool and MaxPool) support 2D filter only, in\n      // channels should always equal to out channels.\n      /*channelSize=*/convInfo.inChannels,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n      convInfo.filterHeight,\n      convInfo.filterWidth,\n  );\n  return dx;\n}\n\nexport const avgPoolGradConfig: KernelConfig = {\n  kernelName: AvgPoolGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: avgPoolGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nexport function reshape(\n    args: {inputs: ReshapeInputs, attrs: ReshapeAttrs, backend: BackendWasm}) {\n  const {inputs, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n\n  util.assert(\n      xSize === util.sizeFromShape($shape),\n      () => `new shape: ${$shape}, old shape: ${x.shape}. New shape and old ` +\n          `shape must have the same number of elements.`);\n\n  // Backend needs to track refCount for the dataId for reshape op\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'wasm',\n  kernelFunc: reshape as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, broadcast_util, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {reshape} from './Reshape';\n\nlet wasmBatchMatMul: (\n    aId: number, aShape: Uint8Array, aShapeSize: number, bId: number,\n    bShape: Uint8Array, bShapeSize: number, transposeA: boolean,\n    transposeB: boolean, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmBatchMatMul = backend.wasm.cwrap(BatchMatMul, null /* void */, [\n    'number',  // a_id\n    'array',   // a_shape\n    'number',  // a_shape.length\n    'number',  // b_id\n    'array',   // b_shape\n    'number',  // b_shape.length\n    'number',  // transpose_a\n    'number',  // transpose_b\n    'number'   // out_id\n  ]);\n}\n\nfunction batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  backend: BackendWasm,\n  attrs: BatchMatMulAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(\n        `BatchMatMul for non non-float32 tensors not yet supported.`);\n  }\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const a3dId = backend.dataIdMap.get(a3d.dataId).id;\n  const b3dId = backend.dataIdMap.get(b3d.dataId).id;\n\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const out = backend.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);\n\n  wasmBatchMatMul(\n      a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes,\n      b3d.shape.length, transposeA, transposeB, outId);\n\n  backend.disposeData(a3d.dataId);\n  backend.disposeData(b3d.dataId);\n\n  out.shape = outShape;\n  return out;\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: batchMatMul as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, buffer, DataType, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: BackendValues, begin: number[], size: number[], shape: number[],\n    dtype: DataType): BackendValues {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n\n    if (dtype === 'string') {\n      return (vals as Uint8Array[]).slice(flatOffset, flatOffset + length);\n    }\n\n    return (vals as TypedArray).subarray(flatOffset, flatOffset + length);\n  }\n\n  const decodedData = dtype === 'string' ?\n      backend_util.fromUint8ToStringArray(vals as Uint8Array[]) :\n      vals as TypedArray;\n\n  const inBuf = buffer(shape, dtype, decodedData);\n  const outBuf = buffer(size, dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.map((idx: number, j) => idx + begin[j]);\n    outBuf.set(inBuf.get(...inLoc), ...outLoc);\n  }\n\n  if (dtype === 'string') {\n    return backend_util.fromStringArrayToUint8(outBuf.values as string[]);\n  }\n  return outBuf.values as TypedArray;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcastTo, DataType, reshape, tidy, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport RowPartitionType = backend_util.RowPartitionType;\n// Based on\n// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc\nclass RaggedTensorToTensorOp {\n  private readonly rowPartitionTypes: RowPartitionType[];\n  private readonly raggedRank: number;\n  constructor(\n      private shape: TypedArray, private shapeShape: number[],\n      private values: TypedArray, private valuesShape: number[],\n      private valuesDType: DataType, private defaultValue: TypedArray,\n      private defaultValueShape: number[],\n      private readonly rowPartitionValues: TypedArray[],\n      private readonly rowPartitionValuesShapes: number[][],\n      rowPartitionTypeStrings: string[]) {\n    this.rowPartitionTypes =\n        backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);\n    this.raggedRank = backend_util.getRaggedRank(this.rowPartitionTypes);\n  }\n\n  private getRowPartitionTypeByDimension(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionTypes[dimension + 1];\n    } else {\n      return this.rowPartitionTypes[dimension];\n    }\n  }\n\n  // Returns the relationship between dimension and dimension + 1.\n  private getRowPartitionTensor(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionValues[dimension + 1];\n    } else {\n      return this.rowPartitionValues[dimension];\n    }\n  }\n\n  private getMaxWidth(dimension: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);\n    switch (this.getRowPartitionTypeByDimension(dimension - 1)) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);\n      case RowPartitionType.ROW_SPLITS:\n        return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);\n      default:\n        throw new Error(`Cannot handle partition type ${\n            RowPartitionType[this.getRowPartitionTypeByDimension(\n                dimension - 1)]}`);\n    }\n  }\n\n  static getMaxWidthRowSplit(rowSplit: TypedArray) {\n    const tensorLength = rowSplit.length;\n    if (tensorLength === 0 || tensorLength === 1) {\n      return 0;\n    }\n    let maxWidth = 0;\n    for (let i = 0; i < tensorLength - 1; ++i) {\n      const currentWidth = rowSplit[i + 1] - rowSplit[i];\n      if (currentWidth > maxWidth) {\n        maxWidth = currentWidth;\n      }\n    }\n    return maxWidth;\n  }\n\n  static getMaxWidthValueRowID(valueRowIds: TypedArray) {\n    const indexLength = valueRowIds.length;\n    if (indexLength === 0) {\n      return 0;\n    }\n    let firstEqualIndex = 0;\n    let firstEqualIndexValue = valueRowIds[0];\n    let maxWidth = 0;\n    for (let i = 1; i < indexLength; ++i) {\n      const value = valueRowIds[i];\n      if (value !== firstEqualIndexValue) {\n        firstEqualIndexValue = value;\n        maxWidth = Math.max(i - firstEqualIndex, maxWidth);\n        firstEqualIndex = i;\n      }\n    }\n    return Math.max(indexLength - firstEqualIndex, maxWidth);\n  }\n\n  private tensorShapeFromTensor(\n      t: TypedArray, tShape: number[], isPartial = true) {\n    if (tShape.length === 0) {\n      if (t[0] === -1) {\n        return [];\n      }\n      throw new Error(\n          `The only valid scalar shape tensor is the fully unknown shape specified as -1.`);\n    }\n    // MakePartialShape/MakeShapeHelper.\n    return makeShape(t, isPartial);\n  }\n\n  private calculateOutputSize(firstDim: number) {\n    const valueShape = this.valuesShape;\n    const defaultValueShape = this.defaultValueShape;\n\n    backend_util.validateDefaultValueShape(defaultValueShape, valueShape);\n\n    const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);\n    const outputShape = backend_util.combineRaggedTensorToTensorShapes(\n        this.raggedRank, shape, valueShape);\n\n    const result = outputShape;\n\n    if (result[0] < 0) {\n      result[0] = firstDim;\n    }\n    for (let i = 1; i <= this.raggedRank; ++i) {\n      if (result[i] < 0) {\n        result[i] = this.getMaxWidth(i);\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * The outputIndex represents the index in the output tensor\n   * where the first element of a particular dimension would be written.\n   * If it is -1, it indicates that the index is out of scope.\n   * Example, given firstDimension = 10, firstDimensionOutput = 6,\n   * and outputIndexMultiplier = 100:\n   * result = [0 100 200 300 400 500 -1 -1 -1 -1]\n   * If firstDimensionOutput = 11 instead, then:\n   * result = [0 100 200 300 400 500 600 700 800 900]\n   */\n  private calculateFirstParentOutputIndex(\n      firstDimension: number, outputIndexMultiplier: number,\n      firstDimensionOutput: number) {\n    const minDimension = Math.min(firstDimension, firstDimensionOutput);\n    const result: number[] = [];\n    let currentOutputIndex = 0;\n    for (let i = 0; i < minDimension;\n         ++i, currentOutputIndex += outputIndexMultiplier) {\n      result.push(currentOutputIndex);\n    }\n    for (let i = minDimension; i < firstDimension; ++i) {\n      result.push(-1);\n    }\n    util.assert(\n        result.length === firstDimension,\n        () => 'Final length of result must be equal to firstDimension.');\n\n    return result;\n  }\n\n  private calculateOutputIndexRowSplit(\n      rowSplit: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowSplitSize = rowSplit.length;\n    const result: number[] = [];\n    for (let i = 0; i < rowSplitSize - 1; ++i) {\n      const rowLength = rowSplit[i + 1] - rowSplit[i];\n      let realLength = Math.min(outputSize, rowLength);\n      let parentOutputIndexCurrent = parentOutputIndex[i];\n\n      if (parentOutputIndexCurrent === -1) {\n        realLength = 0;\n      }\n      for (let j = 0; j < realLength; ++j) {\n        result.push(parentOutputIndexCurrent);\n        parentOutputIndexCurrent += outputIndexMultiplier;\n      }\n      for (let j = 0; j < rowLength - realLength; ++j) {\n        result.push(-1);\n      }\n    }\n    if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {\n      throw new Error('Invalid row split size.');\n    }\n\n    return result;\n  }\n\n  // Calculate the output index of the first element of a list.\n  // The parentOutputIndex is the same computation for the previous list.\n  // -1 indicates an element or list that is out of range.\n  // The outputIndexMultiplier is the number of output indices one moves\n  // forward for each column.\n  // E.g., given:\n  // valueRowIds:[0 1 2 2 2 3 5 5 6]\n  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]\n  // outputIndexMultiplier: 10\n  // outputSize: 2\n  // You get:\n  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]\n  // result[0] = parentOutputIndex[valueRowIds[0]]\n  // result[1] = parentOutputIndex[valueRowIds[1]]\n  // result[2] = parentOutputIndex[valueRowIds[2]]\n  // result[3] = parentOutputIndex[valueRowIds[2] + 10]\n  // result[4] = -1 because it is the third element the size is 2.\n  // result[5] = parentOutputIndex[valueRowIds[3]]\n  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[8] = parentOutputIndex[valueRowIds[7]]\n  private calculateOutputIndexValueRowID(\n      valueRowIds: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const indexSize = valueRowIds.length;\n    const result: number[] = [];\n    if (indexSize === 0) {\n      return [];\n    }\n\n    let currentOutputColumn = 0;\n    let currentValueRowId = valueRowIds[0];\n\n    if (currentValueRowId >= parentOutputIndex.length) {\n      throw new Error(\n          `Got currentValueRowId=${currentValueRowId}, which is not less than ${\n              parentOutputIndex.length}`);\n    }\n\n    let currentOutputIndex = parentOutputIndex[currentValueRowId];\n    result.push(currentOutputIndex);\n    for (let i = 1; i < indexSize; ++i) {\n      const nextValueRowId = valueRowIds[i];\n      if (nextValueRowId === currentValueRowId) {\n        if (currentOutputIndex >= 0) {\n          ++currentOutputColumn;\n          if (currentOutputColumn < outputSize) {\n            currentOutputIndex += outputIndexMultiplier;\n          } else {\n            currentOutputIndex = -1;\n          }\n        }\n      } else {\n        currentOutputColumn = 0;\n        currentValueRowId = nextValueRowId;\n\n        if (nextValueRowId >= parentOutputIndex.length) {\n          throw new Error(\n              `Got nextValueRowId=${nextValueRowId} which is not less than ${\n                  parentOutputIndex.length}`);\n        }\n\n        currentOutputIndex = parentOutputIndex[nextValueRowId];\n      }\n      result.push(currentOutputIndex);\n    }\n\n    if (result.length !== valueRowIds.length) {\n      throw new Error('Invalid row ids.');\n    }\n\n    return result;\n  }\n\n  private calculateOutputIndex(\n      dimension: number, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension);\n    const partitionType = this.getRowPartitionTypeByDimension(dimension);\n    switch (partitionType) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return this.calculateOutputIndexValueRowID(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      case RowPartitionType.ROW_SPLITS:\n        if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {\n          throw new Error(`Row partition size is greater than output size: ${\n              rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);\n        }\n        return this.calculateOutputIndexRowSplit(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      default:\n        throw new Error(\n            `Unsupported partition type: ${RowPartitionType[partitionType]}`);\n    }\n  }\n\n  private getFirstDimensionSize() {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (this.rowPartitionTypes.length === 0) {\n      throw new Error('No row_partition_types given.');\n    }\n    const firstPartitionType = this.rowPartitionTypes[0];\n    switch (firstPartitionType) {\n      case RowPartitionType.FIRST_DIM_SIZE:\n        return firstPartitionTensor[0];\n      case RowPartitionType.VALUE_ROWIDS:\n        throw new Error('Cannot handle VALUE_ROWIDS in first dimension.');\n      case RowPartitionType.ROW_SPLITS:\n        return this.rowPartitionValuesShapes[0][0] - 1;\n      default:\n        throw new Error(\n            `Cannot handle type ${RowPartitionType[firstPartitionType]}`);\n    }\n  }\n\n  compute(): [number[], TypedArray] {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (firstPartitionTensor.length <= 0) {\n      throw new Error(\n          'Invalid first partition input. ' +\n          'Tensor requires at least one element.');\n    }\n    const firstDimension = this.getFirstDimensionSize();\n    const outputSize = this.calculateOutputSize(firstDimension);\n    const multiplier: number[] = new Array(this.raggedRank + 1);\n\n    multiplier[multiplier.length - 1] = 1;\n    for (let i = multiplier.length - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * outputSize[i + 1];\n    }\n    // Full size of the tensor.\n    const outputShape: number[] = makeShape(outputSize, false);\n    const outputTensor =\n        util.getArrayFromDType(\n            this.valuesDType, util.sizeFromShape(outputShape)) as TypedArray;\n\n    const fullSize = multiplier[0] * outputSize[0];\n    if (fullSize > 0) {\n      let outputIndex = this.calculateFirstParentOutputIndex(\n          firstDimension, multiplier[0], outputSize[0]);\n      for (let i = 1; i <= this.raggedRank; ++i) {\n        const newOutputIndex = this.calculateOutputIndex(\n            i - 1, outputIndex, multiplier[i], outputSize[i]);\n        outputIndex = newOutputIndex;\n      }\n\n      this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);\n    }\n\n    return [outputShape, outputTensor];\n  }\n  setOutput(\n      raggedRank: number, outputIndex: number[], outputTensor: TypedArray,\n      outputShape: number[]) {\n    if (outputTensor.length === 0) {\n      return;\n    }\n\n    const valuesBase = this.values;\n    const outputBase = outputTensor;\n\n    let elementShape = outputShape.slice();\n    elementShape = elementShape.slice(raggedRank + 1);\n    const valueElementSize = util.sizeFromShape(elementShape);\n    const outputIndexSize = outputIndex.length;\n\n    // Broadcast the default value to value_element_size.  (We can skip this\n    // if defaultValueTensor.size == 1, since we use fill when that's true.)\n    let defaultValue = this.defaultValue;\n    if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {\n      const srcShape = this.defaultValueShape;\n      tidy(() => {\n        const defaultValueTensor = reshape(defaultValue, srcShape);\n        const bCastDefault = broadcastTo(defaultValueTensor, elementShape);\n        defaultValue = bCastDefault.dataSync();\n      });\n    }\n\n    // Loop through the outputIndex array, finding contiguous regions that\n    // should be copied.  Once we find the end of a contiguous region, copy it\n    // and add any necessary padding (with defaultValue).\n    let srcStart = 0;  // Start of contiguous region (in values)\n    let dstStart = 0;  // Destination for contiguous region (in output)\n    let dstEnd = 0;    // Destination for contiguous region (in output)\n    for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {\n      // dstI is the destination where the value at srcI should be copied.\n      let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;\n\n      // If we're still in a contiguous region, then update dstEnd go to the\n      // next srcI.\n      if (dstI === dstEnd) {\n        ++dstEnd;\n        continue;\n      }\n\n      // We found the end of contiguous region.  This can be because we found\n      // a gap (dstI > dstEnd), or a source value that shouldn't be copied\n      // because it's out-of-bounds (dstI == -1), or the end of the tensor\n      // (dstI === -1).\n      if (dstStart < dstEnd) {\n        // Copy the contiguous region.\n        const src = valuesBase.subarray(srcStart * valueElementSize);\n        const dst = outputBase.subarray(dstStart * valueElementSize);\n        const nVals = (dstEnd - dstStart) * valueElementSize;\n        copyArray(dst, src, nVals);\n      }\n\n      // Add any necessary padding (w/ defaultValue).\n      if (srcI >= outputIndexSize) {\n        // We reached the end of values: pad to the end of output.\n        const outputSize = outputTensor.length;\n        dstI = Math.floor(outputSize / valueElementSize);\n      }\n      if (dstI > dstEnd) {\n        if (this.defaultValue.length === 1) {\n          outputBase\n              .subarray(dstEnd * valueElementSize, dstI * valueElementSize)\n              .fill(this.defaultValue[0]);\n          dstEnd = dstI;\n        } else {\n          while (dstI > dstEnd) {\n            const dst = outputBase.slice(dstEnd * valueElementSize);\n            copyArray(dst, defaultValue, valueElementSize);\n            ++dstEnd;\n          }\n        }\n      }\n\n      // Update indices.\n      if (dstI < 0) {\n        // srcI should be skipped -- leave it out of the contiguous region.\n        srcStart = srcI + 1;\n        dstStart = dstEnd;\n      } else {\n        // srcI should be copied -- include it in the contiguous region.\n        srcStart = srcI;\n        dstStart = dstEnd;\n        dstEnd = dstStart + 1;\n      }\n    }\n  }\n}\n\nfunction copyArray(dst: TypedArray, src: TypedArray, size: number) {\n  for (let i = 0; i < size; i++) {\n    dst[i] = src[i];\n  }\n}\n\nfunction makeShape(shape: number[]|TypedArray, isPartial: boolean) {\n  const out: number[] = [];\n  for (let dim of shape) {\n    if (dim < 0) {\n      if (!isPartial) {\n        throw new Error(`Dimension ${dim} must be >= 0`);\n      }\n      if (dim < -1) {\n        throw new Error(`Dimension ${dim} must be >= -1`);\n      }\n      dim = -1;\n    }\n    out.push(dim);\n  }\n\n  return out;\n}\n\nexport function raggedTensorToTensorImpl(\n    shape: TypedArray, shapesShape: number[], values: TypedArray,\n    valuesShape: number[], valuesDType: DataType, defaultValue: TypedArray,\n    defaultValueShape: number[], rowPartitionValues: TypedArray[],\n    rowPartitionValuesShapes: number[][],\n    rowPartitionTypes: string[]): [number[], TypedArray] {\n  return new RaggedTensorToTensorOp(\n             shape, shapesShape, values, valuesShape, valuesDType, defaultValue,\n             defaultValueShape, rowPartitionValues, rowPartitionValuesShapes,\n             rowPartitionTypes)\n      .compute();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\n/**\n * The StringNGramsOp class creates ngrams from ragged string data.\n * The constructor contains all attributes related to the operation such as\n * padding widths and strings, and the compute function can be used to\n * compute the ngrams for different ragged tensor inputs.\n */\nclass StringNGramsOp {\n  private separator: Uint8Array;\n  private nGramWidths: number[];\n  private padWidth: number;\n  private leftPad: Uint8Array;\n  private rightPad: Uint8Array;\n  private preserveShort: boolean;\n\n  constructor(\n      separator: string, nGramWidths: number[], leftPad: string,\n      rightPad: string, padWidth: number, preserveShortSequences: boolean) {\n    this.separator = util.encodeString(separator);\n    this.nGramWidths = nGramWidths;\n    this.leftPad = util.encodeString(leftPad);\n    this.rightPad = util.encodeString(rightPad);\n    this.padWidth = padWidth;\n    this.preserveShort = preserveShortSequences;\n  }\n\n  private getPadWidth(nGramWidth: number) {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'padWidth' arg, but in no case should the padding\n    // ever be wider than 'nGramWidth' - 1.\n    return Math.min(\n        this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);\n  }\n\n  private getNumNGrams(length: number, nGramWidth: number) {\n    const padWidth = this.getPadWidth(nGramWidth);\n    return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);\n  }\n\n  private createNGrams(\n      data: Uint8Array[], splitIndex: number, output: Uint8Array[],\n      outputStartIndex: number, numNGrams: number, nGramWidth: number) {\n    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {\n      const padWidth = this.getPadWidth(nGramWidth);\n      const leftPadding = Math.max(0, padWidth - nGramIndex);\n      const rightPadding =\n          Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));\n      const numTokens = nGramWidth - (leftPadding + rightPadding);\n      const dataStartIndex =\n          splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);\n\n      // Calculate the total expected size of the nGram so we can reserve the\n      // correct amount of space in the string.\n      let nGramSize = 0;\n      // Size of the left padding.\n      nGramSize += leftPadding * this.leftPad.length;\n      // Size of the tokens.\n      for (let n = 0; n < numTokens; ++n) {\n        nGramSize += data[dataStartIndex + n].length;\n      }\n      // Size of the right padding.\n      nGramSize += rightPadding * this.rightPad.length;\n      // Size of the separators.\n      const numSeparators = leftPadding + rightPadding + numTokens - 1;\n      nGramSize += numSeparators * this.separator.length;\n\n      // Build the nGram.\n      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);\n      const nGram = output[outputStartIndex + nGramIndex];\n\n      let nextNGramIndex = 0;\n      const appendToNGram = (str: Uint8Array) =>\n          str.forEach((value) => nGram[nextNGramIndex++] = value);\n\n      for (let n = 0; n < leftPadding; ++n) {\n        appendToNGram(this.leftPad);\n        appendToNGram(this.separator);\n      }\n      // Only output first numTokens - 1 pairs of data and separator\n      for (let n = 0; n < numTokens - 1; ++n) {\n        appendToNGram(data[dataStartIndex + n]);\n        appendToNGram(this.separator);\n      }\n      // Handle case when there are no tokens or no right padding as these\n      // can result in consecutive separators.\n      if (numTokens > 0) {\n        // If we have tokens, then output last and then pair each separator\n        // with the right padding that follows, to ensure nGram ends either with\n        // the token or with the right pad.\n        appendToNGram(data[dataStartIndex + numTokens - 1]);\n        for (let n = 0; n < rightPadding; ++n) {\n          appendToNGram(this.separator);\n          appendToNGram(this.rightPad);\n        }\n      } else {\n        // If we don't have tokens, then the last item inserted into the nGram\n        // has been the separator from the left padding loop above. Hence,\n        // output right pad and separator and make sure to finish with a\n        // padding, not a separator.\n        for (let n = 0; n < rightPadding - 1; ++n) {\n          appendToNGram(this.rightPad);\n          appendToNGram(this.separator);\n        }\n        appendToNGram(this.rightPad);\n      }\n    }\n  }\n\n  // Data and splits together form the definition of the ragged tensor,\n  // where data is 1 dimensional and contains the values of the tensor\n  // and splits denotes the indices at which each row starts.\n  public compute(data: Uint8Array[], splits: Int32Array):\n      [Uint8Array[], Int32Array] {\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const inputDataSize = data.length;\n    const splitsSize = splits.length;\n    if (splitsSize > 0) {\n      let prevSplit = splits[0];\n      if (prevSplit !== 0) {\n        throw new Error(`First split value must be 0, got ${prevSplit}`);\n      }\n      for (let i = 1; i < splitsSize; ++i) {\n        let validSplits = splits[i] >= prevSplit;\n        validSplits = validSplits && (splits[i] <= inputDataSize);\n        if (!validSplits) {\n          throw new Error(`Invalid split value ${splits[i]}, must be in [${\n              prevSplit}, ${inputDataSize}]`);\n        }\n        prevSplit = splits[i];\n      }\n      if (prevSplit !== inputDataSize) {\n        throw new Error(`Last split value must be data size. Expected ${\n            inputDataSize}, got ${prevSplit}`);\n      }\n    }\n\n    const numBatchItems = splitsSize - 1;\n    const nGramsSplits = util.getArrayFromDType('int32', splitsSize);\n    // If there is no data or size, return an empty ragged tensor.\n    if (inputDataSize === 0 || splitsSize === 0) {\n      const empty: Uint8Array[] = new Array(inputDataSize);\n      for (let i = 0; i <= numBatchItems; ++i) {\n        nGramsSplits[i] = 0;\n      }\n      return [empty, nGramsSplits];\n    }\n\n    nGramsSplits[0] = 0;\n    for (let i = 1; i <= numBatchItems; ++i) {\n      const length = splits[i] - splits[i - 1];\n      let numNGrams = 0;\n      this.nGramWidths.forEach((nGramWidth) => {\n        numNGrams += this.getNumNGrams(length, nGramWidth);\n      });\n      if (this.preserveShort && length > 0 && numNGrams === 0) {\n        numNGrams = 1;\n      }\n      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;\n    }\n\n    const nGrams: Uint8Array[] = new Array(nGramsSplits[numBatchItems]);\n\n    for (let i = 0; i < numBatchItems; ++i) {\n      const splitIndex = splits[i];\n      let outputStartIdx = nGramsSplits[i];\n      this.nGramWidths.forEach((nGramWidth) => {\n        const length = splits[i + 1] - splits[i];\n        const numNGrams = this.getNumNGrams(length, nGramWidth);\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n        outputStartIdx += numNGrams;\n      });\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (nGramSplitsdata). If no ngrams were generated, then they will\n      // be equal (since we increment outputStartIdx by numNGrams every\n      // time we create a set of ngrams.)\n      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {\n        const dataLength = splits[i + 1] - splits[i];\n        // One legitimate reason to not have any ngrams when this.preserveShort\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (dataLength === 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one nGram.\n        const nGramWidth = dataLength + 2 * this.padWidth;\n        const numNGrams = 1;\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n      }\n    }\n    return [nGrams, nGramsSplits];\n  }\n}\n\nexport function stringNGramsImpl(\n    data: Uint8Array[], dataSplits: Int32Array, separator: string,\n    nGramWidths: number[], leftPad: string, rightPad: string, padWidth: number,\n    preserveShortSequences: boolean): [Uint8Array[], Int32Array] {\n  return new StringNGramsOp(\n             separator, nGramWidths, leftPad, rightPad, padWidth,\n             preserveShortSequences)\n      .compute(data, dataSplits);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction split(\n    str: Uint8Array, delimiters: Uint8Array, skipEmpty: boolean,\n    result: Uint8Array[]): void {\n  if (!str.length) {\n    return;\n  }\n  // When the delimiter is empty, the input is split into individual characters.\n  if (delimiters.length === 0) {\n    for (let i = 0; i < str.length; ++i) {\n      result.push(str.subarray(i, i + 1));\n    }\n    return;\n  }\n  // When there is one delimiter, the input is split only at that delimiter.\n  if (delimiters.length === 1) {\n    const delimiter = delimiters[0];\n    let f = str.indexOf(delimiter);\n    while (f !== -1) {\n      const token = str.subarray(0, f);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      str = str.subarray(f + 1);\n      f = str.indexOf(delimiter);\n    }\n    if (!skipEmpty || str.length !== 0) {\n      result.push(str);\n    }\n    return;\n  }\n  // When there are multiple delimiters, the input is split at every instance\n  // one of the delimiters appears.\n  let tokenStart = 0;\n  for (let i = 0; i < str.length + 1; i++) {\n    if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {\n      const token = str.subarray(tokenStart, i);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      tokenStart = i + 1;\n    }\n  }\n}\n\nexport function stringSplitImpl(\n    input: Uint8Array[], delimiter: Uint8Array,\n    skipEmpty: boolean): [TypedArray, Uint8Array[], [number, number]] {\n  const batchSize = input.length;\n\n  // Empty delimiter means split the input character by character.\n  const tokens: Uint8Array[] = [];\n\n  let outputSize = 0;\n  let maxNumEntries = 0;\n  const numIndices: number[] = new Array(batchSize);\n  for (let i = 0; i < batchSize; ++i) {\n    const prevTokensLength = tokens.length;\n    split(input[i], delimiter, skipEmpty, tokens);\n    const nEntries = tokens.length - prevTokensLength;\n    numIndices[i] = nEntries;\n    outputSize += nEntries;\n    maxNumEntries = Math.max(maxNumEntries, nEntries);\n  }\n\n  const indices = util.getArrayFromDType('int32', outputSize * 2) as TypedArray;\n  const values: Uint8Array[] = new Array(outputSize);\n  const shape: [number, number] = [batchSize, maxNumEntries];\n\n  let c = 0;\n  for (let i = 0; i < batchSize; ++i) {\n    for (let j = 0; j < numIndices[i]; ++j) {\n      // indices is a 2d tensor with shape of [outputSize, 2]\n      indices[c * 2] = i;\n      indices[c * 2 + 1] = j;\n      values[c] = tokens[c];\n      ++c;\n    }\n  }\n\n  return [indices, values, shape];\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {sliceImplCPU} from '../kernel_utils/shared';\n\nexport function slice(\n    args: {inputs: SliceInputs, attrs: SliceAttrs, backend: BackendWasm}) {\n  const {inputs: {x}, attrs: {begin, size}, backend} = args;\n\n  const [begin_, size_] = slice_util.parseSliceParams(x, begin, size);\n\n  const isContinous = slice_util.isSliceContinous(x.shape, begin_, size_);\n  const xVals = backend.readSync(x.dataId);\n  const out = backend.makeOutput(size_, x.dtype);\n  const xStrides = util.computeStrides(x.shape);\n  const outData = backend.dataIdMap.get(out.dataId);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin_, xStrides);\n\n    if (x.dtype === 'string') {\n      outData.stringBytes =\n          (xVals as Uint8Array[])\n              .slice(flatOffset, flatOffset + util.sizeFromShape(size_));\n    } else {\n      const outVals = backend.typedArrayFromHeap(out);\n      outVals.set(\n          (xVals as TypedArray)\n              .subarray(flatOffset, flatOffset + util.sizeFromShape(size_)));\n    }\n\n    return out;\n  }\n\n  if (x.dtype === 'string') {\n    const res = sliceImplCPU(xVals, begin_, size_, x.shape, x.dtype);\n    outData.stringBytes = res as Uint8Array[];\n    return out;\n  }\n\n  const outVals = backend.typedArrayFromHeap(out);\n  const rank = x.shape.length;\n  if (rank === 2) {\n    slice2d(\n        xVals as TypedArray, xStrides[0], outVals, begin_ as [number, number],\n        size_ as [number, number]);\n  } else if (rank === 3) {\n    slice3d(\n        xVals as TypedArray, xStrides[0], xStrides[1], outVals,\n        begin_ as [number, number, number], size_ as [number, number, number]);\n  } else if (rank === 4) {\n    slice4d(\n        xVals as TypedArray, xStrides[0], xStrides[1], xStrides[2], outVals,\n        begin_ as [number, number, number, number],\n        size_ as [number, number, number, number]);\n  } else {\n    const res =\n        sliceImplCPU(xVals, begin_, size_, x.shape, x.dtype) as TypedArray;\n    outVals.set(res);\n  }\n\n  return out;\n}\n\nfunction slice2d(\n    xVals: backend_util.TypedArray, xStride: number,\n    outVals: backend_util.TypedArray, begin: [number, number],\n    size: [number, number]): void {\n  let outOffset = 0;\n  const beginI = begin[0];\n  const beginJ = begin[1];\n  const endI = beginI + size[0];\n  for (let i = beginI; i < endI; i++) {\n    const xOffset = i * xStride + beginJ;\n    outVals.set(xVals.subarray(xOffset, xOffset + size[1]), outOffset);\n    outOffset += size[1];\n  }\n}\n\nfunction slice3d(\n    xVals: backend_util.TypedArray, xStride1: number, xStride2: number,\n    outVals: backend_util.TypedArray, begin: [number, number, number],\n    size: [number, number, number]): void {\n  let outOffset = 0;\n  const beginI = begin[0];\n  const beginJ = begin[1];\n  const beginK = begin[2];\n  const endI = beginI + size[0];\n  const endJ = beginJ + size[1];\n  for (let i = beginI; i < endI; i++) {\n    for (let j = beginJ; j < endJ; j++) {\n      const xOffset = i * xStride1 + j * xStride2 + beginK;\n      outVals.set(xVals.subarray(xOffset, xOffset + size[2]), outOffset);\n      outOffset += size[2];\n    }\n  }\n}\n\nfunction slice4d(\n    xVals: backend_util.TypedArray, xStride1: number, xStride2: number,\n    xStride3: number, outVals: backend_util.TypedArray,\n    begin: [number, number, number, number],\n    size: [number, number, number, number]): void {\n  let outOffset = 0;\n  const beginI = begin[0];\n  const beginJ = begin[1];\n  const beginK = begin[2];\n  const endI = beginI + size[0];\n  const endJ = beginJ + size[1];\n  const endK = beginK + size[2];\n  const beginL = begin[3];\n\n  for (let i = beginI; i < endI; i++) {\n    for (let j = beginJ; j < endJ; j++) {\n      for (let k = beginK; k < endK; k++) {\n        const xOffset = i * xStride1 + j * xStride2 + k * xStride3 + beginL;\n        outVals.set(xVals.subarray(xOffset, xOffset + size[3]), outOffset);\n        outOffset += size[3];\n      }\n    }\n  }\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'wasm',\n  kernelFunc: slice as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nfunction batchToSpaceND(args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: BackendWasm,\n  attrs: BatchToSpaceNDAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const xReshaped = reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const xTransposed =\n      transpose({inputs: {x: xReshaped}, backend, attrs: {perm: permuted}});\n  const xTransposedReshaped = reshape(\n      {inputs: {x: xTransposed}, backend, attrs: {shape: reshapedPermuted}});\n  const result = slice({\n    inputs: {x: xTransposedReshaped},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  backend.disposeData(xReshaped.dataId);\n  backend.disposeData(xTransposed.dataId);\n  backend.disposeData(xTransposedReshaped.dataId);\n\n  return result;\n}\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'wasm',\n  kernelFunc: batchToSpaceND as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Bincount, BincountAttrs, BincountInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmBincount: (\n    xId: number, size: number, hasWeights: boolean, weightsId: number,\n    weightsDType: CppDType, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmBincount = backend.wasm.cwrap(Bincount, null /*void*/, [\n    'number',   // xId\n    'number',   // size\n    'boolean',  // hasWeights\n    'number',   // weightsId\n    'number',   // weightsDType\n    'number',   // outId\n  ]);\n}\n\nfunction bincount(\n    args: {backend: BackendWasm, inputs: BincountInputs, attrs: BincountAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {x, weights} = inputs;\n  const {size} = attrs;\n\n  const hasWeights = weights.shape.reduce((p, v) => p * v, 1) !== 0;\n  const outShape = x.shape.length === 1 ? [size] : [x.shape[0], size];\n  const out = backend.makeOutput(outShape, weights.dtype);\n\n  function tensorId(x: TensorInfo) {\n    return backend.dataIdMap.get(x.dataId).id;\n  }\n  wasmBincount(\n      tensorId(x), size, hasWeights, tensorId(weights), CppDType[weights.dtype],\n      tensorId(out));\n\n  return out;\n}\n\nexport const bincountConfig: KernelConfig = {\n  kernelName: Bincount,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: bincount as unknown as KernelFunc\n};\n","\n/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BitwiseAnd, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = true;\n\nexport const bitwiseAndConfig: KernelConfig =\n    createBinaryKernelConfig(BitwiseAnd, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, BroadcastArgs, BroadcastArgsInputs, KernelConfig, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nexport function broadcastArgs(args: {\n  inputs: BroadcastArgsInputs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend} = args;\n  const {s0, s1} = inputs;\n\n  const s0Vals = backend.typedArrayFromHeap(s0);\n  const s1Vals = backend.typedArrayFromHeap(s1);\n\n  const broadcastShape = backend_util.assertAndGetBroadcastShape(\n      Array.from(s0Vals), Array.from(s1Vals));\n\n  return backend.makeOutput(\n      [broadcastShape.length], 'int32', /*memoryOffset=*/undefined,\n      /*values=*/new Int32Array(broadcastShape));\n}\n\nexport const broadcastArgsConfig: KernelConfig = {\n  kernelName: BroadcastArgs,\n  backendName: 'wasm',\n  kernelFunc: broadcastArgs\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\nimport {TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nexport function cast(\n    args: {inputs: CastInputs, attrs: CastAttrs, backend: BackendWasm}):\n    TensorInfo {\n  const {inputs: {x}, attrs: {dtype}, backend} = args;\n  const out = backend.makeOutput(x.shape, dtype);\n  const inVals = backend.typedArrayFromHeap(x);\n  const outVals = backend.typedArrayFromHeap(out);\n  outVals.set(inVals);\n  return out;\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'wasm',\n  kernelFunc: cast as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Ceil} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const ceilConfig: KernelConfig = createUnaryKernelConfig(Ceil);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, ClipByValueInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmClip: (xId: number, min: number, max: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmClip = backend.wasm.cwrap(ClipByValue, null /* void */, [\n    'number',  // x_id\n    'number',  // min\n    'number',  // max\n    'number'   // out_id\n  ]);\n}\n\nfunction clip(args: {\n  inputs: ClipByValueInputs,\n  backend: BackendWasm,\n  attrs: ClipByValueAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {clipValueMin, clipValueMax} = attrs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmClip(xId, clipValueMin, clipValueMax, outId);\n  return out;\n}\n\nexport const clipByValueConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: clip as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {concatImplCPU} from '../kernel_utils/shared';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: BackendWasm, attrs: ConcatAttrs}) {\n  const {inputs, backend} = args;\n\n  const axis = util.parseAxisParam(args.attrs.axis, inputs[0].shape)[0];\n\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, axis);\n\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  const out = backend.makeOutput(outShape, inputs[0].dtype);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return out;\n  }\n\n  if ($inputs[0].dtype === 'string') {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const inputs2D = $inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({inputs: {x: t}, backend, attrs: {shape}});\n    });\n\n    const inputsValShapes = inputs2D.map(t => {\n      return {vals: backend.readSync(t.dataId), shape: t.shape};\n    });\n\n    // Concats 2d tensors along axis=1.\n    outShape =\n        backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = inputs2D[0].shape[0] === 1;\n    const outVals = concatImplCPU(\n                        inputsValShapes, outShape, inputs[0].dtype,\n                        simplyConcat) as string[];\n\n    const finalOutShape =\n        backend_util.computeOutShape($inputs.map(t => t.shape), axis);\n\n    out.shape = finalOutShape;\n    const outData = backend.dataIdMap.get(out.dataId);\n    outData.stringBytes = backend_util.fromStringArrayToUint8(outVals);\n\n    inputs2D.forEach(t => backend.disposeData(t.dataId));\n\n    return out;\n  }\n\n  const batchDim = util.sizeFromShape($inputs[0].shape.slice(0, axis));\n  let sumInnerDims = 0;\n  const innerDims = $inputs.map(input => {\n    const innerDim = util.sizeFromShape(input.shape.slice(axis));\n    sumInnerDims += innerDim;\n    return innerDim;\n  });\n  const inVals = $inputs.map(input => backend.typedArrayFromHeap(input));\n  const outVals = backend.typedArrayFromHeap(out);\n  for (let b = 0; b < batchDim; b++) {\n    let outOffset = b * sumInnerDims;\n    for (let i = 0; i < inVals.length; i++) {\n      const innerDim = innerDims[i];\n      const inOffset = b * innerDim;\n      const vals = inVals[i].subarray(inOffset, inOffset + innerDim);\n      outVals.set(vals, outOffset);\n      outOffset += innerDim;\n    }\n  }\n  return out;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'wasm',\n  kernelFunc: concat as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function concatImpl(\n    inputs: Array<{vals: BackendValues, shape: number[]}>, outShape: number[],\n    dtype: DataType, simplyConcat: boolean): TypedArray|string[] {\n  const outVals = util.getArrayFromDType(dtype, util.sizeFromShape(outShape));\n\n  if (simplyConcat && dtype !== 'string') {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs.forEach(input => {\n      const size = util.sizeFromShape(input.shape);\n\n      (outVals as TypedArray).set(input.vals as TypedArray, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs.forEach(input => {\n      const decodedData = dtype === 'string' ?\n          backend_util.fromUint8ToStringArray(input.vals as Uint8Array[]) :\n          input.vals as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < input.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < input.shape[1]; ++col) {\n          outVals[resIdx + col] = decodedData[tIdx++];\n        }\n      }\n\n      colOffset += input.shape[1];\n    });\n  }\n\n  return outVals;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc, Tensor4D} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmConv2d: (\n    xId: number, batchSize: number, inputHeight: number, inputWidth: number,\n    filterId: number, filterHeight: number, filterWidth: number, padTop: number,\n    padRight: number, padBottom: number, padLeft: number, isSamePad: number,\n    dilationHeight: number, dilationWidth: number, strideHeight: number,\n    strideWidth: number, inputChannels: number, outputChannels: number,\n    outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmConv2d = backend.wasm.cwrap(Conv2D, null /* void */, [\n    'number',  // xId\n    'number',  // batchSize\n    'number',  // inputHeight\n    'number',  // inputWidth\n    'number',  // filterId\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // padTop\n    'number',  // padRight\n    'number',  // padBottom\n    'number',  // padLeft\n    'number',  // isSamePad\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // inputChannels\n    'number',  // outputChannels\n    'number',  // outId\n  ]);\n}\n\nfunction conv2d(\n    args: {inputs: Conv2DInputs, backend: BackendWasm, attrs: Conv2DAttrs}) {\n  const {inputs, attrs, backend} = args;\n\n  const {x, filter} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const filterId = backend.dataIdMap.get(filter.dataId).id;\n\n  const {strides, dilations, pad, dimRoundingMode, dataFormat} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      (x as Tensor4D).shape, (filter as Tensor4D).shape, strides, dilations,\n      pad, dimRoundingMode, false, $dataFormat);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padRight = convInfo.padInfo.right;\n  const padBottom = convInfo.padInfo.bottom;\n  const padLeft = convInfo.padInfo.left;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const inputChannels = convInfo.inChannels;\n  const outputChannels = convInfo.outChannels;\n  const isSamePad = convInfo.padInfo.type === 'SAME' ? 1 : 0;\n\n  if (convInfo.dataFormat !== 'channelsLast') {\n    throw new Error(\n        `wasm backend Conv2D does not support dataFormat:'` +\n        `${convInfo.dataFormat}'. Please use 'channelsLast'.`);\n  }\n\n  const out = backend.makeOutput(convInfo.outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmConv2d(\n      xId, x.shape[0], x.shape[1], x.shape[2], filterId, filterHeight,\n      filterWidth, padTop, padRight, padBottom, padLeft, isSamePad,\n      dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels,\n      outputChannels, outId);\n  return out;\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: conv2d as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmConv2DBackpropInput: (\n    dyId: number, filterId: number, batchSize: number, filterHeight: number,\n    filterWidth: number, inHeight: number, inWidth: number, inChannels: number,\n    outHeight: number, outWidth: number, outChannels: number,\n    strideHeight: number, strideWidth: number, topPad: number, leftPad: number,\n    fltS0: number, fltS1: number, fltS2: number, xBatchStride: number,\n    xRowStride: number, xColStride: number, xChannelStride: number,\n    yBatchStride: number, yRowStride: number, yColStride: number,\n    yChannelStride: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmConv2DBackpropInput = backend.wasm.cwrap(Conv2DBackpropInput, null, [\n    'number',  // dyId\n    'number',  // filterId\n    'number',  // batchSize\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // inChannels\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // outChannels\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // topPad\n    'number',  // leftPad\n    'number',  // fltS0\n    'number',  // fltS1\n    'number',  // fltS2\n    'number',  // xBatchStride\n    'number',  // xRowStride\n    'number',  // xColStride\n    'number',  // xChannelStride\n    'number',  // yBatchStride\n    'number',  // yRowStride\n    'number',  // yColStride\n    'number',  // yChannelStride\n    'number',  // outId\n  ]);\n}\n\nfunction conv2DBackpropInput(args: {\n  backend: BackendWasm,\n  inputs: Conv2DBackpropInputInputs,\n  attrs: Conv2DBackpropInputAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, inputShape} = attrs;\n\n  const dilations = 1;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const dxStrides = util.computeStrides(convInfo.inShape);\n  const dyStrides = util.computeStrides(dy.shape);\n  const [fltS0, fltS1, fltS2] = util.computeStrides(filter.shape);\n  const xBatchStride = dxStrides[0];\n  const xRowStride = isChannelsLast ? dxStrides[1] : dxStrides[2];\n  const xColStride = isChannelsLast ? dxStrides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : dxStrides[1];\n  const yBatchStride = dyStrides[0];\n  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];\n  const yColStride = isChannelsLast ? dyStrides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];\n\n  const out = backend.makeOutput(convInfo.inShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const dyId = backend.dataIdMap.get(dy.dataId).id;\n  const filterId = backend.dataIdMap.get(filter.dataId).id;\n\n  wasmConv2DBackpropInput(\n      dyId, filterId, batchSize, filterHeight, filterWidth, inHeight, inWidth,\n      inChannels, outHeight, outWidth, outChannels, strideHeight, strideWidth,\n      topPad, leftPad, fltS0, fltS1, fltS2, xBatchStride, xRowStride,\n      xColStride, xChannelStride, yBatchStride, yRowStride, yColStride,\n      yChannelStride, outId);\n  return out;\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: conv2DBackpropInput as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmConv3D: (\n    xId: number, filterId: number, outId: number, batchSize: number,\n    inDepth: number, inHeight: number, inWidth: number, inChannels: number,\n    outDepth: number, outHeight: number, outWidth: number, outChannels: number,\n    strideDepth: number, strideHeight: number, strideWidth: number,\n    dilationDepth: number, dilationHeight: number, dilationWidth: number,\n    filterDepth: number, filterHeight: number, filterWidth: number,\n    padFront: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmConv3D = backend.wasm.cwrap(Conv3D, null, [\n    'number',  // xId\n    'number',  // filterId\n    'number',  // outId\n    'number',  // batchSize\n    'number',  // inDepth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // inChannels\n    'number',  // outDepth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // outChannels\n    'number',  // strideDepth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationDepth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // filterDepth\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // padFront\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function conv3D(args: {\n  inputs: Conv3DInputs,\n  attrs: Conv3DAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n  if (x.dtype !== 'float32') {\n    throw new Error(`Tensor x must have dtype float32, got ${x.dtype}`);\n  }\n  if (filter.dtype !== 'float32') {\n    throw new Error(\n        `Tensor filter must have dtype float32, got ${filter.dtype}`);\n  }\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const out = backend.makeOutput(convInfo.outShape, x.dtype);\n  wasmConv3D(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(filter.dataId).id,\n      backend.dataIdMap.get(out.dataId).id,\n      convInfo.batchSize,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.inChannels,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.outChannels,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.filterDepth,\n      convInfo.filterHeight,\n      convInfo.filterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return out;\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: conv3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterV2, Conv3DBackpropFilterV2Attrs, Conv3DBackpropFilterV2Inputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmConv3DBackpropFilterV2: (\n    xId: number, dyId: number, dwId: number, batchSize: number, inDepth: number,\n    inHeight: number, inWidth: number, inChannels: number, outDepth: number,\n    outHeight: number, outWidth: number, outChannels: number,\n    strideDepth: number, strideHeight: number, strideWidth: number,\n    dilationDepth: number, dilationHeight: number, dilationWidth: number,\n    filterDepth: number, filterHeight: number, filterWidth: number,\n    padFront: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmConv3DBackpropFilterV2 =\n      backend.wasm.cwrap(Conv3DBackpropFilterV2, null, [\n        'number',  // xId\n        'number',  // dyId\n        'number',  // dwId\n        'number',  // batchSize\n        'number',  // inDepth\n        'number',  // inHeight\n        'number',  // inWidth\n        'number',  // inChannels\n        'number',  // outDepth\n        'number',  // outHeight\n        'number',  // outWidth\n        'number',  // outChannels\n        'number',  // strideDepth\n        'number',  // strideHeight\n        'number',  // strideWidth\n        'number',  // dilationDepth\n        'number',  // dilationHeight\n        'number',  // dilationWidth\n        'number',  // filterDepth\n        'number',  // filterHeight\n        'number',  // filterWidth\n        'number',  // padFront\n        'number',  // padTop\n        'number',  // padLeft\n      ]);\n}\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterV2Inputs,\n  attrs: Conv3DBackpropFilterV2Attrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  if (x.dtype !== 'float32') {\n    throw new Error(`Tensor dy must have dtype float32, got ${x.dtype}`);\n  }\n  if (dy.dtype !== 'float32') {\n    throw new Error(`Tensor filter must have dtype float32, got ${dy.dtype}`);\n  }\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      /*dilations=*/1, pad);\n\n  const dw = backend.makeOutput(convInfo.filterShape, dy.dtype);\n\n  wasmConv3DBackpropFilterV2(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dw.dataId).id,\n      convInfo.batchSize,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.inChannels,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.outChannels,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.filterDepth,\n      convInfo.filterHeight,\n      convInfo.filterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return dw;\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: conv3DBackpropFilterV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmConv3DBackpropInputV2: (\n    filterId: number, dyId: number, dxId: number, batchSize: number,\n    inDepth: number, inHeight: number, inWidth: number, inChannels: number,\n    outDepth: number, outHeight: number, outWidth: number, outChannels: number,\n    strideDepth: number, strideHeight: number, strideWidth: number,\n    dilationDepth: number, dilationHeight: number, dilationWidth: number,\n    filterDepth: number, filterHeight: number, filterWidth: number,\n    padFront: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmConv3DBackpropInputV2 = backend.wasm.cwrap(Conv3DBackpropInputV2, null, [\n    'number',  // filterId\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // batchSize\n    'number',  // inDepth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // inChannels\n    'number',  // outDepth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // outChannels\n    'number',  // strideDepth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationDepth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // filterDepth\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // padFront\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputV2Inputs,\n  attrs: Conv3DBackpropInputV2Attrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {pad, strides, inputShape} = attrs;\n  if (dy.dtype !== 'float32') {\n    throw new Error(`Tensor dy must have dtype float32, got ${dy.dtype}`);\n  }\n  if (filter.dtype !== 'float32') {\n    throw new Error(\n        `Tensor filter must have dtype float32, got ${filter.dtype}`);\n  }\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, /*dilations=*/1, pad);\n\n  const dx = backend.makeOutput(convInfo.inShape, dy.dtype);\n\n  wasmConv3DBackpropInputV2(\n      backend.dataIdMap.get(filter.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      convInfo.batchSize,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.inChannels,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.outChannels,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.filterDepth,\n      convInfo.filterHeight,\n      convInfo.filterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return dx;\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: conv3DBackpropInputV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const cosConfig: KernelConfig = createUnaryKernelConfig(Cos);\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const coshConfig: KernelConfig = createUnaryKernelConfig(Cosh);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {cast} from './Cast';\n\n// Must match enum in CropAndResize.cc\nenum InterpolationMethod {\n  bilinear = 0,\n  nearest = 1\n}\n\nlet wasmCropAndResize: (\n    imagesId: number, boxesId: number, boxIndId: number, numBoxes: number,\n    imagesShape: Uint8Array, cropHeight: number, cropWidth: number,\n    method: number, extrapolationValue: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmCropAndResize = backend.wasm.cwrap(CropAndResize, null /*void*/, [\n    'number',  // imagesId\n    'number',  // boxesId\n    'number',  // boxIndId\n    'number',  // numBoxes\n    'array',   // images shape\n    'number',  // cropHeight\n    'number',  // cropWidth\n    'number',  // method\n    'number',  // extrapolation value\n    'number'   // out id\n  ]);\n}\n\nfunction cropAndResize(args: {\n  backend: BackendWasm,\n  inputs: CropAndResizeInputs,\n  attrs: CropAndResizeAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {method, extrapolationValue, cropSize} = attrs;\n  const {image, boxes, boxInd} = inputs;\n\n  const numBoxes = boxes.shape[0];\n\n  const [cropHeight, cropWidth] = cropSize as [number, number];\n  const outShape = [numBoxes, cropHeight, cropWidth, image.shape[3]];\n\n  let imagesData = backend.dataIdMap.get(image.dataId);\n  let castedData;\n  if (image.dtype !== 'float32') {\n    castedData = cast({backend, inputs: {x: image}, attrs: {dtype: 'float32'}});\n    imagesData = backend.dataIdMap.get(castedData.dataId);\n  }\n\n  const imagesId = imagesData.id;\n  const boxesId = backend.dataIdMap.get(boxes.dataId).id;\n  const boxIndId = backend.dataIdMap.get(boxInd.dataId).id;\n\n  const out = backend.makeOutput(outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const imagesShapeBytes = new Uint8Array(new Int32Array(image.shape).buffer);\n\n  wasmCropAndResize(\n      imagesId, boxesId, boxIndId, numBoxes, imagesShapeBytes, cropHeight,\n      cropWidth,\n      InterpolationMethod[method as unknown as\n                          keyof typeof InterpolationMethod],\n      extrapolationValue, outId);\n\n  if (castedData != null) {\n    backend.disposeData(castedData.dataId);\n  }\n\n  return out;\n}\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: cropAndResize as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Cumprod, CumprodAttrs, CumprodInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nimport {transpose} from './Transpose';\n\nlet wasmCumprod: (xId: number, exclusive: number, reverse: number,\n                 finalDim: number, outId: number, dtype: CppDType) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmCumprod = backend.wasm.cwrap(Cumprod, null /* void */, [\n    'number', // x_id\n    'number', // exclusive\n    'number', // reverse\n    'number', // final_dim\n    'number', // out_id\n    'number'  // dtype\n  ]);\n}\n\nexport function cumprod(\n  args: {inputs: CumprodInputs, backend: BackendWasm, attrs: CumprodAttrs}):\nTensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  const xRank = x.shape.length;\n\n  util.assert(x.dtype === 'float32' || x.dtype === 'int32',\n    () => `cumprod does not support ${x.dtype} tensors in the WASM backend`);\n  // permute required axis to inner most axis\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation !== null) {\n    permutedX = transpose({inputs: {x}, attrs: {perm: permutation}, backend});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  backend_util.assertAxesAreInnerMostDims('cumprod', [permutedAxis], xRank);\n\n  const permutedOut = backend.makeOutput(permutedX.shape, permutedX.dtype);\n  const finalDim = permutedX.shape[permutedAxis];\n  const permutedXId = backend.dataIdMap.get(permutedX.dataId).id;\n  const permutedOutId = backend.dataIdMap.get(permutedOut.dataId).id;\n  wasmCumprod(permutedXId, exclusive ? 1 : 0, reverse ? 1 : 0, finalDim,\n              permutedOutId, CppDType[x.dtype]);\n\n  // transpose data back if permuted\n  let out = permutedOut;\n  if (permutation !== null) {\n    const undoPermutation = backend_util.getUndoAxesPermutation(permutation);\n    out = transpose(\n      {inputs: {x: permutedOut}, attrs: {perm: undoPermutation}, backend});\n    backend.disposeData(permutedX.dataId);\n    backend.disposeData(permutedOut.dataId);\n  }\n  return out;\n}\n\nexport const cumprodConfig: KernelConfig = {\n  kernelName: Cumprod,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: cumprod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Cumsum, CumsumAttrs, CumsumInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nimport {transpose} from './Transpose';\n\nlet wasmCumsum: (xId: number, exclusive: number, reverse: number,\n                 finalDim: number, outId: number, dtype: CppDType) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmCumsum = backend.wasm.cwrap(Cumsum, null /* void */, [\n    'number', // x_id\n    'number', // exclusive\n    'number', // reverse\n    'number', // final_dim\n    'number', // out_id\n    'number'  // dtype\n  ]);\n}\n\nexport function cumsum(\n  args: {inputs: CumsumInputs, backend: BackendWasm, attrs: CumsumAttrs}):\nTensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  const xRank = x.shape.length;\n\n  util.assert(x.dtype === 'float32' || x.dtype === 'int32',\n    () => `cumsum does not support ${x.dtype} tensors in the WASM backend`);\n  // permute required axis to inner most axis\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation !== null) {\n    permutedX = transpose({inputs: {x}, attrs: {perm: permutation}, backend});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  backend_util.assertAxesAreInnerMostDims('cumsum', [permutedAxis], xRank);\n\n  const permutedOut = backend.makeOutput(permutedX.shape, permutedX.dtype);\n  const finalDim = permutedX.shape[permutedAxis];\n  const permutedXId = backend.dataIdMap.get(permutedX.dataId).id;\n  const permutedOutId = backend.dataIdMap.get(permutedOut.dataId).id;\n  wasmCumsum(permutedXId, exclusive ? 1 : 0, reverse ? 1 : 0, finalDim,\n             permutedOutId, CppDType[x.dtype]);\n\n  // transpose data back if permuted\n  let out = permutedOut;\n  if (permutation !== null) {\n    const undoPermutation = backend_util.getUndoAxesPermutation(permutation);\n    out = transpose(\n      {inputs: {x: permutedOut}, attrs: {perm: undoPermutation}, backend});\n    backend.disposeData(permutedX.dataId);\n    backend.disposeData(permutedOut.dataId);\n  }\n  return out;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: cumsum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmDenseBincount: (\n    xId: number, xShape: Uint8Array, xShapeLen: number, size: number,\n    hasWeights: boolean, weightsId: number, weightsDType: CppDType,\n    binaryOutput: boolean, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmDenseBincount = backend.wasm.cwrap('DenseBincount', null /*void*/, [\n    'number',   // xId\n    'array',    // xShape\n    'number',   // xShapeLen\n    'number',   // size\n    'boolean',  // hasWeights\n    'number',   // weightsId\n    'number',   // weightsDType\n    'boolean',  // binaryOutput\n    'number',   // outId\n  ]);\n}\n\nfunction denseBincount(args: {\n  backend: BackendWasm,\n  inputs: DenseBincountInputs,\n  attrs: DenseBincountAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {x, weights} = inputs;\n  const {size, binaryOutput} = attrs;\n\n  const hasWeights = weights.shape.reduce((p, v) => p * v, 1) !== 0;\n  const outShape = x.shape.length === 1 ? [size] : [x.shape[0], size];\n  const out = backend.makeOutput(outShape, weights.dtype);\n\n  function tensorId(x: TensorInfo) {\n    return backend.dataIdMap.get(x.dataId).id;\n  }\n  wasmDenseBincount(\n      tensorId(x), new Uint8Array(new Int32Array(x.shape).buffer),\n      x.shape.length, size, hasWeights, tensorId(weights),\n      CppDType[weights.dtype], binaryOutput, tensorId(out));\n\n  return out;\n}\n\nexport const denseBincountConfig: KernelConfig = {\n  kernelName: DenseBincount,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: denseBincount as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmDepthToSpace: (\n    xId: number, blockSize: number, channelsLast: number, xStrides: Uint8Array,\n    xStridesLength: number, outputShape: Uint8Array, outputStrides: Uint8Array,\n    outSize: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmDepthToSpace = backend.wasm.cwrap(DepthToSpace, null /*void*/, [\n    'number',  // xId\n    'number',  // blockSize\n    'number',  // channelsLast\n    'array',   // xStrides\n    'number',  // xStridesLength\n    'array',   // outputShape\n    'array',   // outputStrides\n    'number',  // outSize\n    'number',  // outId\n  ]);\n}\n\nexport function depthToSpace(args: {\n  backend: BackendWasm,\n  inputs: DepthToSpaceInputs,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  const batchSize = x.shape[0];\n  const inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n  const inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n  const inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const outputShape = (dataFormat === 'NHWC') ?\n      [batchSize, outputHeight, outputWidth, outputDepth] :\n      [batchSize, outputDepth, outputHeight, outputWidth];\n\n  const out = backend.makeOutput(outputShape, 'float32');\n\n  const xData = backend.dataIdMap.get(x.dataId);\n  const xId = xData.id;\n  const xStridesBytes =\n      new Uint8Array(new Int32Array(util.computeStrides(x.shape)).buffer);\n\n  const outputShapeBytes = new Uint8Array(new Int32Array(outputShape).buffer);\n  const outStridesBytes =\n      new Uint8Array(new Int32Array(util.computeStrides(outputShape)).buffer);\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const channelsLast = dataFormat === 'NHWC' ? 1 : 0;\n  wasmDepthToSpace(\n      xId, blockSize, channelsLast, xStridesBytes, x.shape.length - 1,\n      outputShapeBytes, outStridesBytes, outputShape.length, outId);\n\n  return out;\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: depthToSpace as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc, Tensor4D} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmDepthwiseConv2d: (\n    xId: number, batchSize: number, inputHeight: number, inputWidth: number,\n    filterId: number, filterHeight: number, filterWidth: number, padTop: number,\n    padRight: number, padBottom: number, padLeft: number, isSamePad: number,\n    dilationHeight: number, dilationWidth: number, strideHeight: number,\n    strideWidth: number, inputChannels: number, outputChannels: number,\n    outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmDepthwiseConv2d =\n      backend.wasm.cwrap(DepthwiseConv2dNative, null /* void */, [\n        'number',  // xId\n        'number',  // batchSize\n        'number',  // inputHeight\n        'number',  // inputWidth\n        'number',  // filterId\n        'number',  // filterHeight\n        'number',  // filterWidth\n        'number',  // padTop\n        'number',  // padRight\n        'number',  // padBottom\n        'number',  // padLeft\n        'number',  // isSamePad\n        'number',  // dilationHeight\n        'number',  // dilationWidth\n        'number',  // strideHeight\n        'number',  // strideWidth\n        'number',  // inputChannels\n        'number',  // outputChannels\n        'number',  // outId\n      ]);\n}\n\nfunction depthwiseConv2d(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  backend: BackendWasm,\n  attrs: DepthwiseConv2dNativeAttrs\n}) {\n  const {inputs, attrs, backend} = args;\n\n  const {x, filter} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const filterId = backend.dataIdMap.get(filter.dataId).id;\n\n  const {strides, dilations, pad, dimRoundingMode} = attrs;\n\n  const $dilations = dilations == null ? [1, 1] : dilations;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      (x as Tensor4D).shape, (filter as Tensor4D).shape, strides,\n      ($dilations as number | [number, number]), pad, dimRoundingMode,\n      true /* depthwise */);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padRight = convInfo.padInfo.right;\n  const padBottom = convInfo.padInfo.bottom;\n  const padLeft = convInfo.padInfo.left;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const inputChannels = convInfo.inChannels;\n  const outputChannels = convInfo.outChannels;\n  const isSamePad = convInfo.padInfo.type === 'SAME' ? 1 : 0;\n\n  if (convInfo.dataFormat !== 'channelsLast') {\n    throw new Error(\n        `wasm backend DepthwiseConv2dNative does not support dataFormat:'` +\n        `${convInfo.dataFormat}'. Please use 'channelsLast'.`);\n  }\n\n  const out = backend.makeOutput(convInfo.outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmDepthwiseConv2d(\n      xId, x.shape[0], x.shape[1], x.shape[2], filterId, filterHeight,\n      filterWidth, padTop, padRight, padBottom, padLeft, isSamePad,\n      dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels,\n      outputChannels, outId);\n  return out;\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: depthwiseConv2d as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Diag, DiagInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmDiag: (xId: number, xDType: CppDType, xSize: number, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm) {\n  wasmDiag = backend.wasm.cwrap('Diag', null, [\n    'number',  // xId\n    'number',  // xDType,\n    'number',  // xSize,\n    'number',  // outId\n  ]);\n}\n\nexport function diag(args: {inputs: DiagInputs, backend: BackendWasm}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const out = backend.makeOutput([...x.shape, ...x.shape], x.dtype);\n\n  wasmDiag(\n      backend.dataIdMap.get(x.dataId).id, CppDType[x.dtype], xSize,\n      backend.dataIdMap.get(out.dataId).id);\n  return out;\n}\n\nexport const diagConfig: KernelConfig = {\n  kernelName: Diag,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: diag as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {CppDType} from './types';\n\nlet wasmDilation2D: (\n    xId: number, filterId: number, outId: number, dtype: number, batch: number,\n    depth: number, inHeight: number, inWidth: number, outHeight: number,\n    outWidth: number, strideHeight: number, strideWidth: number,\n    dilationHeight: number, dilationWidth: number, filterHeight: number,\n    filterWidth: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmDilation2D = backend.wasm.cwrap(Dilation2D, null, [\n    'number',  // xId\n    'number',  // filterId\n    'number',  // outId\n    'number',  // dtype\n    'number',  // batch\n    'number',  // depth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function dilation2D(args: {\n  inputs: Dilation2DInputs,\n  attrs: Dilation2DAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  if (x.dtype !== filter.dtype) {\n    throw new Error(\n        `Dilation2D error: x must have the same dtype as filter. Got ${\n            x.dtype} and ${filter.dtype}`);\n  }\n\n  const dilationInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      /*dataFormat=*/'NHWC', dilations);\n\n  const out = backend.makeOutput(dilationInfo.outShape, x.dtype);\n\n  wasmDilation2D(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(filter.dataId).id,\n      backend.dataIdMap.get(out.dataId).id,\n      CppDType[x.dtype],\n      dilationInfo.batchSize,\n      /*depth=*/dilationInfo.inChannels,\n      dilationInfo.inHeight,\n      dilationInfo.inWidth,\n      dilationInfo.outHeight,\n      dilationInfo.outWidth,\n      dilationInfo.strideHeight,\n      dilationInfo.strideWidth,\n      dilationInfo.dilationHeight,\n      dilationInfo.dilationWidth,\n      dilationInfo.filterHeight,\n      dilationInfo.filterWidth,\n      dilationInfo.padInfo.top,\n      dilationInfo.padInfo.left,\n  );\n  return out;\n}\n\nexport const dilation2DConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: dilation2D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, KernelConfig, KernelFunc, Tensor3D, Tensor4D, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmDilation2DBackpropFilter: (\n    xId: number, filterId: number, dyId: number, gradId: number, dtype: number,\n    batch: number, depth: number, inHeight: number, inWidth: number,\n    outHeight: number, outWidth: number, strideHeight: number,\n    strideWidth: number, dilationHeight: number, dilationWidth: number,\n    filterHeight: number, filterWidth: number, padTop: number,\n    padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmDilation2DBackpropFilter =\n      backend.wasm.cwrap(Dilation2DBackpropFilter, null, [\n        'number',  // xId\n        'number',  // filterId\n        'number',  // dyId\n        'number',  // gradId\n        'number',  // dtype\n        'number',  // batch\n        'number',  // depth\n        'number',  // inHeight\n        'number',  // inWidth\n        'number',  // outHeight\n        'number',  // outWidth\n        'number',  // strideHeight\n        'number',  // strideWidth\n        'number',  // dilationHeight\n        'number',  // dilationWidth\n        'number',  // filterHeight\n        'number',  // filterWidth\n        'number',  // padTop\n        'number',  // padLeft\n      ]);\n}\n\nexport function dilation2DBackpropFilter(args: {\n  inputs: {x: Tensor4D, filter: Tensor3D, dy: Tensor4D},\n  attrs: Dilation2DAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, dy} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  if (x.dtype !== filter.dtype || x.dtype !== dy.dtype) {\n    throw new Error(\n        `Dilation2DBackpropFilter error: x must have the same dtype as filter and dy. Got ${\n            x.dtype}, ${filter.dtype}, and ${dy.dtype}`);\n  }\n\n  const dilationInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      /*dataFormat=*/'NHWC', dilations);\n\n  const gradients = backend.makeOutput(filter.shape, filter.dtype);\n\n  wasmDilation2DBackpropFilter(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(filter.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(gradients.dataId).id,\n      CppDType[x.dtype],\n      dilationInfo.batchSize,\n      /*depth=*/dilationInfo.inChannels,\n      dilationInfo.inHeight,\n      dilationInfo.inWidth,\n      dilationInfo.outHeight,\n      dilationInfo.outWidth,\n      dilationInfo.strideHeight,\n      dilationInfo.strideWidth,\n      dilationInfo.dilationHeight,\n      dilationInfo.dilationWidth,\n      dilationInfo.filterHeight,\n      dilationInfo.filterWidth,\n      dilationInfo.padInfo.top,\n      dilationInfo.padInfo.left,\n  );\n  return gradients;\n}\n\nexport const dilation2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: dilation2DBackpropFilter as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, KernelConfig, KernelFunc, Tensor3D, Tensor4D, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmDilation2DBackpropInput: (\n    xId: number, filterId: number, dyId: number, gradId: number, dtype: number,\n    batch: number, depth: number, inHeight: number, inWidth: number,\n    outHeight: number, outWidth: number, strideHeight: number,\n    strideWidth: number, dilationHeight: number, dilationWidth: number,\n    filterHeight: number, filterWidth: number, padTop: number,\n    padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmDilation2DBackpropInput =\n      backend.wasm.cwrap(Dilation2DBackpropInput, null, [\n        'number',  // xId\n        'number',  // filterId\n        'number',  // dyId\n        'number',  // gradId\n        'number',  // dtype\n        'number',  // batch\n        'number',  // depth\n        'number',  // inHeight\n        'number',  // inWidth\n        'number',  // outHeight\n        'number',  // outWidth\n        'number',  // strideHeight\n        'number',  // strideWidth\n        'number',  // dilationHeight\n        'number',  // dilationWidth\n        'number',  // filterHeight\n        'number',  // filterWidth\n        'number',  // padTop\n        'number',  // padLeft\n      ]);\n}\n\nexport function dilation2DBackpropInput(args: {\n  inputs: {x: Tensor4D, filter: Tensor3D, dy: Tensor4D},\n  attrs: Dilation2DAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, dy} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  if (x.dtype !== filter.dtype || x.dtype !== dy.dtype) {\n    throw new Error(\n        `Dilation2DBackpropInput error: x must have the same dtype as filter and dy. Got ${\n            x.dtype}, ${filter.dtype}, and ${dy.dtype}`);\n  }\n\n  const dilationInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      /*dataFormat=*/'NHWC', dilations);\n\n  const gradients = backend.makeOutput(x.shape, x.dtype);\n\n  wasmDilation2DBackpropInput(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(filter.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(gradients.dataId).id,\n      CppDType[x.dtype],\n      dilationInfo.batchSize,\n      /*depth=*/dilationInfo.inChannels,\n      dilationInfo.inHeight,\n      dilationInfo.inWidth,\n      dilationInfo.outHeight,\n      dilationInfo.outWidth,\n      dilationInfo.strideHeight,\n      dilationInfo.strideWidth,\n      dilationInfo.dilationHeight,\n      dilationInfo.dilationWidth,\n      dilationInfo.filterHeight,\n      dilationInfo.filterWidth,\n      dilationInfo.padInfo.top,\n      dilationInfo.padInfo.left,\n  );\n  return gradients;\n}\n\nexport const dilation2DBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: dilation2DBackpropInput as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const eluConfig: KernelConfig = createUnaryKernelConfig(Elu);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {EluGrad, EluGradInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmEluGrad: (yId: number, dyId: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmEluGrad = backend.wasm.cwrap(EluGrad, null, [\n    'number',  // yId\n    'number',  // dyId,\n    'number',  // outId\n  ]);\n}\n\nexport function eluGrad(args: {inputs: EluGradInputs, backend: BackendWasm}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {dy, y} = inputs;\n\n  const out = backend.makeOutput(y.shape, 'float32');\n  const tensorId = (x: TensorInfo) => {\n    return backend.dataIdMap.get(x.dataId).id!;\n  };\n  wasmEluGrad(tensorId(y), tensorId(dy), tensorId(out));\n  return out;\n}\n\nexport const eluGradConfig: KernelConfig = {\n  kernelName: EluGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: eluGrad as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = false;\nexport const equalConfig: KernelConfig =\n    createBinaryKernelConfig(Equal, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const erfConfig: KernelConfig = createUnaryKernelConfig(Erf);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const expConfig: KernelConfig = createUnaryKernelConfig(Exp, 'float32');\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  attrs: ExpandDimsAttrs,\n  backend: BackendWasm\n}) {\n  const {inputs, attrs, backend} = args;\n  const {input} = inputs;\n  const {dim} = attrs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'wasm',\n  kernelFunc: expandDims as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const expm1Config: KernelConfig =\n    createUnaryKernelConfig(Expm1, 'float32');\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\nimport {Fill, FillAttrs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nexport function fill(args: {attrs: FillAttrs, backend: BackendWasm}) {\n  const {attrs: {shape, value}, backend} = args;\n  let {attrs: {dtype}} = args;\n\n  dtype = dtype || util.inferDtype(value);\n\n  const out = backend.makeOutput(shape, dtype);\n  const outVals = backend.typedArrayFromHeap(out);\n  outVals.fill(value as number);\n  return out;\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'wasm',\n  kernelFunc: fill as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FlipLeftRight, FlipLeftRightInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmFlipLeftRight: (\n    xId: number, batch: number, imageHeight: number, imageWidth: number,\n    numChannels: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmFlipLeftRight = backend.wasm.cwrap(FlipLeftRight, null /* void */, [\n    'number',  // xId\n    'number',  // batch\n    'number',  // imageHeight\n    'number',  // imageWidth\n    'number',  // numChannels\n    'number',  // outId\n  ]);\n}\n\nexport function flipLeftRight(\n    args: {inputs: FlipLeftRightInputs, backend: BackendWasm}): TensorInfo {\n  const {inputs, backend} = args;\n  const {image} = inputs;\n\n  const out = backend.makeOutput(image.shape, image.dtype);\n  const imageId = backend.dataIdMap.get(image.dataId).id;\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n  wasmFlipLeftRight(\n      imageId, batch, imageHeight, imageWidth, numChannels, outId);\n  return out;\n}\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'wasm',\n  kernelFunc: flipLeftRight as unknown as KernelFunc,\n  setupFunc: setup\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const floorConfig: KernelConfig = createUnaryKernelConfig(Floor);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = false;\nexport const floorDivConfig: KernelConfig =\n    createBinaryKernelConfig(FloorDiv, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmBatchNorm: (\n    xId: number, meanId: number, varianceId: number, offsetId: number,\n    scaleId: number, varianceEpsilon: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmBatchNorm = backend.wasm.cwrap(\n      FusedBatchNorm, null /* void */,\n      ['number', 'number', 'number', 'number', 'number', 'number', 'number']);\n}\n\nfunction fusedBatchNorm(args: {\n  backend: BackendWasm,\n  inputs: FusedBatchNormInputs,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {varianceEpsilon} = attrs;\n  const {x, mean, variance, offset, scale} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const meanId = backend.dataIdMap.get(mean.dataId).id;\n  const varianceId = backend.dataIdMap.get(variance.dataId).id;\n  const offsetId = offset != null ? backend.dataIdMap.get(offset.dataId).id : 0;\n  const scaleId = scale != null ? backend.dataIdMap.get(scale.dataId).id : 0;\n\n  const out = backend.makeOutput(x.shape, x.dtype);\n  // Short-circuit zero-sized tensors.\n  if (util.sizeFromShape(x.shape) === 0) {\n    return out;\n  }\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  wasmBatchNorm(\n      xId, meanId, varianceId, offsetId, scaleId, varianceEpsilon, outId);\n  return out;\n}\n\nexport const fusedBatchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: fusedBatchNorm as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, Tensor4D} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {FusableActivation} from './types';\n\nlet wasmFusedConv2d:\n    (xId: number, batchSize: number, inputHeight: number, inputWidth: number,\n     filterId: number, filterHeight: number, filterWidth: number,\n     biasId: number, padTop: number, padRight: number, padBottom: number,\n     padLeft: number, isSamePad: number, dilationHeight: number,\n     dilationWidth: number, strideHeight: number, strideWidth: number,\n     inputChannels: number, outputChannels: number, activation: number,\n     preluActivationWeightsId: number, leakyreluAlpha: number, outId: number) =>\n        void;\n\nfunction setup(backend: BackendWasm) {\n  wasmFusedConv2d = backend.wasm.cwrap(FusedConv2D, null /* void */, [\n    'number',  // xId\n    'number',  // batchSize\n    'number',  // inputHeight\n    'number',  // inputWidth\n    'number',  // filterId\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // biasId\n    'number',  // padTop\n    'number',  // padRight\n    'number',  // padBottom\n    'number',  // padLeft\n    'number',  // isSamePad\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // inputChannels\n    'number',  // outputChannels\n    'number',  // activation\n    'number',  // preluActivationWeightsId\n    'number',  // leakyreluAlpha\n    'number',  // outId\n  ]);\n}\n\nfunction fusedConv2d(args: {\n  inputs: FusedConv2DInputs,\n  backend: BackendWasm,\n  attrs: FusedConv2DAttrs\n}) {\n  const {inputs, attrs, backend} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dilations,\n    dataFormat,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      (x as Tensor4D).shape, (filter as Tensor4D).shape, strides, dilations,\n      pad, dimRoundingMode);\n\n  const fusedActivation =\n      FusableActivation[activation as unknown as\n                        keyof typeof FusableActivation];\n  if (fusedActivation == null) {\n    throw new Error(\n        `${activation} activation not yet supported for FusedConv2D ` +\n        `in the wasm backend.`);\n  }\n\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const filterId = backend.dataIdMap.get(filter.dataId).id;\n\n  const outputChannels = convInfo.outChannels;\n\n  let biasId = 0;\n  if (bias != null) {\n    const biasData = backend.dataIdMap.get(bias.dataId);\n    if (biasData.shape.length !== 1) {\n      throw new Error(\n          `FusedConv2D only supports rank-1 bias but got ` +\n          `rank ${biasData.shape.length}.`);\n    }\n    if (biasData.shape[0] !== outputChannels) {\n      throw new Error(\n          `FusedConv2D bias shape (${biasData.shape}) does not ` +\n          `match the number of output channels (${outputChannels})`);\n    }\n    biasId = biasData.id;\n  }\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padRight = convInfo.padInfo.right;\n  const padBottom = convInfo.padInfo.bottom;\n  const padLeft = convInfo.padInfo.left;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const inputChannels = convInfo.inChannels;\n  const isSamePad = convInfo.padInfo.type === 'SAME' ? 1 : 0;\n  const batchSize = convInfo.batchSize;\n  const inHeight = convInfo.inHeight;\n  const inWidth = convInfo.inWidth;\n\n  if (dataFormat !== 'NHWC') {\n    throw new Error(\n        `wasm backend FusedConv2D does not support dataFormat:'` +\n        `${dataFormat}'. Please use 'NHWC'.`);\n  }\n\n  const out = backend.makeOutput(convInfo.outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const preluActivationWeightsId = preluActivationWeights == null ?\n      0 :\n      backend.dataIdMap.get(preluActivationWeights.dataId).id;\n\n  wasmFusedConv2d(\n      xId, batchSize, inHeight, inWidth, filterId, filterHeight, filterWidth,\n      biasId, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight,\n      dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels,\n      fusedActivation, preluActivationWeightsId, leakyreluAlpha || 0, outId);\n\n  return out;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: fusedConv2d as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, Tensor4D} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {FusableActivation} from './types';\n\nlet wasmFusedDepthwiseConv2d:\n    (xId: number, batchSize: number, inputHeight: number, inputWidth: number,\n     filterId: number, filterHeight: number, filterWidth: number,\n     biasId: number, padTop: number, padRight: number, padBottom: number,\n     padLeft: number, isSamePad: number, dilationHeight: number,\n     dilationWidth: number, strideHeight: number, strideWidth: number,\n     inputChannels: number, outputChannels: number, activation: number,\n     preluActivationWeightsId: number, leakyreluAlpha: number, outId: number) =>\n        void;\n\nfunction setup(backend: BackendWasm) {\n  wasmFusedDepthwiseConv2d =\n      backend.wasm.cwrap(FusedDepthwiseConv2D, null /* void */, [\n        'number',  // xId\n        'number',  // batchSize\n        'number',  // inputHeight\n        'number',  // inputWidth\n        'number',  // filterId\n        'number',  // filterHeight\n        'number',  // filterWidth\n        'number',  // biasId\n        'number',  // padTop\n        'number',  // padRight\n        'number',  // padBottom\n        'number',  // padLeft\n        'number',  // isSamePad\n        'number',  // dilationHeight\n        'number',  // dilationWidth\n        'number',  // strideHeight\n        'number',  // strideWidth\n        'number',  // inputChannels\n        'number',  // outputChannels\n        'number',  // activation\n        'number',  // preluActivationWeightsId\n        'number',  // leakyreluAlpha\n        'number',  // outId\n      ]);\n}\n\nfunction fusedDepthwiseConv2d(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  backend: BackendWasm,\n  attrs: FusedDepthwiseConv2DAttrs\n}) {\n  const {inputs, attrs, backend} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dilations,\n    dataFormat,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      (x as Tensor4D).shape, (filter as Tensor4D).shape, strides, dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const fusedActivation =\n      FusableActivation[activation as unknown as\n                        keyof typeof FusableActivation];\n  if (fusedActivation == null) {\n    throw new Error(\n        `${activation} activation not yet supported for FusedDepthwiseConv2D ` +\n        `in the wasm backend.`);\n  }\n\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const filterId = backend.dataIdMap.get(filter.dataId).id;\n\n  const outputChannels = convInfo.outChannels;\n\n  let biasId = 0;\n  if (bias != null) {\n    const biasData = backend.dataIdMap.get(bias.dataId);\n    if (biasData.shape.length !== 1) {\n      throw new Error(\n          `FusedDepthwiseConv2D only supports rank-1 bias but got ` +\n          `rank ${biasData.shape.length}.`);\n    }\n    if (biasData.shape[0] !== outputChannels) {\n      throw new Error(\n          `FusedDepthwiseConv2D bias shape (${biasData.shape}) does not ` +\n          `match the number of output channels (${outputChannels})`);\n    }\n    biasId = biasData.id;\n  }\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padRight = convInfo.padInfo.right;\n  const padBottom = convInfo.padInfo.bottom;\n  const padLeft = convInfo.padInfo.left;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const inputChannels = convInfo.inChannels;\n  const isSamePad = convInfo.padInfo.type === 'SAME' ? 1 : 0;\n  const batchSize = convInfo.batchSize;\n  const inHeight = convInfo.inHeight;\n  const inWidth = convInfo.inWidth;\n\n  if (dataFormat !== 'NHWC') {\n    throw new Error(\n        `wasm backend FusedDepthwiseConv2D does not support dataFormat:'` +\n        `${dataFormat}'. Please use 'NHWC'.`);\n  }\n\n  const out = backend.makeOutput(convInfo.outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const preluActivationWeightsId = preluActivationWeights == null ?\n      0 :\n      backend.dataIdMap.get(preluActivationWeights.dataId).id;\n\n  wasmFusedDepthwiseConv2d(\n      xId, batchSize, inHeight, inWidth, filterId, filterHeight, filterWidth,\n      biasId, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight,\n      dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels,\n      fusedActivation, preluActivationWeightsId, leakyreluAlpha || 0, outId);\n\n  return out;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: fusedDepthwiseConv2d as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {gather_util, GatherNd, GatherNdInputs, KernelConfig, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmGatherNd: (\n    xId: number, dtype: CppDType, indicesId: number, numSlices: number,\n    sliceRank: number, sliceSize: number, strides: Uint8Array, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmGatherNd = backend.wasm.cwrap(GatherNd, null /*void*/, [\n    'number',  // xId\n    'number',  // dtype\n    'number',  // indicesId\n    'number',  // numSlices\n    'number',  // sliceRank\n    'number',  // sliceSize\n    'array',   // strides\n    'number'   // outId\n  ]);\n}\n\nfunction gatherNd(args: {backend: BackendWasm, inputs: GatherNdInputs}):\n    TensorInfo {\n  const {backend, inputs} = args;\n  const {params, indices} = inputs;\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      gather_util.prepareAndValidate(params, indices);\n\n  const out = backend.makeOutput(resultShape, params.dtype);\n  if (numSlices === 0) {\n    return out;\n  }\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n\n  const xData = backend.dataIdMap.get(params.dataId);\n  const xId = xData.id;\n  const indicesData = backend.dataIdMap.get(indices.dataId);\n  const indicesId = indicesData.id;\n\n  const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmGatherNd(\n      xId, CppDType[params.dtype], indicesId, numSlices, sliceRank, sliceSize,\n      stridesBytes, outId);\n\n  return out;\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: gatherNd\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {reshape} from './Reshape';\nimport {CppDType} from './types';\n\nlet wasmGather: (\n    xId: number, dtype: CppDType, xStrides: Uint8Array, stridesSize: number,\n    indicesId: number, batchSize: number, outStrides: Uint8Array,\n    outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmGather = backend.wasm.cwrap('Gather', null /*void*/, [\n    'number',  // xId\n    'number',  // dtype\n    'array',   // xStrides\n    'number',  // stridesSize\n    'number',  // indicesId\n    'number',  // batchSize\n    'array',   // outStrides\n    'number'   // outId\n  ]);\n}\n\nfunction gatherV2(\n    args: {backend: BackendWasm, inputs: GatherV2Inputs, attrs: GatherV2Attrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  // Throw error when any index is out of bound.\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n  const indicesVals = backend.readSync(indices.dataId) as TypedArray;\n  const axisDim = x.shape[parsedAxis];\n  for (let i = 0; i < indicesVals.length; ++i) {\n    const index = indicesVals[i];\n    util.assert(\n        index <= axisDim - 1 && index >= 0,\n        () =>\n            `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);\n  }\n\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x as Tensor, indices as Tensor, parsedAxis, batchDims);\n\n  const flattenX = reshape({\n    inputs: {x},\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    },\n    backend\n  });\n  const indicesSize = util.sizeFromShape(indices.shape);\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]},\n    backend\n  });\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  const out = backend.makeOutput(flattenOutputShape, x.dtype);\n  if (util.sizeFromShape(x.shape) === 0) {\n    return out;\n  }\n  const stridesSize = flattenX.shape.length - 1;\n\n  const xData = backend.dataIdMap.get(flattenX.dataId);\n  const xId = xData.id;\n\n  const indicesData = backend.dataIdMap.get(flattenIndex.dataId);\n  const indicesId = indicesData.id;\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const xStridesBytes = new Uint8Array(\n      new Int32Array(util.computeStrides(flattenX.shape)).buffer);\n  const outStridesBytes = new Uint8Array(\n      new Int32Array(util.computeStrides(flattenOutputShape)).buffer);\n\n  wasmGather(\n      xId, CppDType[x.dtype], xStridesBytes, stridesSize, indicesId,\n      shapeInfo.batchSize, outStridesBytes, outId);\n\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(flattenIndex.dataId);\n\n  // reshape\n  out.shape = shapeInfo.outputShape;\n  return out;\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: gatherV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = false;\nexport const greaterConfig: KernelConfig =\n    createBinaryKernelConfig(Greater, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = false;\nexport const greaterEqualConfig: KernelConfig =\n    createBinaryKernelConfig(GreaterEqual, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const isFiniteConfig: KernelConfig =\n    createUnaryKernelConfig(IsFinite, 'bool');\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const isInfConfig: KernelConfig = createUnaryKernelConfig(IsInf, 'bool');\n","/**\n * @license\n * Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const isNaNConfig: KernelConfig = createUnaryKernelConfig(IsNan, 'bool');\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmFunc: (\n    xId: number, dtype: number, leakyreluAlpha: number, outId: number) => void;\n\nfunction setupFunc(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(LeakyRelu, null /* void */, [\n    'number',  // x_id\n    'number',  // dtype\n    'number',  // leakyrelu_alpha\n    'number',  // out_id\n  ]);\n}\n\nexport function leakyRelu(\n    args:\n        {inputs: LeakyReluInputs, attrs: LeakyReluAttrs, backend: BackendWasm}):\n    TensorInfo {\n  const {inputs: {x}, attrs: {alpha}, backend} = args;\n\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  // According to TF API, LeakyRelu returns float32 when input is either float32\n  // or int32.\n  const out = backend.makeOutput(x.shape, 'float32');\n\n  if (util.sizeFromShape(x.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmFunc(xId, CppDType[x.dtype], alpha, outId);\n  }\n\n  return out;\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'wasm',\n  setupFunc,\n  kernelFunc: leakyRelu as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const lessConfig: KernelConfig =\n    createBinaryKernelConfig(Less, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const lessEqualConfig: KernelConfig =\n    createBinaryKernelConfig(LessEqual, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LinSpace, LinSpaceAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmLinSpace: (outId: number, start: number, stop: number, num: number) =>\n    void;\n\nfunction setup(backend: BackendWasm) {\n  wasmLinSpace = backend.wasm.cwrap(LinSpace, null, [\n    'number',  // outId\n    'number',  // start\n    'number',  // stop\n    'number',  // num\n  ]);\n}\n\nexport function linSpace(args: {attrs: LinSpaceAttrs, backend: BackendWasm}):\n    TensorInfo {\n  const {attrs, backend} = args;\n  const {start, stop, num} = attrs;\n\n  // TFJS Cpu backend supports num as a float and returns undetermined tensor in\n  // that case. However, according to TensorFlow spec, num should be a integer.\n  const numInt = Math.floor(num);\n\n  const out = backend.makeOutput([numInt], 'float32');\n  wasmLinSpace(backend.dataIdMap.get(out.dataId).id, start, stop, numInt);\n  return out;\n}\n\nexport const linSpaceConfig: KernelConfig = {\n  kernelName: LinSpace,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: linSpace as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const logConfig: KernelConfig = createUnaryKernelConfig(Log);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const log1pConfig: KernelConfig = createUnaryKernelConfig(Log1p);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const logicalAndConfig: KernelConfig =\n    createBinaryKernelConfig(LogicalAnd, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const logicalNotConfig: KernelConfig =\n  createUnaryKernelConfig(LogicalNot);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, LogicalOr} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const logicalOrConfig: KernelConfig =\n    createBinaryKernelConfig(LogicalOr, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, LogicalXor} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const logicalXorConfig: KernelConfig =\n    createBinaryKernelConfig(LogicalXor, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRN, LRNAttrs, LRNInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmLRN: (\n    xId: number, outId: number, channels: number, depthRadius: number,\n    bias: number, alpha: number, beta: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmLRN = backend.wasm.cwrap(LRN, null, [\n    'number',  // xId\n    'number',  // outId\n    'number',  // channels\n    'number',  // depthRadius\n    'number',  // bias\n    'number',  // alpha\n    'number',  // beta\n  ]);\n}\n\nexport function lrn(args: {\n  inputs: LRNInputs,\n  attrs: LRNAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  if (x.dtype !== 'float32') {\n    throw new Error('LRN error: x must have dtype float32');\n  }\n\n  const out = backend.makeOutput(x.shape, x.dtype);\n\n  wasmLRN(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(out.dataId).id,\n      /*channels=*/x.shape[3],\n      depthRadius,\n      bias,\n      alpha,\n      beta,\n  );\n  return out;\n}\n\nexport const lrnConfig: KernelConfig = {\n  kernelName: LRN,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: lrn as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmLRNGrad: (\n    xId: number, yId: number, dyId: number, dxId: number, channels: number,\n    depthRadius: number, bias: number, alpha: number, beta: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmLRNGrad = backend.wasm.cwrap(LRNGrad, null, [\n    'number',  // xId\n    'number',  // yId\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // channels\n    'number',  // depthRadius\n    'number',  // bias\n    'number',  // alpha\n    'number',  // beta\n  ]);\n}\n\nexport function lrnGrad(args: {\n  inputs: LRNGradInputs,\n  attrs: LRNGradAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  if (x.dtype !== 'float32' || y.dtype !== 'float32' ||\n      dy.dtype !== 'float32') {\n    throw new Error('LRNGrad error: x, y, and dy must have dtype float32');\n  }\n\n  const dx = backend.makeOutput(x.shape, x.dtype);\n\n  wasmLRNGrad(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(y.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      /*channels=*/dy.shape[3],\n      depthRadius,\n      bias,\n      alpha,\n      beta,\n  );\n  return dx;\n}\n\nexport const lrnGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: lrnGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\nimport {CppDType} from './types';\n\nlet wasmMax: (xId: number, dtype: number, reduceSize: number, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmMax = backend.wasm.cwrap(Max, null /*void*/, [\n    'number',  // x_id\n    'number',  // dtype\n    'number',  // reduce_size\n    'number',  // out_id\n  ]);\n}\n\nfunction max(args: {backend: BackendWasm, inputs: MaxInputs, attrs: MaxAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {reductionIndices: axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    input = transposed;\n    inputId = transposedId;\n  }\n\n  const inputRank = input.shape.length;\n  backend_util.assertAxesAreInnerMostDims('max', axes, inputRank);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, x.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmMax(inputId, CppDType[x.dtype], reduceSize, outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: max as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const maximumConfig: KernelConfig =\n    createBinaryKernelConfig(Maximum, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, Tensor4D, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmMaxPool: (\n    xId: number, batchSize: number, inputHeight: number, inputWidth: number,\n    filterHeight: number, filterWidth: number, padTop: number, padRight: number,\n    padBottom: number, padLeft: number, dilationHeight: number,\n    dilationWidth: number, strideHeight: number, strideWidth: number,\n    inputChannels: number, outputChannels: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMaxPool = backend.wasm.cwrap(MaxPool, null /* void */, [\n    'number',  // xId\n    'number',  // batchSize\n    'number',  // inputHeight\n    'number',  // inputWidth\n    'number',  // filterHeight\n    'number',  // filterWidth\n    'number',  // padTop\n    'number',  // padRight\n    'number',  // padBottom\n    'number',  // padLeft\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // inputChannels\n    'number',  // outputChannels\n    'number',  // outId\n  ]);\n}\n\nfunction maxPool(\n    args: {inputs: MaxPoolInputs, backend: BackendWasm, attrs: MaxPoolAttrs}) {\n  const {inputs, attrs, backend} = args;\n\n  const x = inputs.x as Tensor4D;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n\n  // TF API supports int32 input. CPU and WebGL backend also support int32\n  // input. WASM backend doesn't support it because it uses xnnpack which only\n  // supports float32.\n  //\n  // Add the following assert only for the WASM backend instead of at core op\n  // level.\n  //\n  // TODO: add support for int32 input.\n  util.assert(\n      x.dtype === 'float32',\n      () =>\n          `Error in MaxPool: only float32 input is supported. Got ${x.dtype}.`);\n\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padRight = convInfo.padInfo.right;\n  const padBottom = convInfo.padInfo.bottom;\n  const padLeft = convInfo.padInfo.left;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const inputChannels = convInfo.inChannels;\n  const outputChannels = convInfo.outChannels;\n\n  if (convInfo.dataFormat !== 'channelsLast') {\n    throw new Error(\n        `wasm backend does not support dataFormat:'` +\n        `${convInfo.dataFormat}'. Please use 'channelsLast'.`);\n  }\n\n  const out = backend.makeOutput(convInfo.outShape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  wasmMaxPool(\n      xId, x.shape[0], x.shape[1], x.shape[2], filterHeight, filterWidth,\n      padTop, padRight, padBottom, padLeft, dilationHeight, dilationWidth,\n      strideHeight, strideWidth, inputChannels, outputChannels, outId);\n  return out;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: maxPool as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmMaxPool3D: (\n    xId: number, outId: number, batchSize: number, channelSize: number,\n    inDepth: number, inHeight: number, inWidth: number, outDepth: number,\n    outHeight: number, outWidth: number, strideDepth: number,\n    strideHeight: number, strideWidth: number, dilationDepth: number,\n    dilationHeight: number, dilationWidth: number, effectiveFilterDepth: number,\n    effectiveFilterHeight: number, effectiveFilterWidth: number,\n    padFront: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMaxPool3D = backend.wasm.cwrap('MaxPool3D', null, [\n    'number',  // xId\n    'number',  // outId\n    'number',  // batchSize\n    'number',  // channelSize\n    'number',  // inDepth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outDepth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideDepth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationDepth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // effectiveFilterDepth\n    'number',  // effectiveFilterHeight\n    'number',  // effectiveFilterWidth\n    'number',  // padFront\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function maxPool3D(args: {\n  inputs: MaxPool3DInputs,\n  attrs: MaxPool3DAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      /*dilations=*/1, pad, dimRoundingMode, dataFormat);\n  const out = backend.makeOutput(convInfo.outShape, x.dtype);\n\n  wasmMaxPool3D(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(out.dataId).id,\n      convInfo.batchSize,\n      // Since Pool3D ops (AvgPool3D and MaxPool3D) support 3D filter only, in\n      // channels should always equal to out channels.\n      /*channelSize=*/convInfo.inChannels,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterDepth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return out;\n}\n\nexport const maxPool3DConfig: KernelConfig = {\n  kernelName: MaxPool3D,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: maxPool3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3DGrad, MaxPool3DGradAttrs, MaxPool3DGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmMaxPool3DGrad: (\n    xId: number, dyId: number, dxId: number, batchSize: number,\n    channelSize: number, inDepth: number, inHeight: number, inWidth: number,\n    outDepth: number, outHeight: number, outWidth: number, strideDepth: number,\n    strideHeight: number, strideWidth: number, dilationDepth: number,\n    dilationHeight: number, dilationWidth: number, effectiveFilterDepth: number,\n    effectiveFilterHeight: number, effectiveFilterWidth: number,\n    padFront: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMaxPool3DGrad = backend.wasm.cwrap('MaxPool3DGrad', null, [\n    'number',  // xId\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // batchSize\n    'number',  // channelSize\n    'number',  // inDepth\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outDepth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideDepth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationDepth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // effectiveFilterDepth\n    'number',  // effectiveFilterHeight\n    'number',  // effectiveFilterWidth\n    'number',  // padFront\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function maxPool3DGrad(args: {\n  inputs: MaxPool3DGradInputs,\n  attrs: MaxPool3DGradAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, /*dilations=*/1, pad, dimRoundingMode);\n  const dx = backend.makeOutput(input.shape, input.dtype);\n\n  wasmMaxPool3DGrad(\n      backend.dataIdMap.get(input.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      convInfo.batchSize,\n      // Since Pool3D ops (MaxPool3D and MaxPool3D) support 3D filter only, in\n      // channels should always equal to out channels.\n      /*channelSize=*/convInfo.inChannels,\n      convInfo.inDepth,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outDepth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideDepth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationDepth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterDepth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.front,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return dx;\n}\n\nexport const maxPool3DGradConfig: KernelConfig = {\n  kernelName: MaxPool3DGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: maxPool3DGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPoolGrad, MaxPoolGradAttrs, MaxPoolGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmMaxPoolGrad: (\n    xId: number, dyId: number, dxId: number, batchSize: number,\n    channelSize: number, inHeight: number, inWidth: number, outHeight: number,\n    outWidth: number, strideHeight: number, strideWidth: number,\n    dilationHeight: number, dilationWidth: number,\n    effectiveFilterHeight: number, effectiveFilterWidth: number, padTop: number,\n    padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMaxPoolGrad = backend.wasm.cwrap('MaxPoolGrad', null, [\n    'number',  // xId\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // batchSize\n    'number',  // channelSize\n    'number',  // inHeight\n    'number',  // inWidth\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // strideHeight\n    'number',  // strideWidth\n    'number',  // dilationHeight\n    'number',  // dilationWidth\n    'number',  // effectiveFilterHeight\n    'number',  // effectiveFilterWidth\n    'number',  // padTop\n    'number',  // padLeft\n  ]);\n}\n\nexport function maxPoolGrad(args: {\n  inputs: MaxPoolGradInputs,\n  attrs: MaxPoolGradAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      input.shape as [number, number, number, number], filterSize, strides,\n      /*dilations=*/1, pad, dimRoundingMode);\n  const dx = backend.makeOutput(input.shape, input.dtype);\n\n  wasmMaxPoolGrad(\n      backend.dataIdMap.get(input.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      convInfo.batchSize,\n      // Since Pool ops (MaxPool and MaxPool) support 2D filter only, in\n      // channels should always equal to out channels.\n      /*channelSize=*/convInfo.inChannels,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return dx;\n}\n\nexport const maxPoolGradConfig: KernelConfig = {\n  kernelName: MaxPoolGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: maxPoolGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmMaxPoolWithArgmax: (\n    xId: number, pooledId: number, indexesId: number, dtype: number,\n    includeBatchIndex: boolean, batchSize: number, channelSize: number,\n    inHeight: number, inWidth: number, outHeight: number, outWidth: number,\n    strideHeight: number, strideWidth: number, dilationHeight: number,\n    dilationWidth: number, effectiveFilterHeight: number,\n    effectiveFilterWidth: number, padTop: number, padLeft: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMaxPoolWithArgmax = backend.wasm.cwrap('MaxPoolWithArgmax', null, [\n    'number',   // xId\n    'number',   // pooledId\n    'number',   // indexesId\n    'number',   // dtype\n    'boolean',  // includeBatchIndex\n    'number',   // batchSize\n    'number',   // channelSize\n    'number',   // inHeight\n    'number',   // inWidth\n    'number',   // outHeight\n    'number',   // outWidth\n    'number',   // strideHeight\n    'number',   // strideWidth\n    'number',   // dilationHeight\n    'number',   // dilationWidth\n    'number',   // effectiveFilterHeight\n    'number',   // effectiveFilterWidth\n    'number',   // padTop\n    'number',   // padLeft\n  ]);\n}\n\nexport function maxPoolWithArgmax(args: {\n  inputs: MaxPoolWithArgmaxInputs,\n  attrs: MaxPoolWithArgmaxAttrs,\n  backend: BackendWasm,\n}): TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, includeBatchInIndex} = attrs;\n\n  util.assert(\n      x.shape.length === 4,\n      () => `Error in maxPool: input must be rank 4 but got rank ${\n          x.shape.length}.`);\n  const dilations: [number, number] = [1, 1];\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides, [1, 1],\n      pad);\n\n  const pooled = backend.makeOutput(convInfo.outShape, x.dtype);\n  const indexes = backend.makeOutput(convInfo.outShape, 'int32');\n\n  wasmMaxPoolWithArgmax(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(pooled.dataId).id,\n      backend.dataIdMap.get(indexes.dataId).id,\n      CppDType[x.dtype],\n      includeBatchInIndex,\n      convInfo.batchSize,\n      convInfo.inChannels,\n      convInfo.inHeight,\n      convInfo.inWidth,\n      convInfo.outHeight,\n      convInfo.outWidth,\n      convInfo.strideHeight,\n      convInfo.strideWidth,\n      convInfo.dilationHeight,\n      convInfo.dilationWidth,\n      convInfo.effectiveFilterHeight,\n      convInfo.effectiveFilterWidth,\n      convInfo.padInfo.top,\n      convInfo.padInfo.left,\n  );\n  return [pooled, indexes];\n}\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: maxPoolWithArgmax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {cast} from './Cast';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\n\nlet wasmMean: (xId: number, reduceSize: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmMean =\n      backend.wasm.cwrap(Mean, null /*void*/, ['number, number, number']);\n}\n\nexport function mean(\n    args: {backend: BackendWasm, inputs: MeanInputs, attrs: MeanAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  let reductionAxes = axes;\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    if (transposedId !== xId) {\n      // transpose was not a no-op. We will need to dispose of this\n      // once we are done.\n      input = transposed;\n      inputId = transposedId;\n      reductionAxes = backend_util.getInnerMostAxes(\n          reductionAxes.length, input.shape.length);\n    }\n  }\n\n  backend_util.assertAxesAreInnerMostDims(\n      'mean', reductionAxes, input.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, reductionAxes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  let castedInput = input;\n  if (input.dtype !== 'float32') {\n    castedInput =\n        cast({backend, inputs: {x: input}, attrs: {dtype: 'float32'}});\n    inputId = backend.dataIdMap.get(castedInput.dataId).id;\n  }\n\n  const out = backend.makeOutput(outShape, 'float32');\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmMean(inputId, reduceSize, outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  if (input.dtype !== 'float32') {\n    backend.disposeData(castedInput.dataId);\n  }\n\n  return out;\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: mean as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\nimport {CppDType} from './types';\n\nlet wasmMin: (xId: number, dtype: number, reduceSize: number, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmMin = backend.wasm.cwrap(Min, null /*void*/, [\n    'number',  // x_id\n    'number',  // dtype\n    'number',  // reduce_size\n    'number',  // out_id\n  ]);\n}\n\nfunction min(args: {backend: BackendWasm, inputs: MinInputs, attrs: MinAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    if (transposedId !== xId) {\n      // transpose was not a no-op. We will need to dispose of this\n      // once we are done.\n      input = transposed;\n      inputId = transposedId;\n    }\n  }\n\n  const inputRank = input.shape.length;\n\n  backend_util.assertAxesAreInnerMostDims('min', axes, inputRank);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, input.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmMin(inputId, CppDType[x.dtype], reduceSize, outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: min as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const minimumConfig: KernelConfig =\n    createBinaryKernelConfig(Minimum, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, MirrorPad, MirrorPadAttrs, MirrorPadInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\n// Must match enum in MirrorPad.cc\nenum MirrorPaddingMode {\n  reflect = 0,\n  symmetric = 1\n}\n\nlet wasmMirrorPad: (\n    xId: number, xShapeBytes: Uint8Array, xShapeLength: number, xDtype: number,\n    prePaddingsBytes: Uint8Array, postPaddingsBytes: Uint8Array, mode: number,\n    outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMirrorPad = backend.wasm.cwrap(MirrorPad, null /* void */, [\n    'number',  // xId\n    'array',   // x.shape\n    'number',  // x.shape.length\n    'number',  // x.dtype\n    'array',   // pre-paddings\n    'array',   // post-paddings\n    'number',  // mode\n    'number',  // outId\n  ]);\n}\n\nfunction mirrorPad(args: {\n  inputs: MirrorPadInputs,\n  backend: BackendWasm,\n  attrs: MirrorPadAttrs\n}) {\n  const {inputs: {x}, backend, attrs: {paddings, mode}} = args;\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const out = backend.makeOutput(outShape, x.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n\n  const prePaddingsFlat = paddings.map(padTuple => padTuple[0]);\n  const postPaddingsFlat = paddings.map(padTuple => padTuple[1]);\n  const prePaddingsBytes =\n      new Uint8Array(new Int32Array(prePaddingsFlat).buffer);\n  const postPaddingsBytes =\n      new Uint8Array(new Int32Array(postPaddingsFlat).buffer);\n\n  wasmMirrorPad(\n      xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes,\n      postPaddingsBytes, MirrorPaddingMode[mode], outId);\n  return out;\n}\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'wasm',\n  kernelFunc: mirrorPad as unknown as KernelFunc,\n  setupFunc: setup\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmFunc: (xId: number, outId: number, channels: number, batch: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(Softmax, null /* void */, [\n    'number',  // xId\n    'number',  // outId\n    'number',  // channels\n    'number'   // batch\n  ]);\n}\n\nexport function softmax(\n    args: {backend: BackendWasm, inputs: SoftmaxInputs, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {backend, inputs: {logits}, attrs: {dim}} = args;\n  const xId = backend.dataIdMap.get(logits.dataId).id;\n  const out = backend.makeOutput(logits.shape, logits.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const channels = logits.shape[dim];\n  const batch = util.sizeFromShape(logits.shape) / channels;\n\n  // Short-circuit zero-sized tensors.\n  if (util.sizeFromShape(out.shape) === 0) {\n    return out;\n  }\n\n  wasmFunc(xId, outId, channels, batch);\n  return out;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: softmax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Multinomial, MultinomialAttrs, MultinomialInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {softmax} from './Softmax';\n\nlet wasmMultinomial: (\n    probabilitiesId: number, batchSize: number, numEvents: number,\n    numSamples: number, seed: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmMultinomial = backend.wasm.cwrap(Multinomial, null, [\n    'number',  // probabilitiesId\n    'number',  // batchSize\n    'number',  // numEvents\n    'number',  // numSamples\n    'number',  // seed\n    'number',  // outId\n  ]);\n}\n\nexport function multinomial(args: {\n  inputs: MultinomialInputs,\n  attrs: MultinomialAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {numSamples, seed, normalized} = attrs;\n\n  if (logits.dtype !== 'float32') {\n    throw new Error(\n        `Tensor logits must have dtype float32, got ${logits.dtype}`);\n  }\n\n  const probabilities = normalized ? logits : softmax({\n    inputs: {logits},\n    backend,\n    attrs: {dim: logits.shape.length - 1},\n  });\n\n  const [batchSize, numEvents] = probabilities.shape;\n  const out = backend.makeOutput([batchSize, numSamples], 'int32');\n\n  wasmMultinomial(\n      backend.dataIdMap.get(probabilities.dataId).id,\n      batchSize,\n      numEvents,\n      numSamples,\n      seed,\n      backend.dataIdMap.get(out.dataId).id,\n  );\n  if (!normalized) {\n    backend.disposeData(probabilities.dataId);\n  }\n  return out;\n}\n\nexport const multinomialConfig: KernelConfig = {\n  kernelName: Multinomial,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: multinomial as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Mod} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nexport const modConfig: KernelConfig =\n    createBinaryKernelConfig(Mod, /*supportsFullBroadcast=*/true);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = true;\nexport const multiplyConfig: KernelConfig =\n    createBinaryKernelConfig(Multiply, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Neg} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const negConfig: KernelConfig = createUnaryKernelConfig(Neg);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendWasm} from '../backend_wasm';\n\n// Analogous to `struct Result` in `non_max_suppression_impl.h`.\ninterface Result {\n  pSelectedIndices: number;\n  selectedSize: number;\n  pSelectedScores: number;\n  pValidOutputs: number;\n}\n/**\n * Parse the result of the c++ method, which has the shape equivalent to\n * `Result`.\n */\nexport function parseResultStruct(\n    backend: BackendWasm, resOffset: number): Result {\n  const result = new Int32Array(backend.wasm.HEAPU8.buffer, resOffset, 4);\n  const pSelectedIndices = result[0];\n  const selectedSize = result[1];\n  const pSelectedScores = result[2];\n  const pValidOutputs = result[3];\n  // Since the result was allocated on the heap, we have to delete it.\n  backend.wasm._free(resOffset);\n  return {pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {parseResultStruct} from './NonMaxSuppression_util';\n\nlet wasmFunc: (\n    boxesId: number, scoresId: number, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number) => number;\n\nfunction setup(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(\n      NonMaxSuppressionV3,\n      'number',  // Result*\n      [\n        'number',  // boxesId\n        'number',  // scoresId\n        'number',  // maxOutputSize\n        'number',  // iouThreshold\n        'number',  // scoreThreshold\n      ]);\n}\n\nfunction kernelFunc(args: {\n  backend: BackendWasm,\n  inputs: NonMaxSuppressionV3Inputs,\n  attrs: NonMaxSuppressionV3Attrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {iouThreshold, maxOutputSize, scoreThreshold} = attrs;\n  const {boxes, scores} = inputs;\n\n  const boxesId = backend.dataIdMap.get(boxes.dataId).id;\n  const scoresId = backend.dataIdMap.get(scores.dataId).id;\n\n  const resOffset =\n      wasmFunc(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold);\n\n  const {pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs} =\n      parseResultStruct(backend, resOffset);\n\n  // Since we are not using scores for V3, we have to delete it from the heap.\n  backend.wasm._free(pSelectedScores);\n  backend.wasm._free(pValidOutputs);\n\n  const selectedIndicesTensor =\n      backend.makeOutput([selectedSize], 'int32', pSelectedIndices);\n\n  return selectedIndicesTensor;\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: kernelFunc as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {parseResultStruct} from './NonMaxSuppression_util';\n\nlet wasmFunc: (\n    boxesId: number, scoresId: number, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number,\n    padToMaxOutputSize: boolean) => number;\n\nfunction setup(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(\n      NonMaxSuppressionV4,\n      'number',  // Result*\n      [\n        'number',  // boxesId\n        'number',  // scoresId\n        'number',  // maxOutputSize\n        'number',  // iouThreshold\n        'number',  // scoreThreshold\n        'bool',    // padToMaxOutputSize\n      ]);\n}\n\nfunction nonMaxSuppressionV4(args: {\n  backend: BackendWasm,\n  inputs: NonMaxSuppressionV4Inputs,\n  attrs: NonMaxSuppressionV4Attrs\n}): TensorInfo[] {\n  const {backend, inputs, attrs} = args;\n  const {iouThreshold, maxOutputSize, scoreThreshold, padToMaxOutputSize} =\n      attrs;\n  const {boxes, scores} = inputs;\n\n  const boxesId = backend.dataIdMap.get(boxes.dataId).id;\n  const scoresId = backend.dataIdMap.get(scores.dataId).id;\n\n  const resOffset = wasmFunc(\n      boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold,\n      padToMaxOutputSize);\n\n  const {pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs} =\n      parseResultStruct(backend, resOffset);\n\n  // Since we are not using scores for V4, we have to delete it from the heap.\n  backend.wasm._free(pSelectedScores);\n\n  const selectedIndicesTensor =\n      backend.makeOutput([selectedSize], 'int32', pSelectedIndices);\n\n  const validOutputsTensor = backend.makeOutput([], 'int32', pValidOutputs);\n\n  return [selectedIndicesTensor, validOutputsTensor];\n}\n\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: nonMaxSuppressionV4 as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {parseResultStruct} from './NonMaxSuppression_util';\n\nlet wasmFunc:\n    (boxesId: number, scoresId: number, maxOutputSize: number,\n     iouThreshold: number, scoreThreshold: number, softNmsSigma: number) =>\n        number;\n\nfunction setup(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(\n      NonMaxSuppressionV5,\n      'number',  // Result*\n      [\n        'number',  // boxesId\n        'number',  // scoresId\n        'number',  // maxOutputSize\n        'number',  // iouThreshold\n        'number',  // scoreThreshold\n        'number',  // softNmsSigma\n      ]);\n}\n\nfunction kernelFunc(args: {\n  backend: BackendWasm,\n  inputs: NonMaxSuppressionV5Inputs,\n  attrs: NonMaxSuppressionV5Attrs\n}): TensorInfo[] {\n  const {backend, inputs, attrs} = args;\n  const {iouThreshold, maxOutputSize, scoreThreshold, softNmsSigma} = attrs;\n  const {boxes, scores} = inputs;\n\n  const boxesId = backend.dataIdMap.get(boxes.dataId).id;\n  const scoresId = backend.dataIdMap.get(scores.dataId).id;\n\n  const resOffset = wasmFunc(\n      boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold,\n      softNmsSigma);\n\n  const {pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs} =\n      parseResultStruct(backend, resOffset);\n\n  // Since we are not using validOutputs for V5, we have to delete it from the\n  // heap.\n  backend.wasm._free(pValidOutputs);\n\n  const selectedIndicesTensor =\n      backend.makeOutput([selectedSize], 'int32', pSelectedIndices);\n  const selectedScoresTensor =\n      backend.makeOutput([selectedSize], 'float32', pSelectedScores);\n\n  return [selectedIndicesTensor, selectedScoresTensor];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: kernelFunc as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const notEqualConfig: KernelConfig =\n    createBinaryKernelConfig(NotEqual, supportsFullBroadcast, 'bool');\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OneHot, OneHotAttrs, OneHotInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmOneHot: (\n    indicesId: number, depth: number, onValue: number, offValue: number,\n    outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmOneHot = backend.wasm.cwrap(OneHot, null /* void */, [\n    'number',  // indices_id\n    'number',  // depth,\n    'number',  // onValue\n    'number',  // offValue\n    'number'   // out_id\n  ]);\n}\n\nfunction oneHot(\n    args: {inputs: OneHotInputs, attrs: OneHotAttrs, backend: BackendWasm}) {\n  const {inputs, backend, attrs} = args;\n  const {indices} = inputs;\n  const {dtype, depth, onValue, offValue} = attrs;\n\n  const out = backend.makeOutput([...indices.shape, depth], dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const indicesData = backend.dataIdMap.get(indices.dataId);\n  const indicesId = indicesData.id;\n\n  wasmOneHot(indicesId, depth, onValue, offValue, outId);\n\n  return out;\n}\n\nexport const oneHotConfig: KernelConfig = {\n  kernelName: OneHot,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: oneHot as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nfunction onesLike(args: {inputs: OnesLikeInputs, backend: BackendWasm}) {\n  const {inputs: {x}, backend} = args;\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const outVals = backend.typedArrayFromHeap(out);\n  outVals.fill(1);\n  return out;\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'wasm',\n  kernelFunc: onesLike as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\nimport {BackendWasm} from '../backend_wasm';\n\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: BackendWasm, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'wasm',\n  kernelFunc: pack as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, PadV2, PadV2Attrs, PadV2Inputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {fill} from './Fill';\n\nimport {CppDType} from './types';\n\nlet wasmPadV2: (\n    xId: number, xShapeBytes: Uint8Array, xShapeLength: number, xDtype: number,\n    prePaddingsBytes: Uint8Array, postPaddingsBytes: Uint8Array,\n    constantValue: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmPadV2 = backend.wasm.cwrap(PadV2, null /* void */, [\n    'number',  // xId\n    'array',   // x.shape\n    'number',  // x.shape.length\n    'number',  // x.dtype\n    'array',   // pre-paddings\n    'array',   // post-paddings\n    'number',  // constantValue\n    'number',  // outId\n  ]);\n}\n\nfunction pad(\n    args: {inputs: PadV2Inputs, backend: BackendWasm, attrs: PadV2Attrs}) {\n  const {inputs: {x}, backend, attrs: {paddings, constantValue}} = args;\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  if (util.sizeFromShape(x.shape) === 0) {\n    // Short-circuit the computation, since x doesn't have value, only\n    // the shape is used to compute output shape to pad.\n    return fill({\n      backend,\n      attrs: {shape: outShape, value: constantValue, dtype: x.dtype}\n    });\n  }\n\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const out = backend.makeOutput(outShape, x.dtype);\n  const outTensorData = backend.dataIdMap.get(out.dataId);\n  const outId = outTensorData.id;\n\n  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n\n  const prePaddingsFlat = paddings.map(padTuple => padTuple[0]);\n  const postPaddingsFlat = paddings.map(padTuple => padTuple[1]);\n  const prePaddingsBytes =\n      new Uint8Array(new Int32Array(prePaddingsFlat).buffer);\n  const postPaddingsBytes =\n      new Uint8Array(new Int32Array(postPaddingsFlat).buffer);\n\n  wasmPadV2(\n      xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes,\n      postPaddingsBytes, constantValue, outId);\n  return out;\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'wasm',\n  kernelFunc: pad as unknown as KernelFunc,\n  setupFunc: setup\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = false;\nexport const powConfig: KernelConfig =\n    createBinaryKernelConfig(Pow, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prelu, PreluInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {cast} from './Cast';\n\nlet wasmPrelu: (xId: number, weightsId: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmPrelu = backend.wasm.cwrap(Prelu, null /* void */, [\n    'number',  // x_id\n    'number',  // weights_id\n    'number'   // out_id\n  ]);\n}\n\nfunction prelu(args: {inputs: PreluInputs, backend: BackendWasm}) {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const weightsId = backend.dataIdMap.get(alpha.dataId).id;\n\n  let inputId = xId;\n  const input = x;\n  let castedInput = input;\n  if (input.dtype !== 'float32') {\n    castedInput = cast({backend, inputs: {x}, attrs: {dtype: 'float32'}});\n    inputId = backend.dataIdMap.get(castedInput.dataId).id;\n  }\n\n  const out = backend.makeOutput(x.shape, 'float32');\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmPrelu(inputId, weightsId, outId);\n\n  if (input.dtype !== 'float32') {\n    backend.disposeData(castedInput.dataId);\n  }\n  return out;\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: prelu as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\n\nimport {CppDType} from './types';\n\nlet wasmProd: (\n    xId: number, reduceSize: number,\n    dtype: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmProd = backend.wasm.cwrap(Prod, null /*void*/, [\n    'number',\n    'number',\n    'number',\n    'number'\n  ]);\n}\n\nfunction prod(args: {\n  backend: BackendWasm,\n  inputs: ProdInputs,\n  attrs: ProdAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  let reductionAxes = axes;\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    if (transposedId !== xId) {\n      // transpose was not a no-op. We will need to dispose of this\n      // once we are done.\n      input = transposed;\n      inputId = transposedId;\n      reductionAxes = backend_util.getInnerMostAxes(\n          reductionAxes.length, input.shape.length);\n    }\n  }\n\n  backend_util.assertAxesAreInnerMostDims(\n      'prod', reductionAxes, input.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, reductionAxes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, input.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmProd(inputId, reduceSize, CppDType[out.dtype], outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: prod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {rangeImplCPU} from '../kernel_utils/shared';\n\nexport const range =\n    (args: {backend: BackendWasm, attrs: RangeAttrs}): TensorInfo => {\n      const {backend, attrs} = args;\n      const {start, stop, step, dtype} = attrs;\n      const values = rangeImplCPU(start, stop, step, dtype);\n\n      const out = backend.makeOutput([values.length], dtype);\n      const outVals = backend.typedArrayFromHeap(out);\n      outVals.set(values);\n      return out;\n    };\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'wasm',\n  kernelFunc: range as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataTypeMap, util} from '@tensorflow/tfjs-core';\n\nexport function rangeImpl(\n    start: number, stop: number, step: number,\n    dtype: 'float32'|'int32'): DataTypeMap['float32' | 'int32'] {\n  const sameStartStop = start === stop;\n  const increasingRangeNegativeStep = start < stop && step < 0;\n  const decreasingRangePositiveStep = stop < start && step > 1;\n\n  if (sameStartStop || increasingRangeNegativeStep ||\n      decreasingRangePositiveStep) {\n    return util.makeZerosTypedArray(0, dtype);\n  }\n\n  const numElements = Math.abs(Math.ceil((stop - start) / step));\n  const values = util.makeZerosTypedArray(numElements, dtype);\n\n  if (stop < start && step === 1) {\n    // Auto adjust the step's sign if it hasn't been set\n    // (or was set to 1)\n    step = -1;\n  }\n\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n  return values;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {createBinaryKernelConfig} from './binary_kernel';\n\nconst supportsFullBroadcast = true;\nexport const realDivConfig: KernelConfig =\n    createBinaryKernelConfig(RealDiv, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const reciprocalConfig: KernelConfig =\n    createUnaryKernelConfig(Reciprocal);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const reluConfig: KernelConfig = createUnaryKernelConfig(Relu);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const relu6Config: KernelConfig = createUnaryKernelConfig(Relu6);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {cast} from './Cast';\n\nlet wasmResizeBilinear: (\n    xId: number, batch: number, oldHeight: number, oldWidth: number,\n    numChannels: number, newHeight: number, newWidth: number,\n    alignCorners: number, halfPixelCenters: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmResizeBilinear = backend.wasm.cwrap(ResizeBilinear, null /*void*/, [\n    'number',  // xId\n    'number',  // batch\n    'number',  // oldHeight\n    'number',  // oldWidth\n    'number',  // numChannels\n    'number',  // newHeight\n    'number',  // newWidth\n    'number',  // alignCorners\n    'number',  // halfPixelCenters\n    'number'   // outId\n  ]);\n}\n\nfunction resizeBilinear(args: {\n  backend: BackendWasm,\n  inputs: ResizeBilinearInputs,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const outShape = [batch, newHeight, newWidth, numChannels];\n\n  let xData = backend.dataIdMap.get(images.dataId);\n  let castedData;\n  if (xData.dtype !== 'float32') {\n    castedData =\n        cast({backend, inputs: {x: images}, attrs: {dtype: 'float32'}});\n    xData = backend.dataIdMap.get(castedData.dataId);\n  }\n  const xId = xData.id;\n\n  const out = backend.makeOutput(outShape, 'float32');\n  if (util.sizeFromShape(images.shape) === 0) {\n    return out;\n  }\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  wasmResizeBilinear(\n      xId, batch, oldHeight, oldWidth, numChannels, newHeight, newWidth,\n      alignCorners ? 1 : 0, halfPixelCenters ? 1 : 0, outId);\n\n  if (castedData != null) {\n    backend.disposeData(castedData.dataId);\n  }\n\n  return out;\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: resizeBilinear as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinearGrad, ResizeBilinearGradAttrs, ResizeBilinearGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {cast} from './Cast';\n\nlet wasmResizeBilinearGrad: (\n    imagesId: number, dyId: number, dxId: number, imagesShape: Uint8Array,\n    dyShape: Uint8Array, alignCorners: boolean) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmResizeBilinearGrad = backend.wasm.cwrap(\n      ResizeBilinearGrad, null /*void*/,\n      [\n        'number',   // imagesId\n        'number',   // dyId\n        'number',   // dxId\n        'array',    // imagesShape\n        'array',    // dyShape\n        'boolean',  // alignCorners\n      ]);\n}\n\nfunction resizeBilinearGrad(args: {\n  backend: BackendWasm; inputs: ResizeBilinearGradInputs;\n  attrs: ResizeBilinearGradAttrs;\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  const dx = backend.makeOutput(images.shape, 'float32');\n\n  let xData = backend.dataIdMap.get(images.dataId);\n  let castedData;\n  if (xData.dtype !== 'float32') {\n    castedData = cast({\n      backend,\n      inputs: {x: images},\n      attrs: {dtype: 'float32'},\n    });\n    xData = backend.dataIdMap.get(castedData.dataId);\n  }\n\n  wasmResizeBilinearGrad(\n      backend.dataIdMap.get(images.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      new Uint8Array(new Int32Array(images.shape).buffer),\n      new Uint8Array(new Int32Array(dy.shape).buffer),\n      alignCorners,\n  );\n\n  if (castedData != null) {\n    backend.disposeData(castedData.dataId);\n  }\n\n  return dx;\n}\n\nexport const resizeBilinearGradConfig: KernelConfig = {\n  kernelName: ResizeBilinearGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: resizeBilinearGrad as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {\n  KernelConfig,\n  KernelFunc,\n  ResizeNearestNeighbor,\n  ResizeNearestNeighborAttrs,\n  ResizeNearestNeighborInputs,\n  TensorInfo,\n  util,\n} from '@tensorflow/tfjs-core';\n\nimport { BackendWasm } from '../backend_wasm';\n\nimport { cast } from './Cast';\n\nlet wasmResizeNearestNeighbor: (\n  xId: number,\n  batch: number,\n  oldHeight: number,\n  oldWidth: number,\n  numChannels: number,\n  newHeight: number,\n  newWidth: number,\n  alignCorners: number,\n  halfPixelCenters: number,\n  outId: number\n) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmResizeNearestNeighbor = backend.wasm.cwrap(\n    ResizeNearestNeighbor,\n    null /*void*/,\n    [\n      'number', // xId\n      'number', // batch\n      'number', // oldHeight\n      'number', // oldWidth\n      'number', // numChannels\n      'number', // newHeight\n      'number', // newWidth\n      'number', // alignCorners\n      'number', // halfPixelCenters\n      'number', // outId\n    ]\n  );\n}\n\nfunction resizeNearestNeighbor(args: {\n  backend: BackendWasm;\n  inputs: ResizeNearestNeighborInputs;\n  attrs: ResizeNearestNeighborAttrs;\n}): TensorInfo {\n  const { backend, inputs, attrs } = args;\n  const { images } = inputs;\n  const { alignCorners, halfPixelCenters, size } = attrs;\n\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const outShape = [batch, newHeight, newWidth, numChannels];\n\n  const out = backend.makeOutput(outShape, 'float32');\n  if (util.sizeFromShape(images.shape) === 0) {\n    return out;\n  }\n\n  let xData = backend.dataIdMap.get(images.dataId);\n  let castedData;\n  if (xData.dtype !== 'float32') {\n    castedData = cast({\n      backend,\n      inputs: { x: images },\n      attrs: { dtype: 'float32' },\n    });\n    xData = backend.dataIdMap.get(castedData.dataId);\n  }\n\n  const xId = xData.id;\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  wasmResizeNearestNeighbor(\n    xId,\n    batch,\n    oldHeight,\n    oldWidth,\n    numChannels,\n    newHeight,\n    newWidth,\n    alignCorners ? 1 : 0,\n    halfPixelCenters ? 1 : 0,\n    outId\n  );\n\n  if (castedData != null) {\n    backend.disposeData(castedData.dataId);\n  }\n\n  return out;\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: resizeNearestNeighbor as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighborGrad, ResizeNearestNeighborGradAttrs, ResizeNearestNeighborGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {cast} from './Cast';\n\nlet wasmResizeNearestNeighborGrad: (\n    imagesId: number, dyId: number, dxId: number, imagesShape: Uint8Array,\n    dyShape: Uint8Array, alignCorners: boolean) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmResizeNearestNeighborGrad = backend.wasm.cwrap(\n      ResizeNearestNeighborGrad, null /*void*/,\n      [\n        'number',   // imagesId\n        'number',   // dyId\n        'number',   // dxId\n        'array',    // imagesShape\n        'array',    // dyShape\n        'boolean',  // alignCorners\n      ]);\n}\n\nfunction resizeNearestNeighborGrad(args: {\n  backend: BackendWasm; inputs: ResizeNearestNeighborGradInputs;\n  attrs: ResizeNearestNeighborGradAttrs;\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  const dx = backend.makeOutput(images.shape, 'float32');\n\n  let xData = backend.dataIdMap.get(images.dataId);\n  let castedData;\n  if (xData.dtype !== 'float32') {\n    castedData = cast({\n      backend,\n      inputs: {x: images},\n      attrs: {dtype: 'float32'},\n    });\n    xData = backend.dataIdMap.get(castedData.dataId);\n  }\n\n  wasmResizeNearestNeighborGrad(\n      backend.dataIdMap.get(images.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      new Uint8Array(new Int32Array(images.shape).buffer),\n      new Uint8Array(new Int32Array(dy.shape).buffer),\n      alignCorners,\n  );\n\n  if (castedData != null) {\n    backend.disposeData(castedData.dataId);\n  }\n\n  return dx;\n}\n\nexport const resizeNearestNeighborGradConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighborGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: resizeNearestNeighborGrad as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reverse, ReverseAttrs, ReverseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\n\nlet wasmReverse: (\n    xId: number, axes: Uint8Array, axesLength: number, outShape: Uint8Array,\n    outShapeLength: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmReverse = backend.wasm.cwrap(Reverse, null, [\n    'number',  // x_id\n    'array',   // axes\n    'number',  // axes_length\n    'array',   // out_shape\n    'number',  // out_shape_length\n    'number'   // out_id\n  ]);\n}\n\nexport function reverse(\n    args: {inputs: ReverseInputs, backend: BackendWasm, attrs: ReverseAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dims} = attrs;\n\n  const axes = util.parseAxisParam(dims, x.shape);\n\n  if (x.shape.length === 0) {\n    return identity({inputs: {x}, backend});\n  }\n\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const axesBytes = new Uint8Array(new Int32Array(axes).buffer);\n  const outShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n\n  wasmReverse(\n      xId, axesBytes, axes.length, outShapeBytes, x.shape.length, outId);\n\n  const reshaped =\n      reshape({inputs: {x: out}, attrs: {shape: x.shape}, backend});\n\n  backend.disposeData(out.dataId);\n  return reshaped;\n}\n\nexport const reverseConfig: KernelConfig = {\n  kernelName: Reverse,\n  backendName: 'wasm',\n  kernelFunc: reverse as unknown as KernelFunc,\n  setupFunc: setup\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmRotate: (\n    xId: number, batch: number, imageHeight: number, imageWidth: number,\n    numChannels: number, radians: number, centerX: number, centerY: number,\n    fillBytes: Uint8Array, fillLength: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmRotate = backend.wasm.cwrap(RotateWithOffset, null /* void */, [\n    'number',  // xId\n    'number',  // batch\n    'number',  // imageHeight\n    'number',  // imageWidth\n    'number',  // numChannels\n    'number',  // radians\n    'number',  // centerX\n    'number',  // centerY\n    'array',   // fillBytes\n    'number',  // fillLength\n    'number',  // outId\n  ]);\n}\n\nexport function rotateWithOffset(args: {\n  inputs: RotateWithOffsetInputs,\n  backend: BackendWasm,\n  attrs: RotateWithOffsetAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image} = inputs;\n  const {radians, fillValue, center} = attrs;\n\n  const out = backend.makeOutput(image.shape, image.dtype);\n  const imageId = backend.dataIdMap.get(image.dataId).id;\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n  const [centerX, centerY] =\n      backend_util.getImageCenter(center, imageHeight, imageWidth);\n\n  const fillIsBlack = fillValue === 0;\n  const fullOpacityValue = 255;\n\n  const fillValues = typeof fillValue === 'number' ?\n      [fillValue, fillValue, fillValue, fillIsBlack ? 0 : fullOpacityValue] :\n      [...fillValue, fullOpacityValue];\n  const fillBytes = new Uint8Array(new Int32Array(fillValues).buffer);\n\n  wasmRotate(\n      imageId, batch, imageHeight, imageWidth, numChannels, radians, centerX,\n      centerY, fillBytes, fillValues.length, outId);\n  return out;\n}\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'wasm',\n  kernelFunc: rotateWithOffset as unknown as KernelFunc,\n  setupFunc: setup\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const roundConfig: KernelConfig = createUnaryKernelConfig(Round);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const rsqrtConfig: KernelConfig = createUnaryKernelConfig(Rsqrt);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, scatter_util, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmScatterNd: (\n    indicesId: number, updatesId: number, dtype: CppDType, sliceRank: number,\n    numUpdates: number, sliceSize: number, strides: Uint8Array,\n    outputSize: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmScatterNd = backend.wasm.cwrap(ScatterNd, null /*void*/, [\n    'number',  // indicesId\n    'number',  // updatesId\n    'number',  // dtype\n    'number',  // sliceRank\n    'number',  // numUpdates\n    'number',  // sliceSize\n    'array',   // strides\n    'number',  // outputSize\n    'number'   // outId\n  ]);\n}\n\nfunction scatterNd(\n    args:\n        {backend: BackendWasm, inputs: ScatterNdInputs, attrs: ScatterNdAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const out = backend.makeOutput(shape, updates.dtype);\n  if (util.sizeFromShape(shape) === 0) {\n    return out;\n  }\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      scatter_util.calculateShapes(updates, indices, shape);\n\n  const indicesData = backend.dataIdMap.get(indices.dataId);\n  const indicesId = indicesData.id;\n\n  const updatesData = backend.dataIdMap.get(updates.dataId);\n  const updatesId = updatesData.id;\n\n  const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmScatterNd(\n      indicesId, updatesId, CppDType[updates.dtype], sliceRank, numUpdates,\n      sliceSize, stridesBytes, outputSize, outId);\n\n  return out;\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: scatterNd as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SearchSorted, SearchSortedAttrs, SearchSortedInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {CppDType} from './types';\n\nlet wasmSearchSorted: (\n    sortedSequenceId: number, valuesId: number, batchSize: number,\n    sequenceSize: number, valuesSize: number, dtype: number,\n    isSideLeft: boolean, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmSearchSorted = backend.wasm.cwrap(SearchSorted, null /* void */, [\n    'number',  // sortedSequenceId\n    'number',  // valuesId\n    'number',  // batchSize\n    'number',  // sequenceSize\n    'number',  // valuesSize\n    'number',  // dtype\n    'bool',    // isSideLeft\n    'number',  // outId\n  ]);\n}\n\nfunction searchSorted(args: {\n  inputs: SearchSortedInputs,\n  backend: BackendWasm,\n  attrs: SearchSortedAttrs,\n}) {\n  const {inputs, backend, attrs} = args;\n  const {sortedSequence, values} = inputs;\n  const {side} = attrs;\n\n  if (sortedSequence.dtype !== values.dtype) {\n    throw new Error(\n        `SearchSorted error: sorted_sequence must have the same dtype as values. Got ${\n            sortedSequence.dtype} and ${values.dtype}`);\n  }\n\n  const out = backend.makeOutput(values.shape, 'int32');\n\n  function tensorId(x: TensorInfo) {\n    return backend.dataIdMap.get(x.dataId).id!;\n  }\n  wasmSearchSorted(\n      tensorId(sortedSequence),\n      tensorId(values),\n      /*batchSize=*/sortedSequence.shape[0],\n      /*sequenceSize=*/sortedSequence.shape[1],\n      /*valuesSize=*/values.shape[1],\n      /*dtype=*/CppDType[sortedSequence.dtype],\n      /*isSideLeft=*/side === 'left',\n      tensorId(out),\n  );\n\n  return out;\n}\n\nexport const searchSortedConfig: KernelConfig = {\n  kernelName: SearchSorted,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: searchSorted as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmSelect: (\n    conditionId: number, tId: number, eId: number, offset: number,\n    outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmSelect = backend.wasm.cwrap('SelectV2', null, [\n    'number',  // conditionId\n    'number',  // tId\n    'number',  // eId\n    'number',  // offset\n    'number',  // outId\n  ]);\n}\n\nfunction select(args: {inputs: SelectInputs, backend: BackendWasm}) {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  const conditionId = backend.dataIdMap.get(condition.dataId).id;\n  const tId = backend.dataIdMap.get(t.dataId).id;\n  const eId = backend.dataIdMap.get(e.dataId).id;\n  const out = backend.makeOutput(t.shape, t.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const cRank = condition.shape.length;\n  const tRank = t.shape.length;\n\n  const offset = cRank === 0 || cRank > 1 || tRank === 1 ?\n      1 :\n      util.sizeFromShape(t.shape.slice(1));\n\n  wasmSelect(conditionId, tId, eId, offset, outId);\n  return out;\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'wasm',\n  kernelFunc: select as unknown as KernelFunc,\n  setupFunc: setup\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const seluConfig: KernelConfig = createUnaryKernelConfig(Selu);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Sigmoid, SigmoidInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmFunc: (xId: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmFunc = backend.wasm.cwrap(Sigmoid, null /* void */, ['number', 'number']);\n}\n\nfunction sigmoid(args: {backend: BackendWasm, inputs: SigmoidInputs}):\n    TensorInfo {\n  const {backend, inputs: {x}} = args;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  // Short-circuit zero-sized tensors.\n  if (util.sizeFromShape(out.shape) === 0) {\n    return out;\n  }\n\n  wasmFunc(xId, outId);\n  return out;\n}\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: 'Sigmoid',\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sigmoid as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const signConfig: KernelConfig = createUnaryKernelConfig(Sign);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const sinConfig: KernelConfig = createUnaryKernelConfig(Sin);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const sinhConfig: KernelConfig = createUnaryKernelConfig(Sinh);\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\n\nexport const softplusConfig: KernelConfig = createUnaryKernelConfig(Softplus);\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nfunction spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: BackendWasm,\n  attrs: SpaceToBatchNDAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeData(paddedX.dataId);\n  backend.disposeData(paddedXReshaped.dataId);\n  backend.disposeData(paddedXT.dataId);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'wasm',\n  kernelFunc: spaceToBatchND as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SparseFillEmptyRows, SparseFillEmptyRowsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {slice} from './Slice';\n\nimport {CppDType} from './types';\n\nlet wasmSparseFillEmptyRows: (\n    indicesId: number, valuesId: number, valuesDType: number,\n    indicesCount: number, denseRows: number, rank: number,\n    defaultValueId: number, outputIndicesId: number, outputValuesId: number,\n    emptyRowIndicatorId: number, reverseIndexMapId: number,\n    exceptionValuesId: number) => number;\n\nexport function setup(backend: BackendWasm): void {\n  wasmSparseFillEmptyRows =\n      backend.wasm.cwrap('SparseFillEmptyRows', 'number', [\n        'number',  // indicesId\n        'number',  // valuesId\n        'number',  // valuesDType\n        'number',  // indicesCount\n        'number',  // denseRows\n        'number',  // rank\n        'number',  // defaultValueId\n        'number',  // outputIndicesId\n        'number',  // outputValuesId\n        'number',  // emptyRowIndicatorId\n        'number',  // reverseIndexMapId\n        'number',  // exceptionValuesId\n      ]);\n}\n\nexport function sparseFillEmptyRows(args: {\n  backend: BackendWasm,\n  inputs: SparseFillEmptyRowsInputs,\n}): [TensorInfo, TensorInfo, TensorInfo, TensorInfo] {\n  const {backend, inputs} = args;\n  const {indices, values, denseShape, defaultValue} = inputs;\n\n  const indicesCount = indices.shape[0];\n  const rank = indices.shape[1];\n  const denseRows = backend.readSync(denseShape.dataId)[0] as number;\n\n  // Set output size to maximum possible and resize later (actual result\n  // might be smaller).\n  const maxOutputIndicesShape = [indicesCount + denseRows, rank];\n\n  const indicesId = backend.dataIdMap.get(indices.dataId).id;\n  const valuesId = backend.dataIdMap.get(values.dataId).id;\n  const defaultValueId = backend.dataIdMap.get(defaultValue.dataId).id;\n\n  const outputIndices =\n      backend.makeOutput(maxOutputIndicesShape, indices.dtype);\n  const outputIndicesId = backend.dataIdMap.get(outputIndices.dataId).id;\n\n  const outputValues =\n      backend.makeOutput(maxOutputIndicesShape.slice(0, 1), values.dtype);\n  const outputValuesId = backend.dataIdMap.get(outputValues.dataId).id;\n\n  const emptyRowIndicator = backend.makeOutput([denseRows], 'bool');\n  const emptyRowIndicatorId =\n      backend.dataIdMap.get(emptyRowIndicator.dataId).id;\n\n  const reverseIndexMap = backend.makeOutput([indicesCount], indices.dtype);\n  const reverseIndexMapId = backend.dataIdMap.get(reverseIndexMap.dataId).id;\n\n  const exceptionValues = backend.makeOutput([4], 'int32');\n  const exceptionValuesId = backend.dataIdMap.get(exceptionValues.dataId).id;\n\n  const outputRows = wasmSparseFillEmptyRows(\n      indicesId, valuesId, CppDType[values.dtype], indicesCount, denseRows,\n      rank, defaultValueId, outputIndicesId, outputValuesId,\n      emptyRowIndicatorId, reverseIndexMapId, exceptionValuesId);\n\n  const exceptionValuesArray =\n      backend.readSync(exceptionValues.dataId) as Int32Array;\n\n  let exceptionMessage: string;\n  switch (exceptionValuesArray[0]) {\n    case 1: {\n      exceptionMessage =\n          backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(\n              exceptionValuesArray[1]);\n      break;\n    }\n    case 2: {\n      exceptionMessage =\n          backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(\n              exceptionValuesArray[1], exceptionValuesArray[2]);\n      break;\n    }\n    case 3:\n      exceptionMessage =\n          backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(\n              exceptionValuesArray[1], exceptionValuesArray[2],\n              exceptionValuesArray[3]);\n      break;\n    default:\n      exceptionMessage = '';\n  }\n\n  backend.disposeData(exceptionValues.dataId);\n  if (exceptionMessage) {\n    backend.disposeData(outputIndices.dataId);\n    backend.disposeData(outputValues.dataId);\n    backend.disposeData(emptyRowIndicator.dataId);\n    backend.disposeData(reverseIndexMap.dataId);\n    throw new Error(exceptionMessage);\n  }\n\n  let resizedIndices = outputIndices;\n  let resizedValues = outputValues;\n  // Overestimated output size.\n  if (outputRows !== maxOutputIndicesShape[0]) {\n    resizedIndices = slice({\n      inputs: {x: outputIndices},\n      attrs: {begin: 0, size: [outputRows, rank]},\n      backend\n    });\n    resizedValues = slice({\n      inputs: {x: outputValues},\n      attrs: {begin: 0, size: outputRows},\n      backend\n    });\n    backend.disposeData(outputIndices.dataId);\n    backend.disposeData(outputValues.dataId);\n  }\n\n  return [resizedIndices, resizedValues, emptyRowIndicator, reverseIndexMap];\n}\n\nexport const sparseFillEmptyRowsConfig: KernelConfig = {\n  kernelName: SparseFillEmptyRows,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sparseFillEmptyRows as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SparseReshape, SparseReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmSparseReshape: (\n    inputIndicesId: number, inputShapeId: number, newShapeId: number,\n    nnz: number, newIndicesId: number, outputShapeId: number,\n    exceptionValuesId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmSparseReshape = backend.wasm.cwrap(SparseReshape, null /*void*/, [\n    'number',  // inputIndicesId\n    'number',  // inputShapeId\n    'number',  // newShapeId\n    'number',  // nnz\n    'number',  // newIndicesId\n    'number',  // outputShapeId\n    'number',  // exceptionValuesId\n  ]);\n}\n\nfunction sparseReshape(args: {\n  backend: BackendWasm,\n  inputs: SparseReshapeInputs,\n}): [TensorInfo, TensorInfo] {\n  const {backend, inputs} = args;\n  const {inputIndices, inputShape, newShape} = inputs;\n\n  if (inputIndices.shape.length !== 2) {\n    throw new Error(`Input indices should be a matrix but received shape\n        ${inputIndices.shape}`);\n  }\n  if (inputShape.shape.length !== 1) {\n    throw new Error(`Input shape should be a vector but received shape\n        ${inputShape.shape}`);\n  }\n  if (newShape.shape.length !== 1) {\n    throw new Error(\n        `Target shape should be a vector but received shape ${newShape.shape}`);\n  }\n\n  const inputIndicesId = backend.dataIdMap.get(inputIndices.dataId).id;\n  const inputShapeId = backend.dataIdMap.get(inputShape.dataId).id;\n  const newShapeId = backend.dataIdMap.get(newShape.dataId).id;\n\n  const nnz = inputIndices.shape[0];\n  const outputRank = util.sizeFromShape(newShape.shape);\n\n  const newIndices = backend.makeOutput([nnz, outputRank], inputIndices.dtype);\n  const newIndicesId = backend.dataIdMap.get(newIndices.dataId).id;\n\n  const outputShape = backend.makeOutput([outputRank], newShape.dtype);\n  const outputShapeId = backend.dataIdMap.get(outputShape.dataId).id;\n\n  const exceptionValues = backend.makeOutput([3], 'int32');\n  const exceptionValuesId = backend.dataIdMap.get(exceptionValues.dataId).id;\n\n  wasmSparseReshape(\n      inputIndicesId, inputShapeId, newShapeId, nnz, newIndicesId,\n      outputShapeId, exceptionValuesId);\n\n  const exceptionValuesArray =\n      backend.readSync(exceptionValues.dataId) as Int32Array;\n\n  let exceptionMessage: string;\n  switch (exceptionValuesArray[0]) {\n    case 0: {\n      exceptionMessage =\n          backend_util.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(\n              exceptionValuesArray[1], exceptionValuesArray[2]);\n      break;\n    }\n    case 1: {\n      exceptionMessage =\n          backend_util.getSparseReshapeNegativeOutputDimErrorMessage(\n              exceptionValuesArray[1], exceptionValuesArray[2]);\n      break;\n    }\n    case 2:\n      exceptionMessage =\n          backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage();\n      break;\n    case 3: {\n      const inputShapeValues =\n          Array.from(backend.readSync(inputShape.dataId) as Int32Array),\n            outputShapeValues =\n                Array.from(backend.readSync(outputShape.dataId) as Int32Array);\n      exceptionMessage =\n          backend_util.getSparseReshapeInputOutputMultipleErrorMessage(\n              inputShapeValues, outputShapeValues);\n      break;\n    }\n    case 4: {\n      const inputShapeValues =\n          Array.from(backend.readSync(inputShape.dataId) as Int32Array),\n            outputShapeValues =\n                Array.from(backend.readSync(outputShape.dataId) as Int32Array);\n      exceptionMessage =\n          backend_util.getSparseReshapeInputOutputMismatchErrorMessage(\n              inputShapeValues, outputShapeValues);\n      break;\n    }\n    default:\n      exceptionMessage = '';\n  }\n\n  backend.disposeData(exceptionValues.dataId);\n  if (exceptionMessage) {\n    backend.disposeData(newIndices.dataId);\n    backend.disposeData(outputShape.dataId);\n    throw new Error(exceptionMessage);\n  }\n\n  return [newIndices, outputShape];\n}\n\nexport const sparseReshapeConfig: KernelConfig = {\n  kernelName: SparseReshape,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sparseReshape as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, SparseSegmentMeanInputs, SparseSegmentSumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmSparseSegmentReduction: (\n    dataId: number, dtype: number, numRow: number, indicesId: number,\n    segmentIdsId: number, outputId: number, exceptionValuesId: number,\n    isMean: boolean, defaultValue: number) => void;\n\nexport function setup(backend: BackendWasm): void {\n  wasmSparseSegmentReduction =\n      backend.wasm.cwrap('SparseSegmentReduction', null /*void*/, [\n        'number',  // dataId\n        'number',  // dtype\n        'number',  // numRow\n        'number',  // indicesId\n        'number',  // segmentIdsId\n        'number',  // outputId\n        'number',  // exceptionValuesId,\n        'number',  // isMean\n        'number',  // defaultValue\n      ]);\n}\n\nexport function sparseSegmentReduction(\n    args: {\n      backend: BackendWasm,\n      inputs: SparseSegmentSumInputs|SparseSegmentMeanInputs,\n    },\n    isMean: boolean): TensorInfo {\n  const {backend, inputs} = args;\n  const {data, indices, segmentIds} = inputs;\n\n  const numIndices = indices.shape[0];\n  const segmentIdsBack =\n      (backend.readSync(segmentIds.dataId, numIndices - 1, numIndices) as\n       Int32Array)[0];\n  const lastSegmentIdPlusOne = numIndices > 0 ? segmentIdsBack + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  if (outputRows < 0) {\n    throw (new Error(\n        backend_util\n            .getSparseSegmentReductionNegativeSegmentIdsErrorMessage()));\n  }\n\n  const outputShape = data.shape.slice();\n  outputShape[0] = outputRows;\n\n  const dataId = backend.dataIdMap.get(data.dataId).id;\n  const indicesId = backend.dataIdMap.get(indices.dataId).id;\n  const segmentIdsId = backend.dataIdMap.get(segmentIds.dataId).id;\n\n  const output = backend.makeOutput(outputShape, data.dtype);\n  const outputId = backend.dataIdMap.get(output.dataId).id;\n\n  const exceptionValues = backend.makeOutput([4], 'int32');\n  const exceptionValuesId = backend.dataIdMap.get(exceptionValues.dataId).id;\n\n  wasmSparseSegmentReduction(\n      dataId, CppDType[data.dtype], data.shape[0], indicesId, segmentIdsId,\n      outputId, exceptionValuesId, isMean, 0);\n\n  const exceptionValuesArray =\n      backend.readSync(exceptionValues.dataId) as Int32Array;\n\n  let exceptionMessage: string;\n  switch (exceptionValuesArray[0]) {\n    case 0: {\n      exceptionMessage =\n          backend_util\n              .getSparseSegmentReductionNegativeSegmentIdsErrorMessage();\n      break;\n    }\n    case 1: {\n      exceptionMessage =\n          backend_util\n              .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage();\n      break;\n    }\n    case 2:\n      exceptionMessage =\n          backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(\n              exceptionValuesArray[1], exceptionValuesArray[2]);\n      break;\n    case 3:\n      exceptionMessage =\n          backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(\n              exceptionValuesArray[1], exceptionValuesArray[2],\n              exceptionValuesArray[3]);\n      break;\n    default:\n      exceptionMessage = '';\n  }\n\n  backend.disposeData(exceptionValues.dataId);\n  if (exceptionMessage) {\n    backend.disposeData(output.dataId);\n    throw new Error(exceptionMessage);\n  }\n\n  return output;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseSegmentMean, SparseSegmentMeanInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {setup, sparseSegmentReduction} from './SparseSegmentReduction';\n\nfunction sparseSegmentMean(args: {\n  backend: BackendWasm,\n  inputs: SparseSegmentMeanInputs,\n}): TensorInfo {\n  return sparseSegmentReduction(args, true);\n}\n\nexport const sparseSegmentMeanConfig: KernelConfig = {\n  kernelName: SparseSegmentMean,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sparseSegmentMean as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseSegmentSum, SparseSegmentSumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {setup, sparseSegmentReduction} from './SparseSegmentReduction';\n\nfunction sparseSegmentSum(args: {\n  backend: BackendWasm,\n  inputs: SparseSegmentSumInputs,\n}): TensorInfo {\n  return sparseSegmentReduction(args, false);\n}\n\nexport const sparseSegmentSumConfig: KernelConfig = {\n  kernelName: SparseSegmentSum,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sparseSegmentSum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmSparseToDense: (\n    sparseIndicesId: number, sparseValuesId: number, sparseValuesRank: number,\n    defaultValueId: number, dtype: CppDType, sliceRank: number,\n    numUpdates: number, sliceSize: number, strides: Uint8Array,\n    outputSize: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmSparseToDense = backend.wasm.cwrap(SparseToDense, null /*void*/, [\n    'number',  // sparseIndicesId\n    'number',  // sparseValuesId\n    'number',  // sparseValuesRank\n    'number',  // defaultValueId\n    'number',  // dtype\n    'number',  // sliceRank\n    'number',  // numUpdates\n    'number',  // sliceSize\n    'array',   // strides\n    'number',  // outputSize\n    'number',  // outId\n  ]);\n}\n\nfunction sparseToDense(args: {\n  backend: BackendWasm,\n  inputs: SparseToDenseInputs,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const out = backend.makeOutput(outputShape, defaultValue.dtype);\n  if (util.sizeFromShape(outputShape) === 0) {\n    return out;\n  }\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n\n  const sparseIndicesId = backend.dataIdMap.get(sparseIndices.dataId).id;\n  const sparseValuesId = backend.dataIdMap.get(sparseValues.dataId).id;\n  const defaultValueId = backend.dataIdMap.get(defaultValue.dataId).id;\n\n  const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  wasmSparseToDense(\n      sparseIndicesId, sparseValuesId, sparseValues.shape.length,\n      defaultValueId, CppDType[defaultValue.dtype], sliceRank, numUpdates,\n      sliceSize, stridesBytes, outputSize, outId);\n\n  return out;\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sparseToDense as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SplitV, SplitVAttrs, SplitVInputs, util} from '@tensorflow/tfjs-core';\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, attrs: SplitVAttrs, backend: BackendWasm}) {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n  const begin = new Array(x.shape.length).fill(0);\n  const size = x.shape.slice();\n  return splitSizes.map(s => {\n    const xSliceSize = [...size];\n    xSliceSize[$axis] = s;\n    const xSlice =\n        slice({inputs: {x}, attrs: {begin, size: xSliceSize}, backend});\n    begin[$axis] += s;\n    return xSlice;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'wasm',\n  kernelFunc: splitV as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const sqrtConfig: KernelConfig = createUnaryKernelConfig(Sqrt);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Square} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const squareConfig: KernelConfig = createUnaryKernelConfig(Square);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = true;\nexport const squaredDifferenceConfig: KernelConfig =\n    createBinaryKernelConfig(SquaredDifference, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Step, StepAttrs, StepInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmStep: (xId: number, alpha: number, dtype: number, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmStep = backend.wasm.cwrap(Step, null /*void*/, [\n    'number',  // x_id\n    'number',  // alpha\n    'number',  // dtype\n    'number',  // out_id\n  ]);\n}\n\nfunction step(\n    args: {backend: BackendWasm, inputs: StepInputs, attrs: StepAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {alpha} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmStep(xId, alpha, CppDType[x.dtype], outId);\n  return out;\n}\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: step as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nlet wasmStridedSlice: (\n    xId: number, xStridesBytes: Uint8Array, xRank: number,\n    beginBytes: Uint8Array, endBytes: Uint8Array, stridesBytes: Uint8Array,\n    outShapeBytes: Uint8Array, outStridesBytes: Uint8Array,\n    outShapeLength: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmStridedSlice = backend.wasm.cwrap(StridedSlice, null /*void*/, [\n    'number',  // xId\n    'array',   // xStrides\n    'number',  // xRank\n    'array',   // beginBytes\n    'array',   // endBytes\n    'array',   // stridesBytes\n    'array',   // outShapeBytes\n    'array',   // outStridesBytes\n    'number',  // outShapeLength\n    'number',  // outId\n  ]);\n}\n\nexport function stridedSlice(args: {\n  backend: BackendWasm,\n  inputs: StridedSliceInputs,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {x} = inputs;\n\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  const {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: $begin,\n    end: $end,\n    strides: $strides\n  } =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  let result;\n\n  if (isIdentity) {\n    // Optimization #1, slice is a no-op plus reshape\n    result = reshape({inputs: {x}, backend, attrs: {shape: finalShape}});\n  } else if (sliceDim0 || isSimpleSlice) {\n    // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n    util.assert(\n        x.shape.length >= 1,\n        () => `Input must have rank at least 1, got: ${x.shape.length}`);\n\n    const size = slice_util.computeOutShape($begin, $end, $strides);\n    // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n    const sliced = slice({inputs: {x}, backend, attrs: {begin: $begin, size}});\n    result =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: finalShape}});\n    backend.disposeData(sliced.dataId);\n  } else {\n    const out = backend.makeOutput(finalShapeSparse, 'float32');\n\n    const xId = backend.dataIdMap.get(x.dataId).id;\n    const xStridesBytes =\n        new Uint8Array(new Int32Array(util.computeStrides(x.shape)).buffer);\n    const beginBytes = new Uint8Array(new Int32Array($begin).buffer);\n    const endBytes = new Uint8Array(new Int32Array($end).buffer);\n    const stridesBytes = new Uint8Array(new Int32Array($strides).buffer);\n\n    const outputShapeBytes =\n        new Uint8Array(new Int32Array(finalShapeSparse).buffer);\n    const outStridesBytes = new Uint8Array(\n        new Int32Array(util.computeStrides(finalShapeSparse)).buffer);\n    const outId = backend.dataIdMap.get(out.dataId).id;\n\n    wasmStridedSlice(\n        xId, xStridesBytes, x.shape.length, beginBytes, endBytes, stridesBytes,\n        outputShapeBytes, outStridesBytes, finalShapeSparse.length, outId);\n\n    result = reshape({inputs: {x: out}, backend, attrs: {shape: finalShape}});\n\n    backend.disposeData(out.dataId);\n  }\n\n  return result;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: stridedSlice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringNGrams, StringNGramsAttrs, StringNGramsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {stringNGramsImplCPU} from '../kernel_utils/shared';\n\nfunction stringNGrams(args: {\n  backend: BackendWasm,\n  inputs: StringNGramsInputs,\n  attrs: StringNGramsAttrs\n}): [TensorInfo, TensorInfo] {\n  const {backend, inputs, attrs} = args;\n  const {data, dataSplits} = inputs;\n  const {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences,\n  } = attrs;\n\n  const $data = backend.readSync(data.dataId) as Uint8Array[];\n  const $dataSplits = backend.readSync(dataSplits.dataId) as Int32Array;\n\n  const [nGrams, nGramsSplits] = stringNGramsImplCPU(\n      $data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth,\n      preserveShortSequences);\n\n  const nGramsOut = backend.makeOutput([nGrams.length], 'string');\n  const nGramsOutData = backend.dataIdMap.get(nGramsOut.dataId);\n  nGramsOutData.stringBytes = nGrams;\n\n  const nGramsSplitsOut = backend.makeOutput(dataSplits.shape, 'int32');\n  const nGramsSplitsOutVals = backend.typedArrayFromHeap(nGramsSplitsOut);\n  nGramsSplitsOutVals.set(nGramsSplits);\n\n  return [nGramsOut, nGramsSplitsOut];\n}\n\nexport const stringNGramsConfig: KernelConfig = {\n  kernelName: StringNGrams,\n  backendName: 'wasm',\n  kernelFunc: stringNGrams as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringSplit, StringSplitAttrs, StringSplitInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {stringSplitImplCPU} from '../kernel_utils/shared';\n\nfunction stringSplit(args: {\n  backend: BackendWasm,\n  inputs: StringSplitInputs,\n  attrs: StringSplitAttrs\n}): [TensorInfo, TensorInfo, TensorInfo] {\n  const {backend, inputs, attrs} = args;\n  const {input, delimiter} = inputs;\n  const {skipEmpty} = attrs;\n\n  const inputVals = backend.readSync(input.dataId) as Uint8Array[];\n  const delimiterVals = backend.readSync(delimiter.dataId) as Uint8Array[];\n\n  const [indices, values, shape] =\n      stringSplitImplCPU(inputVals, delimiterVals[0], skipEmpty);\n  const outputSize = values.length;\n\n  const indicesOut = backend.makeOutput([outputSize, 2], 'int32');\n  const indicesOutVals = backend.typedArrayFromHeap(indicesOut);\n  indicesOutVals.set(indices);\n\n  const valuesOut = backend.makeOutput([outputSize], 'string');\n  const valuesOutData = backend.dataIdMap.get(valuesOut.dataId);\n  valuesOutData.stringBytes = values;\n\n  const shapeOut = backend.makeOutput([2], 'int32');\n  const shapeOutVals = backend.typedArrayFromHeap(shapeOut);\n  shapeOutVals.set(shape);\n\n  return [indicesOut, valuesOut, shapeOut];\n}\n\nexport const stringSplitConfig: KernelConfig = {\n  kernelName: StringSplit,\n  backendName: 'wasm',\n  kernelFunc: stringSplit as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringToHashBucketFast, StringToHashBucketFastAttrs, StringToHashBucketFastInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {stringToHashBucketFastImplCPU} from '../kernel_utils/shared';\n\nfunction stringToHashBucketFast(args: {\n  backend: BackendWasm,\n  inputs: StringToHashBucketFastInputs,\n  attrs: StringToHashBucketFastAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {input} = inputs;\n  const {numBuckets} = attrs;\n\n  const inputVals = backend.readSync(input.dataId) as Uint8Array[];\n\n  const values = stringToHashBucketFastImplCPU(inputVals, numBuckets);\n\n  const out = backend.makeOutput(input.shape, 'int32');\n  const outVals = backend.typedArrayFromHeap(out);\n  outVals.set(values);\n  return out;\n}\n\nexport const stringToHashBucketFastConfig: KernelConfig = {\n  kernelName: StringToHashBucketFast,\n  backendName: 'wasm',\n  kernelFunc: stringToHashBucketFast as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function stringToHashBucketFastImpl(\n    input: Uint8Array[], numBuckets: number): TypedArray {\n  const output = util.getArrayFromDType('int32', input.length) as TypedArray;\n\n  for (let i = 0; i < input.length; ++i) {\n    output[i] =\n        util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();\n  }\n\n  return output;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\nimport {createBinaryKernelConfig} from './binary_kernel';\nconst supportsFullBroadcast = true;\nexport const subConfig: KernelConfig =\n    createBinaryKernelConfig(Sub, supportsFullBroadcast);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\nimport {CppDType} from './types';\n\nlet wasmSum: (xId: number, reduceSize: number, dtype: number, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmSum = backend.wasm.cwrap(Sum, null /*void*/, [\n    'number',  // input_id\n    'number',  // reduce_size\n    'number',  // dtype\n    'number',  // out_id\n  ]);\n}\n\nfunction sum(args: {backend: BackendWasm, inputs: SumInputs, attrs: SumAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  let reductionAxes = axes;\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    if (transposedId !== xId) {\n      // transpose was not a no-op. We will need to dispose of this\n      // once we are done.\n      input = transposed;\n      inputId = transposedId;\n      reductionAxes = backend_util.getInnerMostAxes(\n          reductionAxes.length, input.shape.length);\n    }\n  }\n\n  backend_util.assertAxesAreInnerMostDims(\n      'sum', reductionAxes, input.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, reductionAxes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, input.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmSum(inputId, reduceSize, CppDType[out.dtype], outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: sum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const tanConfig: KernelConfig = createUnaryKernelConfig(Tan);\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {createUnaryKernelConfig} from './unary_kernel';\nexport const tanhConfig: KernelConfig = createUnaryKernelConfig(Tanh);\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, scatter_util, TensorInfo, TensorScatterUpdate, TensorScatterUpdateAttrs, TensorScatterUpdateInputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmTensorScatterUpdate: (\n    indicesId: number, updatesId: number, dtype: CppDType, sliceRank: number,\n    numUpdates: number, sliceSize: number, strides: Uint8Array,\n    outputSize: number, outId: number, tensorId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmTensorScatterUpdate =\n      backend.wasm.cwrap(TensorScatterUpdate, null /*void*/, [\n        'number',  // indicesId\n        'number',  // updatesId\n        'number',  // dtype\n        'number',  // sliceRank\n        'number',  // numUpdates\n        'number',  // sliceSize\n        'array',   // strides\n        'number',  // outputSize\n        'number',  // outId\n        'number',  // tensorId\n      ]);\n}\n\nfunction tensorScatterUpdate(args: {\n  backend: BackendWasm,\n  inputs: TensorScatterUpdateInputs,\n  attrs: TensorScatterUpdateAttrs\n}): TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {tensor, indices, updates} = inputs;\n  const {} = attrs;\n\n  const out = backend.makeOutput(tensor.shape, tensor.dtype);\n  if (util.sizeFromShape(tensor.shape) === 0) {\n    return out;\n  }\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      scatter_util.calculateShapes(updates, indices, tensor.shape);\n\n  const indicesData = backend.dataIdMap.get(indices.dataId);\n  const indicesId = indicesData.id;\n\n  const updatesData = backend.dataIdMap.get(updates.dataId);\n  const updatesId = updatesData.id;\n\n  const tensorData = backend.dataIdMap.get(tensor.dataId);\n  const tensorId = tensorData.id;\n\n  const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);\n\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmTensorScatterUpdate(\n      indicesId, updatesId, CppDType[updates.dtype], sliceRank, numUpdates,\n      sliceSize, stridesBytes, outputSize, outId, tensorId);\n\n  return out;\n}\n\nexport const tensorScatterUpdateConfig: KernelConfig = {\n  kernelName: TensorScatterUpdate,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: tensorScatterUpdate as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Tile, TileAttrs, TileInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nlet wasmTile: (\n    xId: number, xShape: Uint8Array, xShapeSize: number, newShape: Uint8Array,\n    newShapeSize: number, dtype: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmTile = backend.wasm.cwrap(Tile, null /* void */, [\n    'number',  // x_id\n    'array',   // x_shape\n    'number',  // x_shape.length\n    'array',   // new_shape\n    'number',  // new_shape.length\n    'number'   // out_id\n  ]);\n}\n\nfunction tile(\n    args: {inputs: TileInputs, backend: BackendWasm, attrs: TileAttrs}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const {reps} = attrs;\n\n  const newShape: number[] = new Array(x.shape.length);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[i] * reps[i];\n  }\n  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n  const newShapeBytes = new Uint8Array(new Int32Array(newShape).buffer);\n\n  const out = backend.makeOutput(newShape, x.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  wasmTile(\n      xId, xShapeBytes, x.shape.length, newShapeBytes, newShape.length,\n      CppDType[out.dtype], outId);\n  return out;\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: tile as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, TopK, TopKAttrs, TopKInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {CppDType} from './types';\n\nlet wasmTopK: (\n    xId: number, xShapeBytes: Uint8Array, xShapeLength: number,\n    xDtype: CppDType, k: number, sorted: boolean, outValuesId: number,\n    outIndicesId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmTopK = backend.wasm.cwrap(TopK, null /* void */, [\n    'number',  // xId\n    'array',   // x.shape\n    'number',  // x.shape.length\n    'number',  // x.dtype\n    'number',  // k\n    'bool',    // sorted\n    'number',  // outValuesId\n    'number',  // outIndicesId\n  ]);\n}\n\nexport const topk:\n    (args: {inputs: TopKInputs, backend: BackendWasm, attrs: TopKAttrs}) =>\n        TensorInfo[] | TensorInfo = ({inputs, backend, attrs}) => {\n          const {x} = inputs;\n          const {k, sorted} = attrs;\n\n          const xId = backend.dataIdMap.get(x.dataId).id;\n          const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n          const outputShape = x.shape.slice();\n          outputShape[outputShape.length - 1] = k;\n          const outValues = backend.makeOutput(outputShape, x.dtype);\n          const outValuesId = backend.dataIdMap.get(outValues.dataId).id;\n          const outIndices = backend.makeOutput(outputShape, 'int32');\n          const outIndicesId = backend.dataIdMap.get(outIndices.dataId).id;\n\n          wasmTopK(\n              xId, xShapeBytes, x.shape.length, CppDType[x.dtype], k, sorted,\n              outValuesId, outIndicesId);\n\n          return [outValues, outIndices];\n        };\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: topk as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transform, TransformAttrs, TransformInputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmTransform: (\n    imageId: number, transformsId: number, isBatchTransform: boolean,\n    batch: number, outHeight: number, outWidth: number, numChannels: number,\n    imageWidth: number, imageHeight: number, inputStrides: Uint8Array,\n    inputStridesLength: number, outputStrides: Uint8Array,\n    outputStridesLength: number, interpolationModeId: number,\n    fillModeId: number, fillValue: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmTransform = backend.wasm.cwrap(Transform, null /*void*/, [\n    'number',  // imageId\n    'number',  // transformsId\n    'bool',    // isBatchTransform\n    'number',  // batch\n    'number',  // outHeight\n    'number',  // outWidth\n    'number',  // numChannels\n    'number',  // imageWidth\n    'number',  // imageHeight\n    'array',   // inputStrides\n    'number',  // inputStridesLength\n    'array',   // outputStrides\n    'number',  // outputStridesLength\n    'number',  // interpolationModeId\n    'number',  // fillModeId\n    'number',  // fillValue\n    'number'   // outId\n  ]);\n}\n\nfunction transform(\n    args:\n        {backend: BackendWasm, inputs: TransformInputs, attrs: TransformAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape =\n      [batch, outHeight, outWidth,\n       numChannels] as [number, number, number, number];\n  const inputStrides =\n      new Uint8Array(new Int32Array(util.computeStrides(image.shape)).buffer);\n\n  const outputStrides =\n      new Uint8Array(new Int32Array(util.computeStrides(outShape)).buffer);\n\n  const out = backend.makeOutput(outShape, image.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const imageData = backend.dataIdMap.get(image.dataId);\n  const imageId = imageData.id;\n\n  const transformsData = backend.dataIdMap.get(transforms.dataId);\n  const transformsId = transformsData.id;\n\n  const interpolationModeId = interpolation === 'nearest' ? 1 : 2;\n  let fillModeId;\n  switch (fillMode) {\n    case 'constant':\n      fillModeId = 1;\n      break;\n    case 'reflect':\n      fillModeId = 2;\n      break;\n    case 'wrap':\n      fillModeId = 3;\n      break;\n    case 'nearest':\n      fillModeId = 4;\n      break;\n    default:\n      fillModeId = 1;\n      break;\n  }\n\n  wasmTransform(\n      imageId, transformsId, (transforms.shape[0] > 1), batch, outHeight,\n      outWidth, numChannels, imageWidth, imageHeight, inputStrides,\n      image.shape.length - 1, outputStrides, outShape.length - 1,\n      interpolationModeId, fillModeId, fillValue, outId);\n\n  return out;\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: transform as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nfunction zerosLike(args: {inputs: ZerosLikeInputs, backend: BackendWasm}) {\n  const {inputs: {x}, backend} = args;\n  const out = backend.makeOutput(x.shape, x.dtype);\n  const outVals = backend.typedArrayFromHeap(out);\n  outVals.fill(0);\n  return out;\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'wasm',\n  kernelFunc: zerosLike as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {allConfig} from './kernels/All';\nimport {anyConfig} from './kernels/Any';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atan2Config} from './kernels/Atan2';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPool3DConfig} from './kernels/AvgPool3D';\nimport {avgPool3DGradConfig} from './kernels/AvgPool3DGrad';\nimport {avgPoolGradConfig} from './kernels/AvgPoolGrad';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {bincountConfig} from './kernels/Bincount';\nimport {bitwiseAndConfig} from './kernels/BitwiseAnd';\nimport {broadcastArgsConfig} from './kernels/BroadcastArgs';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipByValueConfig} from './kernels/ClipByValue';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumprodConfig} from './kernels/Cumprod';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {denseBincountConfig} from './kernels/DenseBincount';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {diagConfig} from './kernels/Diag';\nimport {dilation2DConfig} from './kernels/Dilation2D';\nimport {dilation2DBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2DBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {eluConfig} from './kernels/Elu';\nimport {eluGradConfig} from './kernels/EluGrad';\nimport {equalConfig} from './kernels/Equal';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fusedBatchNormConfig} from './kernels/FusedBatchNorm';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNan';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {linSpaceConfig} from './kernels/LinSpace';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {logicalOrConfig} from './kernels/LogicalOr';\nimport {logicalXorConfig} from './kernels/LogicalXor';\nimport {lrnConfig} from './kernels/LRN';\nimport {lrnGradConfig} from './kernels/LRNGrad';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPool3DConfig} from './kernels/MaxPool3D';\nimport {maxPool3DGradConfig} from './kernels/MaxPool3DGrad';\nimport {maxPoolGradConfig} from './kernels/MaxPoolGrad';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {multinomialConfig} from './kernels/Multinomial';\nimport {modConfig} from './kernels/Mod';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {oneHotConfig} from './kernels/OneHot';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {rangeConfig} from './kernels/Range';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeBilinearGradConfig} from './kernels/ResizeBilinearGrad';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {resizeNearestNeighborGradConfig} from './kernels/ResizeNearestNeighborGrad';\nimport {reverseConfig} from './kernels/Reverse';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {searchSortedConfig} from './kernels/SearchSorted';\nimport {selectConfig} from './kernels/Select';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseFillEmptyRowsConfig} from './kernels/SparseFillEmptyRows';\nimport {sparseReshapeConfig} from './kernels/SparseReshape';\nimport {sparseSegmentMeanConfig} from './kernels/SparseSegmentMean';\nimport {sparseSegmentSumConfig} from './kernels/SparseSegmentSum';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {stringNGramsConfig} from './kernels/StringNGrams';\nimport {stringSplitConfig} from './kernels/StringSplit';\nimport {stringToHashBucketFastConfig} from './kernels/StringToHashBucketFast';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tensorScatterUpdateConfig} from './kernels/TensorScatterUpdate';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\nimport {unpackConfig} from './kernels/Unpack';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  addNConfig,\n  allConfig,\n  anyConfig,\n  argMaxConfig,\n  argMinConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atan2Config,\n  atanhConfig,\n  avgPoolConfig,\n  avgPoolGradConfig,\n  avgPool3DConfig,\n  avgPool3DGradConfig,\n  batchMatMulConfig,\n  batchToSpaceNDConfig,\n  bincountConfig,\n  bitwiseAndConfig,\n  broadcastArgsConfig,\n  castConfig,\n  ceilConfig,\n  clipByValueConfig,\n  concatConfig,\n  conv2DConfig,\n  conv2DBackpropInputConfig,\n  conv3DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumprodConfig,\n  cumsumConfig,\n  denseBincountConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeConfig,\n  diagConfig,\n  dilation2DConfig,\n  dilation2DBackpropFilterConfig,\n  dilation2DBackpropInputConfig,\n  eluConfig,\n  eluGradConfig,\n  equalConfig,\n  erfConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fillConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedBatchNormConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  linSpaceConfig,\n  log1pConfig,\n  logConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  logicalOrConfig,\n  logicalXorConfig,\n  lrnConfig,\n  lrnGradConfig,\n  maxConfig,\n  maximumConfig,\n  maxPoolConfig,\n  maxPool3DConfig,\n  maxPool3DGradConfig,\n  maxPoolGradConfig,\n  maxPoolWithArgmaxConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  multinomialConfig,\n  modConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  oneHotConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  rangeConfig,\n  realDivConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeBilinearGradConfig,\n  resizeNearestNeighborConfig,\n  resizeNearestNeighborGradConfig,\n  reverseConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  searchSortedConfig,\n  selectConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softmaxConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sparseFillEmptyRowsConfig,\n  sparseReshapeConfig,\n  sparseSegmentMeanConfig,\n  sparseSegmentSumConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  stepConfig,\n  stridedSliceConfig,\n  stringNGramsConfig,\n  stringSplitConfig,\n  stringToHashBucketFastConfig,\n  subConfig,\n  sumConfig,\n  tanConfig,\n  tanhConfig,\n  tensorScatterUpdateConfig,\n  tileConfig,\n  topKConfig,\n  transformConfig,\n  transposeConfig,\n  uniqueConfig,\n  unpackConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\nimport {uniqueImplCPU} from '../kernel_utils/shared';\n\nfunction unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: BackendWasm}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n\n  const {outputValues, outputShape, indices} =\n      uniqueImplCPU(backend.readSync(x.dataId), axis, x.shape, x.dtype);\n\n  return [\n    backend.makeOutput(\n        outputShape, x.dtype, /*memoryOffset=*/undefined, outputValues),\n    backend.makeOutput(\n        [indices.length], 'int32', /*memoryOffset=*/undefined, indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'wasm',\n  kernelFunc: unique as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements = new Map<string, number>();\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    const existingIndex = uniqueElements.get(element);\n    if (existingIndex != null) {\n      indices[i] = existingIndex;\n    } else {\n      const uniqueIndex = uniqueElements.size;\n      uniqueElements.set(element, uniqueIndex);\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = uniqueElements.size;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {slice} from './Slice';\n\nfunction unpack(\n    args: {inputs: UnpackInputs, backend: BackendWasm, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const numOutputs = value.shape[axis];\n  const rank = value.shape.length;\n  const outShape: number[] = new Array(rank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < rank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = value.shape[i];\n    }\n  }\n  const outs: TensorInfo[] = new Array(numOutputs);\n  const begin = new Array(rank).fill(0);\n  const size = value.shape.slice();\n  size[axis] = 1;\n  for (let i = 0; i < outs.length; i++) {\n    begin[axis] = i;\n    outs[i] = slice({inputs: {x: value}, attrs: {begin, size}, backend});\n  }\n  return outs.map(({dataId, dtype}) => ({dataId, dtype, shape: outShape}));\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'wasm',\n  kernelFunc: unpack as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\n\nconst ENV = env();\n\n/**\n * True if SIMD is supported.\n */\n// From: https://github.com/GoogleChromeLabs/wasm-feature-detect\nENV.registerFlag('WASM_HAS_SIMD_SUPPORT', async () => {\n  try {\n    // This typed array passed in to WebAssembly.validate is WebAssembly binary\n    // code. In this case it is a small program that contains SIMD\n    // instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0, 0, 0, 1,  4, 1,   96, 0,  0, 3,\n      2, 1,  0,   10,  9, 1, 7, 0, 65, 0, 253, 15, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n});\n\n/**\n * True if threads are supported.\n */\n// From: https://github.com/GoogleChromeLabs/wasm-feature-detect\nENV.registerFlag('WASM_HAS_MULTITHREAD_SUPPORT', async () => {\n  // TODO(annxingyuan): Enable node support once this is resolved:\n  // https://github.com/tensorflow/tfjs/issues/3830\n  if (ENV.get('IS_NODE')) {\n    return false;\n  }\n\n  try {\n    // Test for transferability of SABs (needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    // This typed array is a WebAssembly program containing threaded\n    // instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n});\n","\nvar WasmBackendModuleThreadedSimd = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(WasmBackendModuleThreadedSimd) {\n  WasmBackendModuleThreadedSimd = WasmBackendModuleThreadedSimd || {};\n\nfunction GROWABLE_HEAP_I8(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAP8}function GROWABLE_HEAP_U8(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAPU8}function GROWABLE_HEAP_I16(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAP16}function GROWABLE_HEAP_I32(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAP32}function GROWABLE_HEAP_U32(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAPU32}function GROWABLE_HEAP_F32(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAPF32}function GROWABLE_HEAP_F64(){if(wasmMemory.buffer!=buffer){updateGlobalBufferAndViews(wasmMemory.buffer)}return HEAPF64}var Module=typeof WasmBackendModuleThreadedSimd!=\"undefined\"?WasmBackendModuleThreadedSimd:{};var readyPromiseResolve,readyPromiseReject;Module[\"ready\"]=new Promise(function(resolve,reject){readyPromiseResolve=resolve;readyPromiseReject=reject});var beforeListeners;if(typeof process!==\"undefined\"&&process.listeners){beforeListeners={uncaughtException:process.listeners(\"uncaughtException\"),unhandledRejection:process.listeners(\"unhandledRejection\")}}var moduleOverrides=Object.assign({},Module);var arguments_=[];var thisProgram=\"./this.program\";var quit_=(status,toThrow)=>{throw toThrow};var ENVIRONMENT_IS_WEB=typeof window==\"object\";var ENVIRONMENT_IS_WORKER=typeof importScripts==\"function\";var ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";var ENVIRONMENT_IS_PTHREAD=Module[\"ENVIRONMENT_IS_PTHREAD\"]||false;var scriptDirectory=\"\";function locateFile(path){if(Module[\"locateFile\"]){return Module[\"locateFile\"](path,scriptDirectory)}return scriptDirectory+path}var read_,readAsync,readBinary,setWindowTitle;function logExceptionOnExit(e){if(e instanceof ExitStatus)return;let toLog=e;err(\"exiting due to exception: \"+toLog)}if(ENVIRONMENT_IS_NODE){var fs=require(\"fs\");var nodePath=require(\"path\");if(ENVIRONMENT_IS_WORKER){scriptDirectory=nodePath.dirname(scriptDirectory)+\"/\"}else{scriptDirectory=__dirname+\"/\"}read_=(filename,binary)=>{filename=isFileURI(filename)?new URL(filename):nodePath.normalize(filename);return fs.readFileSync(filename,binary?undefined:\"utf8\")};readBinary=filename=>{var ret=read_(filename,true);if(!ret.buffer){ret=new Uint8Array(ret)}return ret};readAsync=(filename,onload,onerror)=>{filename=isFileURI(filename)?new URL(filename):nodePath.normalize(filename);fs.readFile(filename,function(err,data){if(err)onerror(err);else onload(data.buffer)})};if(process[\"argv\"].length>1){thisProgram=process[\"argv\"][1].replace(/\\\\/g,\"/\")}arguments_=process[\"argv\"].slice(2);process[\"on\"](\"uncaughtException\",function(ex){if(!(ex instanceof ExitStatus)){throw ex}});process[\"on\"](\"unhandledRejection\",function(reason){throw reason});quit_=(status,toThrow)=>{if(keepRuntimeAlive()){process[\"exitCode\"]=status;throw toThrow}logExceptionOnExit(toThrow);process[\"exit\"](status)};Module[\"inspect\"]=function(){return\"[Emscripten Module object]\"};let nodeWorkerThreads;try{nodeWorkerThreads=require(\"worker_threads\")}catch(e){console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?');throw e}global.Worker=nodeWorkerThreads.Worker}else if(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER){if(ENVIRONMENT_IS_WORKER){scriptDirectory=self.location.href}else if(typeof document!=\"undefined\"&&document.currentScript){scriptDirectory=document.currentScript.src}if(typeof _scriptDir !== \"undefined\" && _scriptDir){scriptDirectory=_scriptDir}if(scriptDirectory.indexOf(\"blob:\")!==0){scriptDirectory=scriptDirectory.substr(0,scriptDirectory.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1)}else{scriptDirectory=\"\"}if(!ENVIRONMENT_IS_NODE){read_=url=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,false);xhr.send(null);return xhr.responseText};if(ENVIRONMENT_IS_WORKER){readBinary=url=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,false);xhr.responseType=\"arraybuffer\";xhr.send(null);return new Uint8Array(xhr.response)}}readAsync=(url,onload,onerror)=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,true);xhr.responseType=\"arraybuffer\";xhr.onload=()=>{if(xhr.status==200||xhr.status==0&&xhr.response){onload(xhr.response);return}onerror()};xhr.onerror=onerror;xhr.send(null)}}setWindowTitle=title=>document.title=title}else{}if(ENVIRONMENT_IS_NODE){if(typeof performance==\"undefined\"){global.performance=require(\"perf_hooks\").performance}}var defaultPrint=console.log.bind(console);var defaultPrintErr=console.warn.bind(console);if(ENVIRONMENT_IS_NODE){defaultPrint=str=>fs.writeSync(1,str+\"\\n\");defaultPrintErr=str=>fs.writeSync(2,str+\"\\n\")}var out=Module[\"print\"]||defaultPrint;var err=Module[\"printErr\"]||defaultPrintErr;Object.assign(Module,moduleOverrides);moduleOverrides=null;if(Module[\"arguments\"])arguments_=Module[\"arguments\"];if(Module[\"thisProgram\"])thisProgram=Module[\"thisProgram\"];if(Module[\"quit\"])quit_=Module[\"quit\"];var POINTER_SIZE=4;var Atomics_load=Atomics.load;var Atomics_store=Atomics.store;var Atomics_compareExchange=Atomics.compareExchange;var wasmBinary;if(Module[\"wasmBinary\"])wasmBinary=Module[\"wasmBinary\"];var noExitRuntime=Module[\"noExitRuntime\"]||true;if(typeof WebAssembly!=\"object\"){abort(\"no native wasm support detected\")}var wasmMemory;var wasmModule;var ABORT=false;var EXITSTATUS;function assert(condition,text){if(!condition){abort(text)}}var UTF8Decoder=typeof TextDecoder!=\"undefined\"?new TextDecoder(\"utf8\"):undefined;function UTF8ArrayToString(heapOrArray,idx,maxBytesToRead){idx>>>=0;var endIdx=idx+maxBytesToRead;var endPtr=idx;while(heapOrArray[endPtr]&&!(endPtr>=endIdx))++endPtr;if(endPtr-idx>16&&heapOrArray.buffer&&UTF8Decoder){return UTF8Decoder.decode(heapOrArray.buffer instanceof SharedArrayBuffer?heapOrArray.slice(idx,endPtr):heapOrArray.subarray(idx,endPtr))}var str=\"\";while(idx<endPtr){var u0=heapOrArray[idx++];if(!(u0&128)){str+=String.fromCharCode(u0);continue}var u1=heapOrArray[idx++]&63;if((u0&224)==192){str+=String.fromCharCode((u0&31)<<6|u1);continue}var u2=heapOrArray[idx++]&63;if((u0&240)==224){u0=(u0&15)<<12|u1<<6|u2}else{u0=(u0&7)<<18|u1<<12|u2<<6|heapOrArray[idx++]&63}if(u0<65536){str+=String.fromCharCode(u0)}else{var ch=u0-65536;str+=String.fromCharCode(55296|ch>>10,56320|ch&1023)}}return str}function UTF8ToString(ptr,maxBytesToRead){ptr>>>=0;return ptr?UTF8ArrayToString(GROWABLE_HEAP_U8(),ptr,maxBytesToRead):\"\"}function stringToUTF8Array(str,heap,outIdx,maxBytesToWrite){outIdx>>>=0;if(!(maxBytesToWrite>0))return 0;var startIdx=outIdx;var endIdx=outIdx+maxBytesToWrite-1;for(var i=0;i<str.length;++i){var u=str.charCodeAt(i);if(u>=55296&&u<=57343){var u1=str.charCodeAt(++i);u=65536+((u&1023)<<10)|u1&1023}if(u<=127){if(outIdx>=endIdx)break;heap[outIdx++>>>0]=u}else if(u<=2047){if(outIdx+1>=endIdx)break;heap[outIdx++>>>0]=192|u>>6;heap[outIdx++>>>0]=128|u&63}else if(u<=65535){if(outIdx+2>=endIdx)break;heap[outIdx++>>>0]=224|u>>12;heap[outIdx++>>>0]=128|u>>6&63;heap[outIdx++>>>0]=128|u&63}else{if(outIdx+3>=endIdx)break;heap[outIdx++>>>0]=240|u>>18;heap[outIdx++>>>0]=128|u>>12&63;heap[outIdx++>>>0]=128|u>>6&63;heap[outIdx++>>>0]=128|u&63}}heap[outIdx>>>0]=0;return outIdx-startIdx}function stringToUTF8(str,outPtr,maxBytesToWrite){return stringToUTF8Array(str,GROWABLE_HEAP_U8(),outPtr,maxBytesToWrite)}var buffer,HEAP8,HEAPU8,HEAP16,HEAPU16,HEAP32,HEAPU32,HEAPF32,HEAPF64;if(ENVIRONMENT_IS_PTHREAD){buffer=Module[\"buffer\"]}function updateGlobalBufferAndViews(buf){buffer=buf;Module[\"HEAP8\"]=HEAP8=new Int8Array(buf);Module[\"HEAP16\"]=HEAP16=new Int16Array(buf);Module[\"HEAP32\"]=HEAP32=new Int32Array(buf);Module[\"HEAPU8\"]=HEAPU8=new Uint8Array(buf);Module[\"HEAPU16\"]=HEAPU16=new Uint16Array(buf);Module[\"HEAPU32\"]=HEAPU32=new Uint32Array(buf);Module[\"HEAPF32\"]=HEAPF32=new Float32Array(buf);Module[\"HEAPF64\"]=HEAPF64=new Float64Array(buf)}var INITIAL_MEMORY=Module[\"INITIAL_MEMORY\"]||16777216;if(ENVIRONMENT_IS_PTHREAD){wasmMemory=Module[\"wasmMemory\"];buffer=Module[\"buffer\"]}else{if(Module[\"wasmMemory\"]){wasmMemory=Module[\"wasmMemory\"]}else{wasmMemory=new WebAssembly.Memory({\"initial\":INITIAL_MEMORY/65536,\"maximum\":4294967296/65536,\"shared\":true});if(!(wasmMemory.buffer instanceof SharedArrayBuffer)){err(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\");if(ENVIRONMENT_IS_NODE){err(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\")}throw Error(\"bad memory\")}}}if(wasmMemory){buffer=wasmMemory.buffer}INITIAL_MEMORY=buffer.byteLength;updateGlobalBufferAndViews(buffer);var wasmTable;var __ATPRERUN__=[];var __ATINIT__=[];var __ATPOSTRUN__=[];var runtimeInitialized=false;function keepRuntimeAlive(){return noExitRuntime}function preRun(){if(Module[\"preRun\"]){if(typeof Module[\"preRun\"]==\"function\")Module[\"preRun\"]=[Module[\"preRun\"]];while(Module[\"preRun\"].length){addOnPreRun(Module[\"preRun\"].shift())}}callRuntimeCallbacks(__ATPRERUN__)}function initRuntime(){runtimeInitialized=true;if(ENVIRONMENT_IS_PTHREAD)return;callRuntimeCallbacks(__ATINIT__)}function postRun(){if(ENVIRONMENT_IS_PTHREAD)return;if(Module[\"postRun\"]){if(typeof Module[\"postRun\"]==\"function\")Module[\"postRun\"]=[Module[\"postRun\"]];while(Module[\"postRun\"].length){addOnPostRun(Module[\"postRun\"].shift())}}callRuntimeCallbacks(__ATPOSTRUN__)}function addOnPreRun(cb){__ATPRERUN__.unshift(cb)}function addOnInit(cb){__ATINIT__.unshift(cb)}function addOnPostRun(cb){__ATPOSTRUN__.unshift(cb)}var runDependencies=0;var runDependencyWatcher=null;var dependenciesFulfilled=null;function addRunDependency(id){runDependencies++;if(Module[\"monitorRunDependencies\"]){Module[\"monitorRunDependencies\"](runDependencies)}}function removeRunDependency(id){runDependencies--;if(Module[\"monitorRunDependencies\"]){Module[\"monitorRunDependencies\"](runDependencies)}if(runDependencies==0){if(runDependencyWatcher!==null){clearInterval(runDependencyWatcher);runDependencyWatcher=null}if(dependenciesFulfilled){var callback=dependenciesFulfilled;dependenciesFulfilled=null;callback()}}}function abort(what){if(Module[\"onAbort\"]){Module[\"onAbort\"](what)}what=\"Aborted(\"+what+\")\";err(what);ABORT=true;EXITSTATUS=1;what+=\". Build with -sASSERTIONS for more info.\";var e=new WebAssembly.RuntimeError(what);readyPromiseReject(e);throw e}var dataURIPrefix=\"data:application/octet-stream;base64,\";function isDataURI(filename){return filename.startsWith(dataURIPrefix)}function isFileURI(filename){return filename.startsWith(\"file://\")}var wasmBinaryFile;wasmBinaryFile=\"tfjs-backend-wasm-threaded-simd.wasm\";if(!isDataURI(wasmBinaryFile)){wasmBinaryFile=locateFile(wasmBinaryFile)}function getBinary(file){try{if(file==wasmBinaryFile&&wasmBinary){return new Uint8Array(wasmBinary)}if(readBinary){return readBinary(file)}throw\"both async and sync fetching of the wasm failed\"}catch(err){abort(err)}}function getBinaryPromise(){if(!wasmBinary&&(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER)){if(typeof fetch==\"function\"&&!isFileURI(wasmBinaryFile)){return fetch(wasmBinaryFile,{credentials:\"same-origin\"}).then(function(response){if(!response[\"ok\"]){throw\"failed to load wasm binary file at '\"+wasmBinaryFile+\"'\"}return response[\"arrayBuffer\"]()}).catch(function(){return getBinary(wasmBinaryFile)})}else{if(readAsync){return new Promise(function(resolve,reject){readAsync(wasmBinaryFile,function(response){resolve(new Uint8Array(response))},reject)})}}}return Promise.resolve().then(function(){return getBinary(wasmBinaryFile)})}function createWasm(){var info={\"env\":asmLibraryArg,\"wasi_snapshot_preview1\":asmLibraryArg};function receiveInstance(instance,module){var exports=instance.exports;Module[\"asm\"]=exports;registerTLSInit(Module[\"asm\"][\"_emscripten_tls_init\"]);wasmTable=Module[\"asm\"][\"__indirect_function_table\"];addOnInit(Module[\"asm\"][\"__wasm_call_ctors\"]);wasmModule=module;if(!ENVIRONMENT_IS_PTHREAD){var numWorkersToLoad=PThread.unusedWorkers.length;PThread.unusedWorkers.forEach(function(w){PThread.loadWasmModuleToWorker(w,function(){if(!--numWorkersToLoad)removeRunDependency(\"wasm-instantiate\")})})}}if(!ENVIRONMENT_IS_PTHREAD){addRunDependency(\"wasm-instantiate\")}function receiveInstantiationResult(result){receiveInstance(result[\"instance\"],result[\"module\"])}function instantiateArrayBuffer(receiver){return getBinaryPromise().then(function(binary){return WebAssembly.instantiate(binary,info)}).then(function(instance){return instance}).then(receiver,function(reason){err(\"failed to asynchronously prepare wasm: \"+reason);abort(reason)})}function instantiateAsync(){if(!wasmBinary&&typeof WebAssembly.instantiateStreaming==\"function\"&&!isDataURI(wasmBinaryFile)&&!isFileURI(wasmBinaryFile)&&!ENVIRONMENT_IS_NODE&&typeof fetch==\"function\"){return fetch(wasmBinaryFile,{credentials:\"same-origin\"}).then(function(response){var result=WebAssembly.instantiateStreaming(response,info);return result.then(receiveInstantiationResult,function(reason){err(\"wasm streaming compile failed: \"+reason);err(\"falling back to ArrayBuffer instantiation\");return instantiateArrayBuffer(receiveInstantiationResult)})})}else{return instantiateArrayBuffer(receiveInstantiationResult)}}if(Module[\"instantiateWasm\"]){try{var exports=Module[\"instantiateWasm\"](info,receiveInstance);return exports}catch(e){err(\"Module.instantiateWasm callback failed with error: \"+e);readyPromiseReject(e)}}instantiateAsync().catch(readyPromiseReject);return{}}var tempDouble;var tempI64;var ASM_CONSTS={};function ExitStatus(status){this.name=\"ExitStatus\";this.message=\"Program terminated with exit(\"+status+\")\";this.status=status}function killThread(pthread_ptr){var worker=PThread.pthreads[pthread_ptr];delete PThread.pthreads[pthread_ptr];worker.terminate();__emscripten_thread_free_data(pthread_ptr);PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(worker),1);worker.pthread_ptr=0}function cancelThread(pthread_ptr){var worker=PThread.pthreads[pthread_ptr];worker.postMessage({\"cmd\":\"cancel\"})}function cleanupThread(pthread_ptr){var worker=PThread.pthreads[pthread_ptr];assert(worker);PThread.returnWorkerToPool(worker)}function spawnThread(threadParams){var worker=PThread.getNewWorker();if(!worker){return 6}PThread.runningWorkers.push(worker);PThread.pthreads[threadParams.pthread_ptr]=worker;worker.pthread_ptr=threadParams.pthread_ptr;var msg={\"cmd\":\"run\",\"start_routine\":threadParams.startRoutine,\"arg\":threadParams.arg,\"pthread_ptr\":threadParams.pthread_ptr};worker.runPthread=()=>{if(ENVIRONMENT_IS_NODE){worker.ref()}worker.postMessage(msg,threadParams.transferList);delete worker.runPthread};if(worker.loaded){worker.runPthread()}return 0}var SYSCALLS={varargs:undefined,get:function(){SYSCALLS.varargs+=4;var ret=GROWABLE_HEAP_I32()[SYSCALLS.varargs-4>>>2];return ret},getStr:function(ptr){var ret=UTF8ToString(ptr);return ret}};function _proc_exit(code){if(ENVIRONMENT_IS_PTHREAD)return _emscripten_proxy_to_main_thread_js(1,1,code);EXITSTATUS=code;if(!keepRuntimeAlive()){PThread.terminateAllThreads();if(Module[\"onExit\"])Module[\"onExit\"](code);ABORT=true}quit_(code,new ExitStatus(code))}function exitJS(status,implicit){EXITSTATUS=status;if(!implicit){if(ENVIRONMENT_IS_PTHREAD){exitOnMainThread(status);throw\"unwind\"}else{}}_proc_exit(status)}var _exit=exitJS;function handleException(e){if(e instanceof ExitStatus||e==\"unwind\"){return EXITSTATUS}quit_(1,e)}var PThread={unusedWorkers:[],runningWorkers:[],tlsInitFunctions:[],pthreads:{},init:function(){if(ENVIRONMENT_IS_PTHREAD){PThread.initWorker()}else{PThread.initMainThread()}},initMainThread:function(){var pthreadPoolSize=8;while(pthreadPoolSize--){PThread.allocateUnusedWorker()}},initWorker:function(){noExitRuntime=false},setExitStatus:function(status){EXITSTATUS=status},terminateAllThreads:function(){for(var worker of Object.values(PThread.pthreads)){PThread.returnWorkerToPool(worker)}for(var worker of PThread.unusedWorkers){worker.terminate()}PThread.unusedWorkers=[]},returnWorkerToPool:function(worker){var pthread_ptr=worker.pthread_ptr;delete PThread.pthreads[pthread_ptr];PThread.unusedWorkers.push(worker);PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(worker),1);worker.pthread_ptr=0;if(ENVIRONMENT_IS_NODE){worker.unref()}__emscripten_thread_free_data(pthread_ptr)},receiveObjectTransfer:function(data){},threadInitTLS:function(){PThread.tlsInitFunctions.forEach(f=>f())},loadWasmModuleToWorker:function(worker,onFinishedLoading){worker.onmessage=e=>{var d=e[\"data\"];var cmd=d[\"cmd\"];if(worker.pthread_ptr)PThread.currentProxiedOperationCallerThread=worker.pthread_ptr;if(d[\"targetThread\"]&&d[\"targetThread\"]!=_pthread_self()){var targetWorker=PThread.pthreads[d.targetThread];if(targetWorker){targetWorker.postMessage(d,d[\"transferList\"])}else{err('Internal error! Worker sent a message \"'+cmd+'\" to target pthread '+d[\"targetThread\"]+\", but that thread no longer exists!\")}PThread.currentProxiedOperationCallerThread=undefined;return}if(cmd===\"processProxyingQueue\"){executeNotifiedProxyingQueue(d[\"queue\"])}else if(cmd===\"spawnThread\"){spawnThread(d)}else if(cmd===\"cleanupThread\"){cleanupThread(d[\"thread\"])}else if(cmd===\"killThread\"){killThread(d[\"thread\"])}else if(cmd===\"cancelThread\"){cancelThread(d[\"thread\"])}else if(cmd===\"loaded\"){worker.loaded=true;if(ENVIRONMENT_IS_NODE){worker.unref()}if(onFinishedLoading)onFinishedLoading(worker);if(worker.runPthread){worker.runPthread()}}else if(cmd===\"print\"){out(\"Thread \"+d[\"threadId\"]+\": \"+d[\"text\"])}else if(cmd===\"printErr\"){err(\"Thread \"+d[\"threadId\"]+\": \"+d[\"text\"])}else if(cmd===\"alert\"){alert(\"Thread \"+d[\"threadId\"]+\": \"+d[\"text\"])}else if(d.target===\"setimmediate\"){worker.postMessage(d)}else if(cmd===\"callHandler\"){Module[d[\"handler\"]](...d[\"args\"])}else if(cmd){err(\"worker sent an unknown command \"+cmd)}PThread.currentProxiedOperationCallerThread=undefined};worker.onerror=e=>{var message=\"worker sent an error!\";err(message+\" \"+e.filename+\":\"+e.lineno+\": \"+e.message);throw e};if(ENVIRONMENT_IS_NODE){worker.on(\"message\",function(data){worker.onmessage({data:data})});worker.on(\"error\",function(e){worker.onerror(e)});worker.on(\"detachedExit\",function(){})}var handlers=[];var knownHandlers=[\"onExit\",\"onAbort\",\"print\",\"printErr\"];for(var handler of knownHandlers){if(Module.hasOwnProperty(handler)){handlers.push(handler)}}worker.postMessage({\"cmd\":\"load\",\"handlers\":handlers,\"urlOrBlob\":Module[\"mainScriptUrlOrBlob\"]||_scriptDir,\"wasmMemory\":wasmMemory,\"wasmModule\":wasmModule})},allocateUnusedWorker:function(){var worker;var pthreadMainJs=locateFile(\"tfjs-backend-wasm-threaded-simd.worker.js\");worker=new Worker(pthreadMainJs);PThread.unusedWorkers.push(worker)},getNewWorker:function(){if(PThread.unusedWorkers.length==0){PThread.allocateUnusedWorker();PThread.loadWasmModuleToWorker(PThread.unusedWorkers[0])}return PThread.unusedWorkers.pop()}};Module[\"PThread\"]=PThread;function callRuntimeCallbacks(callbacks){while(callbacks.length>0){callbacks.shift()(Module)}}function establishStackSpace(){var pthread_ptr=_pthread_self();var stackTop=GROWABLE_HEAP_I32()[pthread_ptr+52>>>2];var stackSize=GROWABLE_HEAP_I32()[pthread_ptr+56>>>2];var stackMax=stackTop-stackSize;_emscripten_stack_set_limits(stackTop,stackMax);stackRestore(stackTop)}Module[\"establishStackSpace\"]=establishStackSpace;function exitOnMainThread(returnCode){if(ENVIRONMENT_IS_PTHREAD)return _emscripten_proxy_to_main_thread_js(2,0,returnCode);try{_exit(returnCode)}catch(e){handleException(e)}}var wasmTableMirror=[];function getWasmTableEntry(funcPtr){var func=wasmTableMirror[funcPtr];if(!func){if(funcPtr>=wasmTableMirror.length)wasmTableMirror.length=funcPtr+1;wasmTableMirror[funcPtr]=func=wasmTable.get(funcPtr)}return func}function invokeEntryPoint(ptr,arg){var result=getWasmTableEntry(ptr)(arg);if(keepRuntimeAlive()){PThread.setExitStatus(result)}else{__emscripten_thread_exit(result)}}Module[\"invokeEntryPoint\"]=invokeEntryPoint;function registerTLSInit(tlsInitFunc){PThread.tlsInitFunctions.push(tlsInitFunc)}function ___emscripten_init_main_thread_js(tb){__emscripten_thread_init(tb,!ENVIRONMENT_IS_WORKER,1,!ENVIRONMENT_IS_WEB);PThread.threadInitTLS()}function ___emscripten_thread_cleanup(thread){if(!ENVIRONMENT_IS_PTHREAD)cleanupThread(thread);else postMessage({\"cmd\":\"cleanupThread\",\"thread\":thread})}function pthreadCreateProxied(pthread_ptr,attr,startRoutine,arg){if(ENVIRONMENT_IS_PTHREAD)return _emscripten_proxy_to_main_thread_js(3,1,pthread_ptr,attr,startRoutine,arg);return ___pthread_create_js(pthread_ptr,attr,startRoutine,arg)}function ___pthread_create_js(pthread_ptr,attr,startRoutine,arg){if(typeof SharedArrayBuffer==\"undefined\"){err(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\");return 6}var transferList=[];var error=0;if(ENVIRONMENT_IS_PTHREAD&&(transferList.length===0||error)){return pthreadCreateProxied(pthread_ptr,attr,startRoutine,arg)}if(error)return error;var threadParams={startRoutine:startRoutine,pthread_ptr:pthread_ptr,arg:arg,transferList:transferList};if(ENVIRONMENT_IS_PTHREAD){threadParams.cmd=\"spawnThread\";postMessage(threadParams,transferList);return 0}return spawnThread(threadParams)}function __emscripten_default_pthread_stack_size(){return 65536}var nowIsMonotonic=true;function __emscripten_get_now_is_monotonic(){return nowIsMonotonic}function executeNotifiedProxyingQueue(queue){Atomics.store(GROWABLE_HEAP_I32(),queue>>2,1);if(_pthread_self()){__emscripten_proxy_execute_task_queue(queue)}Atomics.compareExchange(GROWABLE_HEAP_I32(),queue>>2,1,0)}Module[\"executeNotifiedProxyingQueue\"]=executeNotifiedProxyingQueue;function __emscripten_notify_task_queue(targetThreadId,currThreadId,mainThreadId,queue){if(targetThreadId==currThreadId){setTimeout(()=>executeNotifiedProxyingQueue(queue))}else if(ENVIRONMENT_IS_PTHREAD){postMessage({\"targetThread\":targetThreadId,\"cmd\":\"processProxyingQueue\",\"queue\":queue})}else{var worker=PThread.pthreads[targetThreadId];if(!worker){return}worker.postMessage({\"cmd\":\"processProxyingQueue\",\"queue\":queue})}return 1}function __emscripten_set_offscreencanvas_size(target,width,height){return-1}function _abort(){abort(\"\")}function warnOnce(text){if(!warnOnce.shown)warnOnce.shown={};if(!warnOnce.shown[text]){warnOnce.shown[text]=1;if(ENVIRONMENT_IS_NODE)text=\"warning: \"+text;err(text)}}function _emscripten_check_blocking_allowed(){if(ENVIRONMENT_IS_NODE)return;if(ENVIRONMENT_IS_WORKER)return;warnOnce(\"Blocking on the main thread is very dangerous, see https://emscripten.org/docs/porting/pthreads.html#blocking-on-the-main-browser-thread\")}function _emscripten_date_now(){return Date.now()}function getHeapMax(){return 4294901760}function _emscripten_get_heap_max(){return getHeapMax()}var _emscripten_get_now;if(ENVIRONMENT_IS_NODE){_emscripten_get_now=()=>{var t=process[\"hrtime\"]();return t[0]*1e3+t[1]/1e6}}else _emscripten_get_now=()=>performance.timeOrigin+performance.now();function _emscripten_memcpy_big(dest,src,num){GROWABLE_HEAP_U8().copyWithin(dest>>>0,src>>>0,src+num>>>0)}function _emscripten_num_logical_cores(){if(ENVIRONMENT_IS_NODE)return require(\"os\").cpus().length;return navigator[\"hardwareConcurrency\"]}function withStackSave(f){var stack=stackSave();var ret=f();stackRestore(stack);return ret}function _emscripten_proxy_to_main_thread_js(index,sync){var numCallArgs=arguments.length-2;var outerArgs=arguments;return withStackSave(()=>{var serializedNumCallArgs=numCallArgs;var args=stackAlloc(serializedNumCallArgs*8);var b=args>>3;for(var i=0;i<numCallArgs;i++){var arg=outerArgs[2+i];GROWABLE_HEAP_F64()[b+i>>>0]=arg}return _emscripten_run_in_main_runtime_thread_js(index,serializedNumCallArgs,args,sync)})}var _emscripten_receive_on_main_thread_js_callArgs=[];function _emscripten_receive_on_main_thread_js(index,numCallArgs,args){_emscripten_receive_on_main_thread_js_callArgs.length=numCallArgs;var b=args>>3;for(var i=0;i<numCallArgs;i++){_emscripten_receive_on_main_thread_js_callArgs[i]=GROWABLE_HEAP_F64()[b+i>>>0]}var isEmAsmConst=index<0;var func=!isEmAsmConst?proxiedFunctionTable[index]:ASM_CONSTS[-index-1];return func.apply(null,_emscripten_receive_on_main_thread_js_callArgs)}function emscripten_realloc_buffer(size){try{wasmMemory.grow(size-buffer.byteLength+65535>>>16);updateGlobalBufferAndViews(wasmMemory.buffer);return 1}catch(e){}}function _emscripten_resize_heap(requestedSize){var oldSize=GROWABLE_HEAP_U8().length;requestedSize=requestedSize>>>0;if(requestedSize<=oldSize){return false}var maxHeapSize=getHeapMax();if(requestedSize>maxHeapSize){return false}let alignUp=(x,multiple)=>x+(multiple-x%multiple)%multiple;for(var cutDown=1;cutDown<=4;cutDown*=2){var overGrownHeapSize=oldSize*(1+.2/cutDown);overGrownHeapSize=Math.min(overGrownHeapSize,requestedSize+100663296);var newSize=Math.min(maxHeapSize,alignUp(Math.max(requestedSize,overGrownHeapSize),65536));var replacement=emscripten_realloc_buffer(newSize);if(replacement){return true}}return false}function _emscripten_unwind_to_js_event_loop(){throw\"unwind\"}function _fd_close(fd){if(ENVIRONMENT_IS_PTHREAD)return _emscripten_proxy_to_main_thread_js(4,1,fd);return 52}function _fd_seek(fd,offset_low,offset_high,whence,newOffset){if(ENVIRONMENT_IS_PTHREAD)return _emscripten_proxy_to_main_thread_js(5,1,fd,offset_low,offset_high,whence,newOffset);return 70}var printCharBuffers=[null,[],[]];function printChar(stream,curr){var buffer=printCharBuffers[stream];if(curr===0||curr===10){(stream===1?out:err)(UTF8ArrayToString(buffer,0));buffer.length=0}else{buffer.push(curr)}}function _fd_write(fd,iov,iovcnt,pnum){if(ENVIRONMENT_IS_PTHREAD)return _emscripten_proxy_to_main_thread_js(6,1,fd,iov,iovcnt,pnum);var num=0;for(var i=0;i<iovcnt;i++){var ptr=GROWABLE_HEAP_U32()[iov>>>2];var len=GROWABLE_HEAP_U32()[iov+4>>>2];iov+=8;for(var j=0;j<len;j++){printChar(fd,GROWABLE_HEAP_U8()[ptr+j>>>0])}num+=len}GROWABLE_HEAP_U32()[pnum>>>2]=num;return 0}function getCFunc(ident){var func=Module[\"_\"+ident];return func}function writeArrayToMemory(array,buffer){GROWABLE_HEAP_I8().set(array,buffer>>>0)}function ccall(ident,returnType,argTypes,args,opts){var toC={\"string\":str=>{var ret=0;if(str!==null&&str!==undefined&&str!==0){var len=(str.length<<2)+1;ret=stackAlloc(len);stringToUTF8(str,ret,len)}return ret},\"array\":arr=>{var ret=stackAlloc(arr.length);writeArrayToMemory(arr,ret);return ret}};function convertReturnValue(ret){if(returnType===\"string\"){return UTF8ToString(ret)}if(returnType===\"boolean\")return Boolean(ret);return ret}var func=getCFunc(ident);var cArgs=[];var stack=0;if(args){for(var i=0;i<args.length;i++){var converter=toC[argTypes[i]];if(converter){if(stack===0)stack=stackSave();cArgs[i]=converter(args[i])}else{cArgs[i]=args[i]}}}var ret=func.apply(null,cArgs);function onDone(ret){if(stack!==0)stackRestore(stack);return convertReturnValue(ret)}ret=onDone(ret);return ret}function cwrap(ident,returnType,argTypes,opts){argTypes=argTypes||[];var numericArgs=argTypes.every(type=>type===\"number\"||type===\"boolean\");var numericRet=returnType!==\"string\";if(numericRet&&numericArgs&&!opts){return getCFunc(ident)}return function(){return ccall(ident,returnType,argTypes,arguments,opts)}}PThread.init();var proxiedFunctionTable=[null,_proc_exit,exitOnMainThread,pthreadCreateProxied,_fd_close,_fd_seek,_fd_write];var asmLibraryArg={\"__emscripten_init_main_thread_js\":___emscripten_init_main_thread_js,\"__emscripten_thread_cleanup\":___emscripten_thread_cleanup,\"__pthread_create_js\":___pthread_create_js,\"_emscripten_default_pthread_stack_size\":__emscripten_default_pthread_stack_size,\"_emscripten_get_now_is_monotonic\":__emscripten_get_now_is_monotonic,\"_emscripten_notify_task_queue\":__emscripten_notify_task_queue,\"_emscripten_set_offscreencanvas_size\":__emscripten_set_offscreencanvas_size,\"abort\":_abort,\"emscripten_check_blocking_allowed\":_emscripten_check_blocking_allowed,\"emscripten_date_now\":_emscripten_date_now,\"emscripten_get_heap_max\":_emscripten_get_heap_max,\"emscripten_get_now\":_emscripten_get_now,\"emscripten_memcpy_big\":_emscripten_memcpy_big,\"emscripten_num_logical_cores\":_emscripten_num_logical_cores,\"emscripten_receive_on_main_thread_js\":_emscripten_receive_on_main_thread_js,\"emscripten_resize_heap\":_emscripten_resize_heap,\"emscripten_unwind_to_js_event_loop\":_emscripten_unwind_to_js_event_loop,\"exit\":_exit,\"fd_close\":_fd_close,\"fd_seek\":_fd_seek,\"fd_write\":_fd_write,\"memory\":wasmMemory||Module[\"wasmMemory\"]};var asm=createWasm();var ___wasm_call_ctors=Module[\"___wasm_call_ctors\"]=function(){return(___wasm_call_ctors=Module[\"___wasm_call_ctors\"]=Module[\"asm\"][\"__wasm_call_ctors\"]).apply(null,arguments)};var _init=Module[\"_init\"]=function(){return(_init=Module[\"_init\"]=Module[\"asm\"][\"init\"]).apply(null,arguments)};var _init_with_threads_count=Module[\"_init_with_threads_count\"]=function(){return(_init_with_threads_count=Module[\"_init_with_threads_count\"]=Module[\"asm\"][\"init_with_threads_count\"]).apply(null,arguments)};var _get_threads_count=Module[\"_get_threads_count\"]=function(){return(_get_threads_count=Module[\"_get_threads_count\"]=Module[\"asm\"][\"get_threads_count\"]).apply(null,arguments)};var _register_tensor=Module[\"_register_tensor\"]=function(){return(_register_tensor=Module[\"_register_tensor\"]=Module[\"asm\"][\"register_tensor\"]).apply(null,arguments)};var _dispose_data=Module[\"_dispose_data\"]=function(){return(_dispose_data=Module[\"_dispose_data\"]=Module[\"asm\"][\"dispose_data\"]).apply(null,arguments)};var _dispose=Module[\"_dispose\"]=function(){return(_dispose=Module[\"_dispose\"]=Module[\"asm\"][\"dispose\"]).apply(null,arguments)};var _Abs=Module[\"_Abs\"]=function(){return(_Abs=Module[\"_Abs\"]=Module[\"asm\"][\"Abs\"]).apply(null,arguments)};var _Acos=Module[\"_Acos\"]=function(){return(_Acos=Module[\"_Acos\"]=Module[\"asm\"][\"Acos\"]).apply(null,arguments)};var _Acosh=Module[\"_Acosh\"]=function(){return(_Acosh=Module[\"_Acosh\"]=Module[\"asm\"][\"Acosh\"]).apply(null,arguments)};var _Add=Module[\"_Add\"]=function(){return(_Add=Module[\"_Add\"]=Module[\"asm\"][\"Add\"]).apply(null,arguments)};var _AddN=Module[\"_AddN\"]=function(){return(_AddN=Module[\"_AddN\"]=Module[\"asm\"][\"AddN\"]).apply(null,arguments)};var _All=Module[\"_All\"]=function(){return(_All=Module[\"_All\"]=Module[\"asm\"][\"All\"]).apply(null,arguments)};var _Any=Module[\"_Any\"]=function(){return(_Any=Module[\"_Any\"]=Module[\"asm\"][\"Any\"]).apply(null,arguments)};var _ArgMax=Module[\"_ArgMax\"]=function(){return(_ArgMax=Module[\"_ArgMax\"]=Module[\"asm\"][\"ArgMax\"]).apply(null,arguments)};var _ArgMin=Module[\"_ArgMin\"]=function(){return(_ArgMin=Module[\"_ArgMin\"]=Module[\"asm\"][\"ArgMin\"]).apply(null,arguments)};var _Asin=Module[\"_Asin\"]=function(){return(_Asin=Module[\"_Asin\"]=Module[\"asm\"][\"Asin\"]).apply(null,arguments)};var _Asinh=Module[\"_Asinh\"]=function(){return(_Asinh=Module[\"_Asinh\"]=Module[\"asm\"][\"Asinh\"]).apply(null,arguments)};var _Atan=Module[\"_Atan\"]=function(){return(_Atan=Module[\"_Atan\"]=Module[\"asm\"][\"Atan\"]).apply(null,arguments)};var _Atan2=Module[\"_Atan2\"]=function(){return(_Atan2=Module[\"_Atan2\"]=Module[\"asm\"][\"Atan2\"]).apply(null,arguments)};var _Atanh=Module[\"_Atanh\"]=function(){return(_Atanh=Module[\"_Atanh\"]=Module[\"asm\"][\"Atanh\"]).apply(null,arguments)};var _AvgPool=Module[\"_AvgPool\"]=function(){return(_AvgPool=Module[\"_AvgPool\"]=Module[\"asm\"][\"AvgPool\"]).apply(null,arguments)};var _AvgPool3D=Module[\"_AvgPool3D\"]=function(){return(_AvgPool3D=Module[\"_AvgPool3D\"]=Module[\"asm\"][\"AvgPool3D\"]).apply(null,arguments)};var _AvgPool3DGrad=Module[\"_AvgPool3DGrad\"]=function(){return(_AvgPool3DGrad=Module[\"_AvgPool3DGrad\"]=Module[\"asm\"][\"AvgPool3DGrad\"]).apply(null,arguments)};var _AvgPoolGrad=Module[\"_AvgPoolGrad\"]=function(){return(_AvgPoolGrad=Module[\"_AvgPoolGrad\"]=Module[\"asm\"][\"AvgPoolGrad\"]).apply(null,arguments)};var _BatchMatMul=Module[\"_BatchMatMul\"]=function(){return(_BatchMatMul=Module[\"_BatchMatMul\"]=Module[\"asm\"][\"BatchMatMul\"]).apply(null,arguments)};var _Bincount=Module[\"_Bincount\"]=function(){return(_Bincount=Module[\"_Bincount\"]=Module[\"asm\"][\"Bincount\"]).apply(null,arguments)};var _BitwiseAnd=Module[\"_BitwiseAnd\"]=function(){return(_BitwiseAnd=Module[\"_BitwiseAnd\"]=Module[\"asm\"][\"BitwiseAnd\"]).apply(null,arguments)};var _Ceil=Module[\"_Ceil\"]=function(){return(_Ceil=Module[\"_Ceil\"]=Module[\"asm\"][\"Ceil\"]).apply(null,arguments)};var _ClipByValue=Module[\"_ClipByValue\"]=function(){return(_ClipByValue=Module[\"_ClipByValue\"]=Module[\"asm\"][\"ClipByValue\"]).apply(null,arguments)};var _Conv2D=Module[\"_Conv2D\"]=function(){return(_Conv2D=Module[\"_Conv2D\"]=Module[\"asm\"][\"Conv2D\"]).apply(null,arguments)};var _Conv2DBackpropInput=Module[\"_Conv2DBackpropInput\"]=function(){return(_Conv2DBackpropInput=Module[\"_Conv2DBackpropInput\"]=Module[\"asm\"][\"Conv2DBackpropInput\"]).apply(null,arguments)};var _Conv3D=Module[\"_Conv3D\"]=function(){return(_Conv3D=Module[\"_Conv3D\"]=Module[\"asm\"][\"Conv3D\"]).apply(null,arguments)};var _Conv3DBackpropFilterV2=Module[\"_Conv3DBackpropFilterV2\"]=function(){return(_Conv3DBackpropFilterV2=Module[\"_Conv3DBackpropFilterV2\"]=Module[\"asm\"][\"Conv3DBackpropFilterV2\"]).apply(null,arguments)};var _Conv3DBackpropInputV2=Module[\"_Conv3DBackpropInputV2\"]=function(){return(_Conv3DBackpropInputV2=Module[\"_Conv3DBackpropInputV2\"]=Module[\"asm\"][\"Conv3DBackpropInputV2\"]).apply(null,arguments)};var _Cos=Module[\"_Cos\"]=function(){return(_Cos=Module[\"_Cos\"]=Module[\"asm\"][\"Cos\"]).apply(null,arguments)};var _Cosh=Module[\"_Cosh\"]=function(){return(_Cosh=Module[\"_Cosh\"]=Module[\"asm\"][\"Cosh\"]).apply(null,arguments)};var _CropAndResize=Module[\"_CropAndResize\"]=function(){return(_CropAndResize=Module[\"_CropAndResize\"]=Module[\"asm\"][\"CropAndResize\"]).apply(null,arguments)};var _Cumprod=Module[\"_Cumprod\"]=function(){return(_Cumprod=Module[\"_Cumprod\"]=Module[\"asm\"][\"Cumprod\"]).apply(null,arguments)};var _Cumsum=Module[\"_Cumsum\"]=function(){return(_Cumsum=Module[\"_Cumsum\"]=Module[\"asm\"][\"Cumsum\"]).apply(null,arguments)};var _DenseBincount=Module[\"_DenseBincount\"]=function(){return(_DenseBincount=Module[\"_DenseBincount\"]=Module[\"asm\"][\"DenseBincount\"]).apply(null,arguments)};var _DepthToSpace=Module[\"_DepthToSpace\"]=function(){return(_DepthToSpace=Module[\"_DepthToSpace\"]=Module[\"asm\"][\"DepthToSpace\"]).apply(null,arguments)};var _DepthwiseConv2dNative=Module[\"_DepthwiseConv2dNative\"]=function(){return(_DepthwiseConv2dNative=Module[\"_DepthwiseConv2dNative\"]=Module[\"asm\"][\"DepthwiseConv2dNative\"]).apply(null,arguments)};var _Diag=Module[\"_Diag\"]=function(){return(_Diag=Module[\"_Diag\"]=Module[\"asm\"][\"Diag\"]).apply(null,arguments)};var _Dilation2D=Module[\"_Dilation2D\"]=function(){return(_Dilation2D=Module[\"_Dilation2D\"]=Module[\"asm\"][\"Dilation2D\"]).apply(null,arguments)};var _Dilation2DBackpropFilter=Module[\"_Dilation2DBackpropFilter\"]=function(){return(_Dilation2DBackpropFilter=Module[\"_Dilation2DBackpropFilter\"]=Module[\"asm\"][\"Dilation2DBackpropFilter\"]).apply(null,arguments)};var _Dilation2DBackpropInput=Module[\"_Dilation2DBackpropInput\"]=function(){return(_Dilation2DBackpropInput=Module[\"_Dilation2DBackpropInput\"]=Module[\"asm\"][\"Dilation2DBackpropInput\"]).apply(null,arguments)};var _Elu=Module[\"_Elu\"]=function(){return(_Elu=Module[\"_Elu\"]=Module[\"asm\"][\"Elu\"]).apply(null,arguments)};var _EluGrad=Module[\"_EluGrad\"]=function(){return(_EluGrad=Module[\"_EluGrad\"]=Module[\"asm\"][\"EluGrad\"]).apply(null,arguments)};var _Equal=Module[\"_Equal\"]=function(){return(_Equal=Module[\"_Equal\"]=Module[\"asm\"][\"Equal\"]).apply(null,arguments)};var _Erf=Module[\"_Erf\"]=function(){return(_Erf=Module[\"_Erf\"]=Module[\"asm\"][\"Erf\"]).apply(null,arguments)};var _Exp=Module[\"_Exp\"]=function(){return(_Exp=Module[\"_Exp\"]=Module[\"asm\"][\"Exp\"]).apply(null,arguments)};var _Expm1=Module[\"_Expm1\"]=function(){return(_Expm1=Module[\"_Expm1\"]=Module[\"asm\"][\"Expm1\"]).apply(null,arguments)};var _FlipLeftRight=Module[\"_FlipLeftRight\"]=function(){return(_FlipLeftRight=Module[\"_FlipLeftRight\"]=Module[\"asm\"][\"FlipLeftRight\"]).apply(null,arguments)};var _Floor=Module[\"_Floor\"]=function(){return(_Floor=Module[\"_Floor\"]=Module[\"asm\"][\"Floor\"]).apply(null,arguments)};var _FloorDiv=Module[\"_FloorDiv\"]=function(){return(_FloorDiv=Module[\"_FloorDiv\"]=Module[\"asm\"][\"FloorDiv\"]).apply(null,arguments)};var _FusedBatchNorm=Module[\"_FusedBatchNorm\"]=function(){return(_FusedBatchNorm=Module[\"_FusedBatchNorm\"]=Module[\"asm\"][\"FusedBatchNorm\"]).apply(null,arguments)};var _FusedConv2D=Module[\"_FusedConv2D\"]=function(){return(_FusedConv2D=Module[\"_FusedConv2D\"]=Module[\"asm\"][\"FusedConv2D\"]).apply(null,arguments)};var _FusedDepthwiseConv2D=Module[\"_FusedDepthwiseConv2D\"]=function(){return(_FusedDepthwiseConv2D=Module[\"_FusedDepthwiseConv2D\"]=Module[\"asm\"][\"FusedDepthwiseConv2D\"]).apply(null,arguments)};var _Gather=Module[\"_Gather\"]=function(){return(_Gather=Module[\"_Gather\"]=Module[\"asm\"][\"Gather\"]).apply(null,arguments)};var _GatherNd=Module[\"_GatherNd\"]=function(){return(_GatherNd=Module[\"_GatherNd\"]=Module[\"asm\"][\"GatherNd\"]).apply(null,arguments)};var _Greater=Module[\"_Greater\"]=function(){return(_Greater=Module[\"_Greater\"]=Module[\"asm\"][\"Greater\"]).apply(null,arguments)};var _GreaterEqual=Module[\"_GreaterEqual\"]=function(){return(_GreaterEqual=Module[\"_GreaterEqual\"]=Module[\"asm\"][\"GreaterEqual\"]).apply(null,arguments)};var _IsFinite=Module[\"_IsFinite\"]=function(){return(_IsFinite=Module[\"_IsFinite\"]=Module[\"asm\"][\"IsFinite\"]).apply(null,arguments)};var _IsInf=Module[\"_IsInf\"]=function(){return(_IsInf=Module[\"_IsInf\"]=Module[\"asm\"][\"IsInf\"]).apply(null,arguments)};var _IsNan=Module[\"_IsNan\"]=function(){return(_IsNan=Module[\"_IsNan\"]=Module[\"asm\"][\"IsNan\"]).apply(null,arguments)};var _LRN=Module[\"_LRN\"]=function(){return(_LRN=Module[\"_LRN\"]=Module[\"asm\"][\"LRN\"]).apply(null,arguments)};var _LRNGrad=Module[\"_LRNGrad\"]=function(){return(_LRNGrad=Module[\"_LRNGrad\"]=Module[\"asm\"][\"LRNGrad\"]).apply(null,arguments)};var _LeakyRelu=Module[\"_LeakyRelu\"]=function(){return(_LeakyRelu=Module[\"_LeakyRelu\"]=Module[\"asm\"][\"LeakyRelu\"]).apply(null,arguments)};var _Less=Module[\"_Less\"]=function(){return(_Less=Module[\"_Less\"]=Module[\"asm\"][\"Less\"]).apply(null,arguments)};var _LessEqual=Module[\"_LessEqual\"]=function(){return(_LessEqual=Module[\"_LessEqual\"]=Module[\"asm\"][\"LessEqual\"]).apply(null,arguments)};var _LinSpace=Module[\"_LinSpace\"]=function(){return(_LinSpace=Module[\"_LinSpace\"]=Module[\"asm\"][\"LinSpace\"]).apply(null,arguments)};var _Log=Module[\"_Log\"]=function(){return(_Log=Module[\"_Log\"]=Module[\"asm\"][\"Log\"]).apply(null,arguments)};var _Log1p=Module[\"_Log1p\"]=function(){return(_Log1p=Module[\"_Log1p\"]=Module[\"asm\"][\"Log1p\"]).apply(null,arguments)};var _LogicalAnd=Module[\"_LogicalAnd\"]=function(){return(_LogicalAnd=Module[\"_LogicalAnd\"]=Module[\"asm\"][\"LogicalAnd\"]).apply(null,arguments)};var _LogicalNot=Module[\"_LogicalNot\"]=function(){return(_LogicalNot=Module[\"_LogicalNot\"]=Module[\"asm\"][\"LogicalNot\"]).apply(null,arguments)};var _LogicalOr=Module[\"_LogicalOr\"]=function(){return(_LogicalOr=Module[\"_LogicalOr\"]=Module[\"asm\"][\"LogicalOr\"]).apply(null,arguments)};var _LogicalXor=Module[\"_LogicalXor\"]=function(){return(_LogicalXor=Module[\"_LogicalXor\"]=Module[\"asm\"][\"LogicalXor\"]).apply(null,arguments)};var _Max=Module[\"_Max\"]=function(){return(_Max=Module[\"_Max\"]=Module[\"asm\"][\"Max\"]).apply(null,arguments)};var _MaxPool=Module[\"_MaxPool\"]=function(){return(_MaxPool=Module[\"_MaxPool\"]=Module[\"asm\"][\"MaxPool\"]).apply(null,arguments)};var _MaxPool3D=Module[\"_MaxPool3D\"]=function(){return(_MaxPool3D=Module[\"_MaxPool3D\"]=Module[\"asm\"][\"MaxPool3D\"]).apply(null,arguments)};var _MaxPool3DGrad=Module[\"_MaxPool3DGrad\"]=function(){return(_MaxPool3DGrad=Module[\"_MaxPool3DGrad\"]=Module[\"asm\"][\"MaxPool3DGrad\"]).apply(null,arguments)};var _MaxPoolGrad=Module[\"_MaxPoolGrad\"]=function(){return(_MaxPoolGrad=Module[\"_MaxPoolGrad\"]=Module[\"asm\"][\"MaxPoolGrad\"]).apply(null,arguments)};var _MaxPoolWithArgmax=Module[\"_MaxPoolWithArgmax\"]=function(){return(_MaxPoolWithArgmax=Module[\"_MaxPoolWithArgmax\"]=Module[\"asm\"][\"MaxPoolWithArgmax\"]).apply(null,arguments)};var _Maximum=Module[\"_Maximum\"]=function(){return(_Maximum=Module[\"_Maximum\"]=Module[\"asm\"][\"Maximum\"]).apply(null,arguments)};var _Mean=Module[\"_Mean\"]=function(){return(_Mean=Module[\"_Mean\"]=Module[\"asm\"][\"Mean\"]).apply(null,arguments)};var _Min=Module[\"_Min\"]=function(){return(_Min=Module[\"_Min\"]=Module[\"asm\"][\"Min\"]).apply(null,arguments)};var _Minimum=Module[\"_Minimum\"]=function(){return(_Minimum=Module[\"_Minimum\"]=Module[\"asm\"][\"Minimum\"]).apply(null,arguments)};var _MirrorPad=Module[\"_MirrorPad\"]=function(){return(_MirrorPad=Module[\"_MirrorPad\"]=Module[\"asm\"][\"MirrorPad\"]).apply(null,arguments)};var _Mod=Module[\"_Mod\"]=function(){return(_Mod=Module[\"_Mod\"]=Module[\"asm\"][\"Mod\"]).apply(null,arguments)};var _Multinomial=Module[\"_Multinomial\"]=function(){return(_Multinomial=Module[\"_Multinomial\"]=Module[\"asm\"][\"Multinomial\"]).apply(null,arguments)};var _Multiply=Module[\"_Multiply\"]=function(){return(_Multiply=Module[\"_Multiply\"]=Module[\"asm\"][\"Multiply\"]).apply(null,arguments)};var _Neg=Module[\"_Neg\"]=function(){return(_Neg=Module[\"_Neg\"]=Module[\"asm\"][\"Neg\"]).apply(null,arguments)};var _NonMaxSuppressionV3=Module[\"_NonMaxSuppressionV3\"]=function(){return(_NonMaxSuppressionV3=Module[\"_NonMaxSuppressionV3\"]=Module[\"asm\"][\"NonMaxSuppressionV3\"]).apply(null,arguments)};var _NonMaxSuppressionV4=Module[\"_NonMaxSuppressionV4\"]=function(){return(_NonMaxSuppressionV4=Module[\"_NonMaxSuppressionV4\"]=Module[\"asm\"][\"NonMaxSuppressionV4\"]).apply(null,arguments)};var _NonMaxSuppressionV5=Module[\"_NonMaxSuppressionV5\"]=function(){return(_NonMaxSuppressionV5=Module[\"_NonMaxSuppressionV5\"]=Module[\"asm\"][\"NonMaxSuppressionV5\"]).apply(null,arguments)};var _NotEqual=Module[\"_NotEqual\"]=function(){return(_NotEqual=Module[\"_NotEqual\"]=Module[\"asm\"][\"NotEqual\"]).apply(null,arguments)};var _OneHot=Module[\"_OneHot\"]=function(){return(_OneHot=Module[\"_OneHot\"]=Module[\"asm\"][\"OneHot\"]).apply(null,arguments)};var _PadV2=Module[\"_PadV2\"]=function(){return(_PadV2=Module[\"_PadV2\"]=Module[\"asm\"][\"PadV2\"]).apply(null,arguments)};var _Pow=Module[\"_Pow\"]=function(){return(_Pow=Module[\"_Pow\"]=Module[\"asm\"][\"Pow\"]).apply(null,arguments)};var _Prelu=Module[\"_Prelu\"]=function(){return(_Prelu=Module[\"_Prelu\"]=Module[\"asm\"][\"Prelu\"]).apply(null,arguments)};var _Prod=Module[\"_Prod\"]=function(){return(_Prod=Module[\"_Prod\"]=Module[\"asm\"][\"Prod\"]).apply(null,arguments)};var _RealDiv=Module[\"_RealDiv\"]=function(){return(_RealDiv=Module[\"_RealDiv\"]=Module[\"asm\"][\"RealDiv\"]).apply(null,arguments)};var _Reciprocal=Module[\"_Reciprocal\"]=function(){return(_Reciprocal=Module[\"_Reciprocal\"]=Module[\"asm\"][\"Reciprocal\"]).apply(null,arguments)};var _Relu=Module[\"_Relu\"]=function(){return(_Relu=Module[\"_Relu\"]=Module[\"asm\"][\"Relu\"]).apply(null,arguments)};var _Relu6=Module[\"_Relu6\"]=function(){return(_Relu6=Module[\"_Relu6\"]=Module[\"asm\"][\"Relu6\"]).apply(null,arguments)};var _ResizeBilinear=Module[\"_ResizeBilinear\"]=function(){return(_ResizeBilinear=Module[\"_ResizeBilinear\"]=Module[\"asm\"][\"ResizeBilinear\"]).apply(null,arguments)};var _ResizeBilinearGrad=Module[\"_ResizeBilinearGrad\"]=function(){return(_ResizeBilinearGrad=Module[\"_ResizeBilinearGrad\"]=Module[\"asm\"][\"ResizeBilinearGrad\"]).apply(null,arguments)};var _ResizeNearestNeighbor=Module[\"_ResizeNearestNeighbor\"]=function(){return(_ResizeNearestNeighbor=Module[\"_ResizeNearestNeighbor\"]=Module[\"asm\"][\"ResizeNearestNeighbor\"]).apply(null,arguments)};var _ResizeNearestNeighborGrad=Module[\"_ResizeNearestNeighborGrad\"]=function(){return(_ResizeNearestNeighborGrad=Module[\"_ResizeNearestNeighborGrad\"]=Module[\"asm\"][\"ResizeNearestNeighborGrad\"]).apply(null,arguments)};var _Reverse=Module[\"_Reverse\"]=function(){return(_Reverse=Module[\"_Reverse\"]=Module[\"asm\"][\"Reverse\"]).apply(null,arguments)};var _RotateWithOffset=Module[\"_RotateWithOffset\"]=function(){return(_RotateWithOffset=Module[\"_RotateWithOffset\"]=Module[\"asm\"][\"RotateWithOffset\"]).apply(null,arguments)};var _Round=Module[\"_Round\"]=function(){return(_Round=Module[\"_Round\"]=Module[\"asm\"][\"Round\"]).apply(null,arguments)};var _Rsqrt=Module[\"_Rsqrt\"]=function(){return(_Rsqrt=Module[\"_Rsqrt\"]=Module[\"asm\"][\"Rsqrt\"]).apply(null,arguments)};var _ScatterNd=Module[\"_ScatterNd\"]=function(){return(_ScatterNd=Module[\"_ScatterNd\"]=Module[\"asm\"][\"ScatterNd\"]).apply(null,arguments)};var _SearchSorted=Module[\"_SearchSorted\"]=function(){return(_SearchSorted=Module[\"_SearchSorted\"]=Module[\"asm\"][\"SearchSorted\"]).apply(null,arguments)};var _SelectV2=Module[\"_SelectV2\"]=function(){return(_SelectV2=Module[\"_SelectV2\"]=Module[\"asm\"][\"SelectV2\"]).apply(null,arguments)};var _Selu=Module[\"_Selu\"]=function(){return(_Selu=Module[\"_Selu\"]=Module[\"asm\"][\"Selu\"]).apply(null,arguments)};var _Sigmoid=Module[\"_Sigmoid\"]=function(){return(_Sigmoid=Module[\"_Sigmoid\"]=Module[\"asm\"][\"Sigmoid\"]).apply(null,arguments)};var _Sign=Module[\"_Sign\"]=function(){return(_Sign=Module[\"_Sign\"]=Module[\"asm\"][\"Sign\"]).apply(null,arguments)};var _Sin=Module[\"_Sin\"]=function(){return(_Sin=Module[\"_Sin\"]=Module[\"asm\"][\"Sin\"]).apply(null,arguments)};var _Sinh=Module[\"_Sinh\"]=function(){return(_Sinh=Module[\"_Sinh\"]=Module[\"asm\"][\"Sinh\"]).apply(null,arguments)};var _Softmax=Module[\"_Softmax\"]=function(){return(_Softmax=Module[\"_Softmax\"]=Module[\"asm\"][\"Softmax\"]).apply(null,arguments)};var _Softplus=Module[\"_Softplus\"]=function(){return(_Softplus=Module[\"_Softplus\"]=Module[\"asm\"][\"Softplus\"]).apply(null,arguments)};var _SparseFillEmptyRows=Module[\"_SparseFillEmptyRows\"]=function(){return(_SparseFillEmptyRows=Module[\"_SparseFillEmptyRows\"]=Module[\"asm\"][\"SparseFillEmptyRows\"]).apply(null,arguments)};var _SparseReshape=Module[\"_SparseReshape\"]=function(){return(_SparseReshape=Module[\"_SparseReshape\"]=Module[\"asm\"][\"SparseReshape\"]).apply(null,arguments)};var _SparseSegmentReduction=Module[\"_SparseSegmentReduction\"]=function(){return(_SparseSegmentReduction=Module[\"_SparseSegmentReduction\"]=Module[\"asm\"][\"SparseSegmentReduction\"]).apply(null,arguments)};var _SparseToDense=Module[\"_SparseToDense\"]=function(){return(_SparseToDense=Module[\"_SparseToDense\"]=Module[\"asm\"][\"SparseToDense\"]).apply(null,arguments)};var _Sqrt=Module[\"_Sqrt\"]=function(){return(_Sqrt=Module[\"_Sqrt\"]=Module[\"asm\"][\"Sqrt\"]).apply(null,arguments)};var _Square=Module[\"_Square\"]=function(){return(_Square=Module[\"_Square\"]=Module[\"asm\"][\"Square\"]).apply(null,arguments)};var _SquaredDifference=Module[\"_SquaredDifference\"]=function(){return(_SquaredDifference=Module[\"_SquaredDifference\"]=Module[\"asm\"][\"SquaredDifference\"]).apply(null,arguments)};var _Step=Module[\"_Step\"]=function(){return(_Step=Module[\"_Step\"]=Module[\"asm\"][\"Step\"]).apply(null,arguments)};var _StridedSlice=Module[\"_StridedSlice\"]=function(){return(_StridedSlice=Module[\"_StridedSlice\"]=Module[\"asm\"][\"StridedSlice\"]).apply(null,arguments)};var _Sub=Module[\"_Sub\"]=function(){return(_Sub=Module[\"_Sub\"]=Module[\"asm\"][\"Sub\"]).apply(null,arguments)};var _Sum=Module[\"_Sum\"]=function(){return(_Sum=Module[\"_Sum\"]=Module[\"asm\"][\"Sum\"]).apply(null,arguments)};var _Tan=Module[\"_Tan\"]=function(){return(_Tan=Module[\"_Tan\"]=Module[\"asm\"][\"Tan\"]).apply(null,arguments)};var _Tanh=Module[\"_Tanh\"]=function(){return(_Tanh=Module[\"_Tanh\"]=Module[\"asm\"][\"Tanh\"]).apply(null,arguments)};var _TensorScatterUpdate=Module[\"_TensorScatterUpdate\"]=function(){return(_TensorScatterUpdate=Module[\"_TensorScatterUpdate\"]=Module[\"asm\"][\"TensorScatterUpdate\"]).apply(null,arguments)};var _Tile=Module[\"_Tile\"]=function(){return(_Tile=Module[\"_Tile\"]=Module[\"asm\"][\"Tile\"]).apply(null,arguments)};var _TopK=Module[\"_TopK\"]=function(){return(_TopK=Module[\"_TopK\"]=Module[\"asm\"][\"TopK\"]).apply(null,arguments)};var _Transform=Module[\"_Transform\"]=function(){return(_Transform=Module[\"_Transform\"]=Module[\"asm\"][\"Transform\"]).apply(null,arguments)};var _Transpose=Module[\"_Transpose\"]=function(){return(_Transpose=Module[\"_Transpose\"]=Module[\"asm\"][\"Transpose\"]).apply(null,arguments)};var __FusedMatMul=Module[\"__FusedMatMul\"]=function(){return(__FusedMatMul=Module[\"__FusedMatMul\"]=Module[\"asm\"][\"_FusedMatMul\"]).apply(null,arguments)};var _malloc=Module[\"_malloc\"]=function(){return(_malloc=Module[\"_malloc\"]=Module[\"asm\"][\"malloc\"]).apply(null,arguments)};var _free=Module[\"_free\"]=function(){return(_free=Module[\"_free\"]=Module[\"asm\"][\"free\"]).apply(null,arguments)};var __emscripten_tls_init=Module[\"__emscripten_tls_init\"]=function(){return(__emscripten_tls_init=Module[\"__emscripten_tls_init\"]=Module[\"asm\"][\"_emscripten_tls_init\"]).apply(null,arguments)};var _pthread_self=Module[\"_pthread_self\"]=function(){return(_pthread_self=Module[\"_pthread_self\"]=Module[\"asm\"][\"pthread_self\"]).apply(null,arguments)};var ___errno_location=Module[\"___errno_location\"]=function(){return(___errno_location=Module[\"___errno_location\"]=Module[\"asm\"][\"__errno_location\"]).apply(null,arguments)};var __emscripten_thread_init=Module[\"__emscripten_thread_init\"]=function(){return(__emscripten_thread_init=Module[\"__emscripten_thread_init\"]=Module[\"asm\"][\"_emscripten_thread_init\"]).apply(null,arguments)};var __emscripten_thread_crashed=Module[\"__emscripten_thread_crashed\"]=function(){return(__emscripten_thread_crashed=Module[\"__emscripten_thread_crashed\"]=Module[\"asm\"][\"_emscripten_thread_crashed\"]).apply(null,arguments)};var _emscripten_main_thread_process_queued_calls=Module[\"_emscripten_main_thread_process_queued_calls\"]=function(){return(_emscripten_main_thread_process_queued_calls=Module[\"_emscripten_main_thread_process_queued_calls\"]=Module[\"asm\"][\"emscripten_main_thread_process_queued_calls\"]).apply(null,arguments)};var _emscripten_main_browser_thread_id=Module[\"_emscripten_main_browser_thread_id\"]=function(){return(_emscripten_main_browser_thread_id=Module[\"_emscripten_main_browser_thread_id\"]=Module[\"asm\"][\"emscripten_main_browser_thread_id\"]).apply(null,arguments)};var _emscripten_run_in_main_runtime_thread_js=Module[\"_emscripten_run_in_main_runtime_thread_js\"]=function(){return(_emscripten_run_in_main_runtime_thread_js=Module[\"_emscripten_run_in_main_runtime_thread_js\"]=Module[\"asm\"][\"emscripten_run_in_main_runtime_thread_js\"]).apply(null,arguments)};var _emscripten_dispatch_to_thread_=Module[\"_emscripten_dispatch_to_thread_\"]=function(){return(_emscripten_dispatch_to_thread_=Module[\"_emscripten_dispatch_to_thread_\"]=Module[\"asm\"][\"emscripten_dispatch_to_thread_\"]).apply(null,arguments)};var __emscripten_proxy_execute_task_queue=Module[\"__emscripten_proxy_execute_task_queue\"]=function(){return(__emscripten_proxy_execute_task_queue=Module[\"__emscripten_proxy_execute_task_queue\"]=Module[\"asm\"][\"_emscripten_proxy_execute_task_queue\"]).apply(null,arguments)};var __emscripten_thread_free_data=Module[\"__emscripten_thread_free_data\"]=function(){return(__emscripten_thread_free_data=Module[\"__emscripten_thread_free_data\"]=Module[\"asm\"][\"_emscripten_thread_free_data\"]).apply(null,arguments)};var __emscripten_thread_exit=Module[\"__emscripten_thread_exit\"]=function(){return(__emscripten_thread_exit=Module[\"__emscripten_thread_exit\"]=Module[\"asm\"][\"_emscripten_thread_exit\"]).apply(null,arguments)};var _emscripten_stack_set_limits=Module[\"_emscripten_stack_set_limits\"]=function(){return(_emscripten_stack_set_limits=Module[\"_emscripten_stack_set_limits\"]=Module[\"asm\"][\"emscripten_stack_set_limits\"]).apply(null,arguments)};var stackSave=Module[\"stackSave\"]=function(){return(stackSave=Module[\"stackSave\"]=Module[\"asm\"][\"stackSave\"]).apply(null,arguments)};var stackRestore=Module[\"stackRestore\"]=function(){return(stackRestore=Module[\"stackRestore\"]=Module[\"asm\"][\"stackRestore\"]).apply(null,arguments)};var stackAlloc=Module[\"stackAlloc\"]=function(){return(stackAlloc=Module[\"stackAlloc\"]=Module[\"asm\"][\"stackAlloc\"]).apply(null,arguments)};var dynCall_iijjiiii=Module[\"dynCall_iijjiiii\"]=function(){return(dynCall_iijjiiii=Module[\"dynCall_iijjiiii\"]=Module[\"asm\"][\"dynCall_iijjiiii\"]).apply(null,arguments)};var dynCall_jiji=Module[\"dynCall_jiji\"]=function(){return(dynCall_jiji=Module[\"dynCall_jiji\"]=Module[\"asm\"][\"dynCall_jiji\"]).apply(null,arguments)};Module[\"keepRuntimeAlive\"]=keepRuntimeAlive;Module[\"wasmMemory\"]=wasmMemory;Module[\"cwrap\"]=cwrap;Module[\"ExitStatus\"]=ExitStatus;Module[\"PThread\"]=PThread;var calledRun;dependenciesFulfilled=function runCaller(){if(!calledRun)run();if(!calledRun)dependenciesFulfilled=runCaller};function run(args){args=args||arguments_;if(runDependencies>0){return}if(ENVIRONMENT_IS_PTHREAD){readyPromiseResolve(Module);initRuntime();startWorker(Module);return}preRun();if(runDependencies>0){return}function doRun(){if(calledRun)return;calledRun=true;Module[\"calledRun\"]=true;if(ABORT)return;initRuntime();readyPromiseResolve(Module);if(Module[\"onRuntimeInitialized\"])Module[\"onRuntimeInitialized\"]();postRun()}if(Module[\"setStatus\"]){Module[\"setStatus\"](\"Running...\");setTimeout(function(){setTimeout(function(){Module[\"setStatus\"](\"\")},1);doRun()},1)}else{doRun()}}if(Module[\"preInit\"]){if(typeof Module[\"preInit\"]==\"function\")Module[\"preInit\"]=[Module[\"preInit\"]];while(Module[\"preInit\"].length>0){Module[\"preInit\"].pop()()}}run();var listenersAdded;if(beforeListeners){listenersAdded={uncaughtException:process.listeners(\"uncaughtException\").filter(function(listener){return!beforeListeners.uncaughtException.indexOf(listener)>-1}),unhandledRejection:process.listeners(\"unhandledRejection\").filter(function(listener){return!beforeListeners.unhandledRejection.indexOf(listener)>-1})}}var actualModule;if(typeof WasmBackendModule!==\"undefined\"){actualModule=WasmBackendModule}else if(typeof WasmBackendModuleThreadedSimd!==\"undefined\"){actualModule=WasmBackendModuleThreadedSimd}else{throw new Error(\"Could not find wasm module in post.js\")}if(listenersAdded){var tmpDispose=actualModule[\"_dispose\"];actualModule[\"_dispose\"]=function(){tmpDispose();listenersAdded.uncaughtException.forEach(function(listener){process.removeListener(\"uncaughtException\",listener)});listenersAdded.unhandledRejection.forEach(function(listener){process.removeListener(\"unhandledRejection\",listener)})}}\n\n\n  return WasmBackendModuleThreadedSimd.ready\n}\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = WasmBackendModuleThreadedSimd;\nelse if (typeof define === 'function' && define['amd'])\n  define([], function() { return WasmBackendModuleThreadedSimd; });\nelse if (typeof exports === 'object')\n  exports[\"WasmBackendModuleThreadedSimd\"] = WasmBackendModuleThreadedSimd;\n","module.exports.wasmWorkerContents = `\"use strict\";var Module={};var ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\");var parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",data=>onmessage({data:data}));var fs=require(\"fs\");Object.assign(global,{self:global,require:require,Module:Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:function(f){(0,eval)(fs.readFileSync(f,\"utf8\")+\"//# sourceURL=\"+f)},postMessage:function(msg){parentPort.postMessage(msg)},performance:global.performance||{now:function(){return Date.now()}}})}var initializedJS=false;var pendingNotifiedProxyingQueues=[];function threadPrintErr(){var text=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,text+\"\\n\");return}console.error(text)}function threadAlert(){var text=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:text,threadId:Module[\"_pthread_self\"]()})}var err=threadPrintErr;self.alert=threadAlert;Module[\"instantiateWasm\"]=(info,receiveInstance)=>{var instance=new WebAssembly.Instance(Module[\"wasmModule\"],info);receiveInstance(instance);Module[\"wasmModule\"]=null;return instance.exports};self.onunhandledrejection=e=>{throw e.reason??e};self.startWorker=instance=>{Module=instance;postMessage({\"cmd\":\"loaded\"})};self.onmessage=e=>{try{if(e.data.cmd===\"load\"){Module[\"wasmModule\"]=e.data.wasmModule;for(const handler of e.data.handlers){Module[handler]=function(){postMessage({cmd:\"callHandler\",handler:handler,args:[...arguments]})}}Module[\"wasmMemory\"]=e.data.wasmMemory;Module[\"buffer\"]=Module[\"wasmMemory\"].buffer;Module[\"ENVIRONMENT_IS_PTHREAD\"]=true;if(typeof e.data.urlOrBlob==\"string\"){importScripts(e.data.urlOrBlob)}else{var objectUrl=URL.createObjectURL(e.data.urlOrBlob);importScripts(objectUrl);URL.revokeObjectURL(objectUrl)}WasmBackendModuleThreadedSimd(Module)}else if(e.data.cmd===\"run\"){Module[\"__emscripten_thread_init\"](e.data.pthread_ptr,0,0,1);Module[\"establishStackSpace\"]();Module[\"PThread\"].receiveObjectTransfer(e.data);Module[\"PThread\"].threadInitTLS();if(!initializedJS){pendingNotifiedProxyingQueues.forEach(queue=>{Module[\"executeNotifiedProxyingQueue\"](queue)});pendingNotifiedProxyingQueues=[];initializedJS=true}try{Module[\"invokeEntryPoint\"](e.data.start_routine,e.data.arg)}catch(ex){if(ex!=\"unwind\"){if(ex instanceof Module[\"ExitStatus\"]){if(Module[\"keepRuntimeAlive\"]()){}else{Module[\"__emscripten_thread_exit\"](ex.status)}}else{throw ex}}}}else if(e.data.cmd===\"cancel\"){if(Module[\"_pthread_self\"]()){Module[\"__emscripten_thread_exit\"](-1)}}else if(e.data.target===\"setimmediate\"){}else if(e.data.cmd===\"processProxyingQueue\"){if(initializedJS){Module[\"executeNotifiedProxyingQueue\"](e.data.queue)}else{pendingNotifiedProxyingQueues.push(e.data.queue)}}else if(e.data.cmd){err(\"worker.js received unknown command \"+e.data.cmd);err(e.data)}}catch(ex){if(Module[\"__emscripten_thread_crashed\"]){Module[\"__emscripten_thread_crashed\"]()}throw ex}};`;","\nvar WasmBackendModule = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(WasmBackendModule) {\n  WasmBackendModule = WasmBackendModule || {};\n\nvar Module=typeof WasmBackendModule!=\"undefined\"?WasmBackendModule:{};var readyPromiseResolve,readyPromiseReject;Module[\"ready\"]=new Promise(function(resolve,reject){readyPromiseResolve=resolve;readyPromiseReject=reject});var beforeListeners;if(typeof process!==\"undefined\"&&process.listeners){beforeListeners={uncaughtException:process.listeners(\"uncaughtException\"),unhandledRejection:process.listeners(\"unhandledRejection\")}}var moduleOverrides=Object.assign({},Module);var arguments_=[];var thisProgram=\"./this.program\";var quit_=(status,toThrow)=>{throw toThrow};var ENVIRONMENT_IS_WEB=typeof window==\"object\";var ENVIRONMENT_IS_WORKER=typeof importScripts==\"function\";var ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";var scriptDirectory=\"\";function locateFile(path){if(Module[\"locateFile\"]){return Module[\"locateFile\"](path,scriptDirectory)}return scriptDirectory+path}var read_,readAsync,readBinary,setWindowTitle;function logExceptionOnExit(e){if(e instanceof ExitStatus)return;let toLog=e;err(\"exiting due to exception: \"+toLog)}if(ENVIRONMENT_IS_NODE){var fs=require(\"fs\");var nodePath=require(\"path\");if(ENVIRONMENT_IS_WORKER){scriptDirectory=nodePath.dirname(scriptDirectory)+\"/\"}else{scriptDirectory=__dirname+\"/\"}read_=(filename,binary)=>{filename=isFileURI(filename)?new URL(filename):nodePath.normalize(filename);return fs.readFileSync(filename,binary?undefined:\"utf8\")};readBinary=filename=>{var ret=read_(filename,true);if(!ret.buffer){ret=new Uint8Array(ret)}return ret};readAsync=(filename,onload,onerror)=>{filename=isFileURI(filename)?new URL(filename):nodePath.normalize(filename);fs.readFile(filename,function(err,data){if(err)onerror(err);else onload(data.buffer)})};if(process[\"argv\"].length>1){thisProgram=process[\"argv\"][1].replace(/\\\\/g,\"/\")}arguments_=process[\"argv\"].slice(2);process[\"on\"](\"uncaughtException\",function(ex){if(!(ex instanceof ExitStatus)){throw ex}});process[\"on\"](\"unhandledRejection\",function(reason){throw reason});quit_=(status,toThrow)=>{if(keepRuntimeAlive()){process[\"exitCode\"]=status;throw toThrow}logExceptionOnExit(toThrow);process[\"exit\"](status)};Module[\"inspect\"]=function(){return\"[Emscripten Module object]\"}}else if(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER){if(ENVIRONMENT_IS_WORKER){scriptDirectory=self.location.href}else if(typeof document!=\"undefined\"&&document.currentScript){scriptDirectory=document.currentScript.src}if(_scriptDir){scriptDirectory=_scriptDir}if(scriptDirectory.indexOf(\"blob:\")!==0){scriptDirectory=scriptDirectory.substr(0,scriptDirectory.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1)}else{scriptDirectory=\"\"}{read_=url=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,false);xhr.send(null);return xhr.responseText};if(ENVIRONMENT_IS_WORKER){readBinary=url=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,false);xhr.responseType=\"arraybuffer\";xhr.send(null);return new Uint8Array(xhr.response)}}readAsync=(url,onload,onerror)=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,true);xhr.responseType=\"arraybuffer\";xhr.onload=()=>{if(xhr.status==200||xhr.status==0&&xhr.response){onload(xhr.response);return}onerror()};xhr.onerror=onerror;xhr.send(null)}}setWindowTitle=title=>document.title=title}else{}var out=Module[\"print\"]||console.log.bind(console);var err=Module[\"printErr\"]||console.warn.bind(console);Object.assign(Module,moduleOverrides);moduleOverrides=null;if(Module[\"arguments\"])arguments_=Module[\"arguments\"];if(Module[\"thisProgram\"])thisProgram=Module[\"thisProgram\"];if(Module[\"quit\"])quit_=Module[\"quit\"];var POINTER_SIZE=4;var wasmBinary;if(Module[\"wasmBinary\"])wasmBinary=Module[\"wasmBinary\"];var noExitRuntime=Module[\"noExitRuntime\"]||true;if(typeof WebAssembly!=\"object\"){abort(\"no native wasm support detected\")}var wasmMemory;var ABORT=false;var EXITSTATUS;function assert(condition,text){if(!condition){abort(text)}}var UTF8Decoder=typeof TextDecoder!=\"undefined\"?new TextDecoder(\"utf8\"):undefined;function UTF8ArrayToString(heapOrArray,idx,maxBytesToRead){idx>>>=0;var endIdx=idx+maxBytesToRead;var endPtr=idx;while(heapOrArray[endPtr]&&!(endPtr>=endIdx))++endPtr;if(endPtr-idx>16&&heapOrArray.buffer&&UTF8Decoder){return UTF8Decoder.decode(heapOrArray.subarray(idx,endPtr))}var str=\"\";while(idx<endPtr){var u0=heapOrArray[idx++];if(!(u0&128)){str+=String.fromCharCode(u0);continue}var u1=heapOrArray[idx++]&63;if((u0&224)==192){str+=String.fromCharCode((u0&31)<<6|u1);continue}var u2=heapOrArray[idx++]&63;if((u0&240)==224){u0=(u0&15)<<12|u1<<6|u2}else{u0=(u0&7)<<18|u1<<12|u2<<6|heapOrArray[idx++]&63}if(u0<65536){str+=String.fromCharCode(u0)}else{var ch=u0-65536;str+=String.fromCharCode(55296|ch>>10,56320|ch&1023)}}return str}function UTF8ToString(ptr,maxBytesToRead){ptr>>>=0;return ptr?UTF8ArrayToString(HEAPU8,ptr,maxBytesToRead):\"\"}function stringToUTF8Array(str,heap,outIdx,maxBytesToWrite){outIdx>>>=0;if(!(maxBytesToWrite>0))return 0;var startIdx=outIdx;var endIdx=outIdx+maxBytesToWrite-1;for(var i=0;i<str.length;++i){var u=str.charCodeAt(i);if(u>=55296&&u<=57343){var u1=str.charCodeAt(++i);u=65536+((u&1023)<<10)|u1&1023}if(u<=127){if(outIdx>=endIdx)break;heap[outIdx++>>>0]=u}else if(u<=2047){if(outIdx+1>=endIdx)break;heap[outIdx++>>>0]=192|u>>6;heap[outIdx++>>>0]=128|u&63}else if(u<=65535){if(outIdx+2>=endIdx)break;heap[outIdx++>>>0]=224|u>>12;heap[outIdx++>>>0]=128|u>>6&63;heap[outIdx++>>>0]=128|u&63}else{if(outIdx+3>=endIdx)break;heap[outIdx++>>>0]=240|u>>18;heap[outIdx++>>>0]=128|u>>12&63;heap[outIdx++>>>0]=128|u>>6&63;heap[outIdx++>>>0]=128|u&63}}heap[outIdx>>>0]=0;return outIdx-startIdx}function stringToUTF8(str,outPtr,maxBytesToWrite){return stringToUTF8Array(str,HEAPU8,outPtr,maxBytesToWrite)}var buffer,HEAP8,HEAPU8,HEAP16,HEAPU16,HEAP32,HEAPU32,HEAPF32,HEAPF64;function updateGlobalBufferAndViews(buf){buffer=buf;Module[\"HEAP8\"]=HEAP8=new Int8Array(buf);Module[\"HEAP16\"]=HEAP16=new Int16Array(buf);Module[\"HEAP32\"]=HEAP32=new Int32Array(buf);Module[\"HEAPU8\"]=HEAPU8=new Uint8Array(buf);Module[\"HEAPU16\"]=HEAPU16=new Uint16Array(buf);Module[\"HEAPU32\"]=HEAPU32=new Uint32Array(buf);Module[\"HEAPF32\"]=HEAPF32=new Float32Array(buf);Module[\"HEAPF64\"]=HEAPF64=new Float64Array(buf)}var INITIAL_MEMORY=Module[\"INITIAL_MEMORY\"]||16777216;var wasmTable;var __ATPRERUN__=[];var __ATINIT__=[];var __ATPOSTRUN__=[];var runtimeInitialized=false;function keepRuntimeAlive(){return noExitRuntime}function preRun(){if(Module[\"preRun\"]){if(typeof Module[\"preRun\"]==\"function\")Module[\"preRun\"]=[Module[\"preRun\"]];while(Module[\"preRun\"].length){addOnPreRun(Module[\"preRun\"].shift())}}callRuntimeCallbacks(__ATPRERUN__)}function initRuntime(){runtimeInitialized=true;callRuntimeCallbacks(__ATINIT__)}function postRun(){if(Module[\"postRun\"]){if(typeof Module[\"postRun\"]==\"function\")Module[\"postRun\"]=[Module[\"postRun\"]];while(Module[\"postRun\"].length){addOnPostRun(Module[\"postRun\"].shift())}}callRuntimeCallbacks(__ATPOSTRUN__)}function addOnPreRun(cb){__ATPRERUN__.unshift(cb)}function addOnInit(cb){__ATINIT__.unshift(cb)}function addOnPostRun(cb){__ATPOSTRUN__.unshift(cb)}var runDependencies=0;var runDependencyWatcher=null;var dependenciesFulfilled=null;function addRunDependency(id){runDependencies++;if(Module[\"monitorRunDependencies\"]){Module[\"monitorRunDependencies\"](runDependencies)}}function removeRunDependency(id){runDependencies--;if(Module[\"monitorRunDependencies\"]){Module[\"monitorRunDependencies\"](runDependencies)}if(runDependencies==0){if(runDependencyWatcher!==null){clearInterval(runDependencyWatcher);runDependencyWatcher=null}if(dependenciesFulfilled){var callback=dependenciesFulfilled;dependenciesFulfilled=null;callback()}}}function abort(what){if(Module[\"onAbort\"]){Module[\"onAbort\"](what)}what=\"Aborted(\"+what+\")\";err(what);ABORT=true;EXITSTATUS=1;what+=\". Build with -sASSERTIONS for more info.\";var e=new WebAssembly.RuntimeError(what);readyPromiseReject(e);throw e}var dataURIPrefix=\"data:application/octet-stream;base64,\";function isDataURI(filename){return filename.startsWith(dataURIPrefix)}function isFileURI(filename){return filename.startsWith(\"file://\")}var wasmBinaryFile;wasmBinaryFile=\"tfjs-backend-wasm.wasm\";if(!isDataURI(wasmBinaryFile)){wasmBinaryFile=locateFile(wasmBinaryFile)}function getBinary(file){try{if(file==wasmBinaryFile&&wasmBinary){return new Uint8Array(wasmBinary)}if(readBinary){return readBinary(file)}throw\"both async and sync fetching of the wasm failed\"}catch(err){abort(err)}}function getBinaryPromise(){if(!wasmBinary&&(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER)){if(typeof fetch==\"function\"&&!isFileURI(wasmBinaryFile)){return fetch(wasmBinaryFile,{credentials:\"same-origin\"}).then(function(response){if(!response[\"ok\"]){throw\"failed to load wasm binary file at '\"+wasmBinaryFile+\"'\"}return response[\"arrayBuffer\"]()}).catch(function(){return getBinary(wasmBinaryFile)})}else{if(readAsync){return new Promise(function(resolve,reject){readAsync(wasmBinaryFile,function(response){resolve(new Uint8Array(response))},reject)})}}}return Promise.resolve().then(function(){return getBinary(wasmBinaryFile)})}function createWasm(){var info={\"env\":asmLibraryArg,\"wasi_snapshot_preview1\":asmLibraryArg};function receiveInstance(instance,module){var exports=instance.exports;Module[\"asm\"]=exports;wasmMemory=Module[\"asm\"][\"memory\"];updateGlobalBufferAndViews(wasmMemory.buffer);wasmTable=Module[\"asm\"][\"__indirect_function_table\"];addOnInit(Module[\"asm\"][\"__wasm_call_ctors\"]);removeRunDependency(\"wasm-instantiate\")}addRunDependency(\"wasm-instantiate\");function receiveInstantiationResult(result){receiveInstance(result[\"instance\"])}function instantiateArrayBuffer(receiver){return getBinaryPromise().then(function(binary){return WebAssembly.instantiate(binary,info)}).then(function(instance){return instance}).then(receiver,function(reason){err(\"failed to asynchronously prepare wasm: \"+reason);abort(reason)})}function instantiateAsync(){if(!wasmBinary&&typeof WebAssembly.instantiateStreaming==\"function\"&&!isDataURI(wasmBinaryFile)&&!isFileURI(wasmBinaryFile)&&!ENVIRONMENT_IS_NODE&&typeof fetch==\"function\"){return fetch(wasmBinaryFile,{credentials:\"same-origin\"}).then(function(response){var result=WebAssembly.instantiateStreaming(response,info);return result.then(receiveInstantiationResult,function(reason){err(\"wasm streaming compile failed: \"+reason);err(\"falling back to ArrayBuffer instantiation\");return instantiateArrayBuffer(receiveInstantiationResult)})})}else{return instantiateArrayBuffer(receiveInstantiationResult)}}if(Module[\"instantiateWasm\"]){try{var exports=Module[\"instantiateWasm\"](info,receiveInstance);return exports}catch(e){err(\"Module.instantiateWasm callback failed with error: \"+e);readyPromiseReject(e)}}instantiateAsync().catch(readyPromiseReject);return{}}var tempDouble;var tempI64;function ExitStatus(status){this.name=\"ExitStatus\";this.message=\"Program terminated with exit(\"+status+\")\";this.status=status}function callRuntimeCallbacks(callbacks){while(callbacks.length>0){callbacks.shift()(Module)}}function _abort(){abort(\"\")}function getHeapMax(){return 4294901760}function _emscripten_get_heap_max(){return getHeapMax()}function _emscripten_memcpy_big(dest,src,num){HEAPU8.copyWithin(dest>>>0,src>>>0,src+num>>>0)}function emscripten_realloc_buffer(size){try{wasmMemory.grow(size-buffer.byteLength+65535>>>16);updateGlobalBufferAndViews(wasmMemory.buffer);return 1}catch(e){}}function _emscripten_resize_heap(requestedSize){var oldSize=HEAPU8.length;requestedSize=requestedSize>>>0;var maxHeapSize=getHeapMax();if(requestedSize>maxHeapSize){return false}let alignUp=(x,multiple)=>x+(multiple-x%multiple)%multiple;for(var cutDown=1;cutDown<=4;cutDown*=2){var overGrownHeapSize=oldSize*(1+.2/cutDown);overGrownHeapSize=Math.min(overGrownHeapSize,requestedSize+100663296);var newSize=Math.min(maxHeapSize,alignUp(Math.max(requestedSize,overGrownHeapSize),65536));var replacement=emscripten_realloc_buffer(newSize);if(replacement){return true}}return false}var SYSCALLS={varargs:undefined,get:function(){SYSCALLS.varargs+=4;var ret=HEAP32[SYSCALLS.varargs-4>>>2];return ret},getStr:function(ptr){var ret=UTF8ToString(ptr);return ret}};function _fd_close(fd){return 52}function _fd_seek(fd,offset_low,offset_high,whence,newOffset){return 70}var printCharBuffers=[null,[],[]];function printChar(stream,curr){var buffer=printCharBuffers[stream];if(curr===0||curr===10){(stream===1?out:err)(UTF8ArrayToString(buffer,0));buffer.length=0}else{buffer.push(curr)}}function _fd_write(fd,iov,iovcnt,pnum){var num=0;for(var i=0;i<iovcnt;i++){var ptr=HEAPU32[iov>>>2];var len=HEAPU32[iov+4>>>2];iov+=8;for(var j=0;j<len;j++){printChar(fd,HEAPU8[ptr+j>>>0])}num+=len}HEAPU32[pnum>>>2]=num;return 0}function getCFunc(ident){var func=Module[\"_\"+ident];return func}function writeArrayToMemory(array,buffer){HEAP8.set(array,buffer>>>0)}function ccall(ident,returnType,argTypes,args,opts){var toC={\"string\":str=>{var ret=0;if(str!==null&&str!==undefined&&str!==0){var len=(str.length<<2)+1;ret=stackAlloc(len);stringToUTF8(str,ret,len)}return ret},\"array\":arr=>{var ret=stackAlloc(arr.length);writeArrayToMemory(arr,ret);return ret}};function convertReturnValue(ret){if(returnType===\"string\"){return UTF8ToString(ret)}if(returnType===\"boolean\")return Boolean(ret);return ret}var func=getCFunc(ident);var cArgs=[];var stack=0;if(args){for(var i=0;i<args.length;i++){var converter=toC[argTypes[i]];if(converter){if(stack===0)stack=stackSave();cArgs[i]=converter(args[i])}else{cArgs[i]=args[i]}}}var ret=func.apply(null,cArgs);function onDone(ret){if(stack!==0)stackRestore(stack);return convertReturnValue(ret)}ret=onDone(ret);return ret}function cwrap(ident,returnType,argTypes,opts){argTypes=argTypes||[];var numericArgs=argTypes.every(type=>type===\"number\"||type===\"boolean\");var numericRet=returnType!==\"string\";if(numericRet&&numericArgs&&!opts){return getCFunc(ident)}return function(){return ccall(ident,returnType,argTypes,arguments,opts)}}var asmLibraryArg={\"abort\":_abort,\"emscripten_get_heap_max\":_emscripten_get_heap_max,\"emscripten_memcpy_big\":_emscripten_memcpy_big,\"emscripten_resize_heap\":_emscripten_resize_heap,\"fd_close\":_fd_close,\"fd_seek\":_fd_seek,\"fd_write\":_fd_write};var asm=createWasm();var ___wasm_call_ctors=Module[\"___wasm_call_ctors\"]=function(){return(___wasm_call_ctors=Module[\"___wasm_call_ctors\"]=Module[\"asm\"][\"__wasm_call_ctors\"]).apply(null,arguments)};var _init=Module[\"_init\"]=function(){return(_init=Module[\"_init\"]=Module[\"asm\"][\"init\"]).apply(null,arguments)};var _init_with_threads_count=Module[\"_init_with_threads_count\"]=function(){return(_init_with_threads_count=Module[\"_init_with_threads_count\"]=Module[\"asm\"][\"init_with_threads_count\"]).apply(null,arguments)};var _get_threads_count=Module[\"_get_threads_count\"]=function(){return(_get_threads_count=Module[\"_get_threads_count\"]=Module[\"asm\"][\"get_threads_count\"]).apply(null,arguments)};var _register_tensor=Module[\"_register_tensor\"]=function(){return(_register_tensor=Module[\"_register_tensor\"]=Module[\"asm\"][\"register_tensor\"]).apply(null,arguments)};var _dispose_data=Module[\"_dispose_data\"]=function(){return(_dispose_data=Module[\"_dispose_data\"]=Module[\"asm\"][\"dispose_data\"]).apply(null,arguments)};var _dispose=Module[\"_dispose\"]=function(){return(_dispose=Module[\"_dispose\"]=Module[\"asm\"][\"dispose\"]).apply(null,arguments)};var _Abs=Module[\"_Abs\"]=function(){return(_Abs=Module[\"_Abs\"]=Module[\"asm\"][\"Abs\"]).apply(null,arguments)};var _Acos=Module[\"_Acos\"]=function(){return(_Acos=Module[\"_Acos\"]=Module[\"asm\"][\"Acos\"]).apply(null,arguments)};var _Acosh=Module[\"_Acosh\"]=function(){return(_Acosh=Module[\"_Acosh\"]=Module[\"asm\"][\"Acosh\"]).apply(null,arguments)};var _Add=Module[\"_Add\"]=function(){return(_Add=Module[\"_Add\"]=Module[\"asm\"][\"Add\"]).apply(null,arguments)};var _AddN=Module[\"_AddN\"]=function(){return(_AddN=Module[\"_AddN\"]=Module[\"asm\"][\"AddN\"]).apply(null,arguments)};var _All=Module[\"_All\"]=function(){return(_All=Module[\"_All\"]=Module[\"asm\"][\"All\"]).apply(null,arguments)};var _Any=Module[\"_Any\"]=function(){return(_Any=Module[\"_Any\"]=Module[\"asm\"][\"Any\"]).apply(null,arguments)};var _ArgMax=Module[\"_ArgMax\"]=function(){return(_ArgMax=Module[\"_ArgMax\"]=Module[\"asm\"][\"ArgMax\"]).apply(null,arguments)};var _ArgMin=Module[\"_ArgMin\"]=function(){return(_ArgMin=Module[\"_ArgMin\"]=Module[\"asm\"][\"ArgMin\"]).apply(null,arguments)};var _Asin=Module[\"_Asin\"]=function(){return(_Asin=Module[\"_Asin\"]=Module[\"asm\"][\"Asin\"]).apply(null,arguments)};var _Asinh=Module[\"_Asinh\"]=function(){return(_Asinh=Module[\"_Asinh\"]=Module[\"asm\"][\"Asinh\"]).apply(null,arguments)};var _Atan=Module[\"_Atan\"]=function(){return(_Atan=Module[\"_Atan\"]=Module[\"asm\"][\"Atan\"]).apply(null,arguments)};var _Atan2=Module[\"_Atan2\"]=function(){return(_Atan2=Module[\"_Atan2\"]=Module[\"asm\"][\"Atan2\"]).apply(null,arguments)};var _Atanh=Module[\"_Atanh\"]=function(){return(_Atanh=Module[\"_Atanh\"]=Module[\"asm\"][\"Atanh\"]).apply(null,arguments)};var _AvgPool=Module[\"_AvgPool\"]=function(){return(_AvgPool=Module[\"_AvgPool\"]=Module[\"asm\"][\"AvgPool\"]).apply(null,arguments)};var _AvgPool3D=Module[\"_AvgPool3D\"]=function(){return(_AvgPool3D=Module[\"_AvgPool3D\"]=Module[\"asm\"][\"AvgPool3D\"]).apply(null,arguments)};var _AvgPool3DGrad=Module[\"_AvgPool3DGrad\"]=function(){return(_AvgPool3DGrad=Module[\"_AvgPool3DGrad\"]=Module[\"asm\"][\"AvgPool3DGrad\"]).apply(null,arguments)};var _AvgPoolGrad=Module[\"_AvgPoolGrad\"]=function(){return(_AvgPoolGrad=Module[\"_AvgPoolGrad\"]=Module[\"asm\"][\"AvgPoolGrad\"]).apply(null,arguments)};var _BatchMatMul=Module[\"_BatchMatMul\"]=function(){return(_BatchMatMul=Module[\"_BatchMatMul\"]=Module[\"asm\"][\"BatchMatMul\"]).apply(null,arguments)};var _Bincount=Module[\"_Bincount\"]=function(){return(_Bincount=Module[\"_Bincount\"]=Module[\"asm\"][\"Bincount\"]).apply(null,arguments)};var _BitwiseAnd=Module[\"_BitwiseAnd\"]=function(){return(_BitwiseAnd=Module[\"_BitwiseAnd\"]=Module[\"asm\"][\"BitwiseAnd\"]).apply(null,arguments)};var _Ceil=Module[\"_Ceil\"]=function(){return(_Ceil=Module[\"_Ceil\"]=Module[\"asm\"][\"Ceil\"]).apply(null,arguments)};var _ClipByValue=Module[\"_ClipByValue\"]=function(){return(_ClipByValue=Module[\"_ClipByValue\"]=Module[\"asm\"][\"ClipByValue\"]).apply(null,arguments)};var _Conv2D=Module[\"_Conv2D\"]=function(){return(_Conv2D=Module[\"_Conv2D\"]=Module[\"asm\"][\"Conv2D\"]).apply(null,arguments)};var _Conv2DBackpropInput=Module[\"_Conv2DBackpropInput\"]=function(){return(_Conv2DBackpropInput=Module[\"_Conv2DBackpropInput\"]=Module[\"asm\"][\"Conv2DBackpropInput\"]).apply(null,arguments)};var _Conv3D=Module[\"_Conv3D\"]=function(){return(_Conv3D=Module[\"_Conv3D\"]=Module[\"asm\"][\"Conv3D\"]).apply(null,arguments)};var _Conv3DBackpropFilterV2=Module[\"_Conv3DBackpropFilterV2\"]=function(){return(_Conv3DBackpropFilterV2=Module[\"_Conv3DBackpropFilterV2\"]=Module[\"asm\"][\"Conv3DBackpropFilterV2\"]).apply(null,arguments)};var _Conv3DBackpropInputV2=Module[\"_Conv3DBackpropInputV2\"]=function(){return(_Conv3DBackpropInputV2=Module[\"_Conv3DBackpropInputV2\"]=Module[\"asm\"][\"Conv3DBackpropInputV2\"]).apply(null,arguments)};var _Cos=Module[\"_Cos\"]=function(){return(_Cos=Module[\"_Cos\"]=Module[\"asm\"][\"Cos\"]).apply(null,arguments)};var _Cosh=Module[\"_Cosh\"]=function(){return(_Cosh=Module[\"_Cosh\"]=Module[\"asm\"][\"Cosh\"]).apply(null,arguments)};var _CropAndResize=Module[\"_CropAndResize\"]=function(){return(_CropAndResize=Module[\"_CropAndResize\"]=Module[\"asm\"][\"CropAndResize\"]).apply(null,arguments)};var _Cumprod=Module[\"_Cumprod\"]=function(){return(_Cumprod=Module[\"_Cumprod\"]=Module[\"asm\"][\"Cumprod\"]).apply(null,arguments)};var _Cumsum=Module[\"_Cumsum\"]=function(){return(_Cumsum=Module[\"_Cumsum\"]=Module[\"asm\"][\"Cumsum\"]).apply(null,arguments)};var _DenseBincount=Module[\"_DenseBincount\"]=function(){return(_DenseBincount=Module[\"_DenseBincount\"]=Module[\"asm\"][\"DenseBincount\"]).apply(null,arguments)};var _DepthToSpace=Module[\"_DepthToSpace\"]=function(){return(_DepthToSpace=Module[\"_DepthToSpace\"]=Module[\"asm\"][\"DepthToSpace\"]).apply(null,arguments)};var _DepthwiseConv2dNative=Module[\"_DepthwiseConv2dNative\"]=function(){return(_DepthwiseConv2dNative=Module[\"_DepthwiseConv2dNative\"]=Module[\"asm\"][\"DepthwiseConv2dNative\"]).apply(null,arguments)};var _Diag=Module[\"_Diag\"]=function(){return(_Diag=Module[\"_Diag\"]=Module[\"asm\"][\"Diag\"]).apply(null,arguments)};var _Dilation2D=Module[\"_Dilation2D\"]=function(){return(_Dilation2D=Module[\"_Dilation2D\"]=Module[\"asm\"][\"Dilation2D\"]).apply(null,arguments)};var _Dilation2DBackpropFilter=Module[\"_Dilation2DBackpropFilter\"]=function(){return(_Dilation2DBackpropFilter=Module[\"_Dilation2DBackpropFilter\"]=Module[\"asm\"][\"Dilation2DBackpropFilter\"]).apply(null,arguments)};var _Dilation2DBackpropInput=Module[\"_Dilation2DBackpropInput\"]=function(){return(_Dilation2DBackpropInput=Module[\"_Dilation2DBackpropInput\"]=Module[\"asm\"][\"Dilation2DBackpropInput\"]).apply(null,arguments)};var _Elu=Module[\"_Elu\"]=function(){return(_Elu=Module[\"_Elu\"]=Module[\"asm\"][\"Elu\"]).apply(null,arguments)};var _EluGrad=Module[\"_EluGrad\"]=function(){return(_EluGrad=Module[\"_EluGrad\"]=Module[\"asm\"][\"EluGrad\"]).apply(null,arguments)};var _Equal=Module[\"_Equal\"]=function(){return(_Equal=Module[\"_Equal\"]=Module[\"asm\"][\"Equal\"]).apply(null,arguments)};var _Erf=Module[\"_Erf\"]=function(){return(_Erf=Module[\"_Erf\"]=Module[\"asm\"][\"Erf\"]).apply(null,arguments)};var _Exp=Module[\"_Exp\"]=function(){return(_Exp=Module[\"_Exp\"]=Module[\"asm\"][\"Exp\"]).apply(null,arguments)};var _Expm1=Module[\"_Expm1\"]=function(){return(_Expm1=Module[\"_Expm1\"]=Module[\"asm\"][\"Expm1\"]).apply(null,arguments)};var _FlipLeftRight=Module[\"_FlipLeftRight\"]=function(){return(_FlipLeftRight=Module[\"_FlipLeftRight\"]=Module[\"asm\"][\"FlipLeftRight\"]).apply(null,arguments)};var _Floor=Module[\"_Floor\"]=function(){return(_Floor=Module[\"_Floor\"]=Module[\"asm\"][\"Floor\"]).apply(null,arguments)};var _FloorDiv=Module[\"_FloorDiv\"]=function(){return(_FloorDiv=Module[\"_FloorDiv\"]=Module[\"asm\"][\"FloorDiv\"]).apply(null,arguments)};var _FusedBatchNorm=Module[\"_FusedBatchNorm\"]=function(){return(_FusedBatchNorm=Module[\"_FusedBatchNorm\"]=Module[\"asm\"][\"FusedBatchNorm\"]).apply(null,arguments)};var _FusedConv2D=Module[\"_FusedConv2D\"]=function(){return(_FusedConv2D=Module[\"_FusedConv2D\"]=Module[\"asm\"][\"FusedConv2D\"]).apply(null,arguments)};var _FusedDepthwiseConv2D=Module[\"_FusedDepthwiseConv2D\"]=function(){return(_FusedDepthwiseConv2D=Module[\"_FusedDepthwiseConv2D\"]=Module[\"asm\"][\"FusedDepthwiseConv2D\"]).apply(null,arguments)};var _Gather=Module[\"_Gather\"]=function(){return(_Gather=Module[\"_Gather\"]=Module[\"asm\"][\"Gather\"]).apply(null,arguments)};var _GatherNd=Module[\"_GatherNd\"]=function(){return(_GatherNd=Module[\"_GatherNd\"]=Module[\"asm\"][\"GatherNd\"]).apply(null,arguments)};var _Greater=Module[\"_Greater\"]=function(){return(_Greater=Module[\"_Greater\"]=Module[\"asm\"][\"Greater\"]).apply(null,arguments)};var _GreaterEqual=Module[\"_GreaterEqual\"]=function(){return(_GreaterEqual=Module[\"_GreaterEqual\"]=Module[\"asm\"][\"GreaterEqual\"]).apply(null,arguments)};var _IsFinite=Module[\"_IsFinite\"]=function(){return(_IsFinite=Module[\"_IsFinite\"]=Module[\"asm\"][\"IsFinite\"]).apply(null,arguments)};var _IsInf=Module[\"_IsInf\"]=function(){return(_IsInf=Module[\"_IsInf\"]=Module[\"asm\"][\"IsInf\"]).apply(null,arguments)};var _IsNan=Module[\"_IsNan\"]=function(){return(_IsNan=Module[\"_IsNan\"]=Module[\"asm\"][\"IsNan\"]).apply(null,arguments)};var _LRN=Module[\"_LRN\"]=function(){return(_LRN=Module[\"_LRN\"]=Module[\"asm\"][\"LRN\"]).apply(null,arguments)};var _LRNGrad=Module[\"_LRNGrad\"]=function(){return(_LRNGrad=Module[\"_LRNGrad\"]=Module[\"asm\"][\"LRNGrad\"]).apply(null,arguments)};var _LeakyRelu=Module[\"_LeakyRelu\"]=function(){return(_LeakyRelu=Module[\"_LeakyRelu\"]=Module[\"asm\"][\"LeakyRelu\"]).apply(null,arguments)};var _Less=Module[\"_Less\"]=function(){return(_Less=Module[\"_Less\"]=Module[\"asm\"][\"Less\"]).apply(null,arguments)};var _LessEqual=Module[\"_LessEqual\"]=function(){return(_LessEqual=Module[\"_LessEqual\"]=Module[\"asm\"][\"LessEqual\"]).apply(null,arguments)};var _LinSpace=Module[\"_LinSpace\"]=function(){return(_LinSpace=Module[\"_LinSpace\"]=Module[\"asm\"][\"LinSpace\"]).apply(null,arguments)};var _Log=Module[\"_Log\"]=function(){return(_Log=Module[\"_Log\"]=Module[\"asm\"][\"Log\"]).apply(null,arguments)};var _Log1p=Module[\"_Log1p\"]=function(){return(_Log1p=Module[\"_Log1p\"]=Module[\"asm\"][\"Log1p\"]).apply(null,arguments)};var _LogicalAnd=Module[\"_LogicalAnd\"]=function(){return(_LogicalAnd=Module[\"_LogicalAnd\"]=Module[\"asm\"][\"LogicalAnd\"]).apply(null,arguments)};var _LogicalNot=Module[\"_LogicalNot\"]=function(){return(_LogicalNot=Module[\"_LogicalNot\"]=Module[\"asm\"][\"LogicalNot\"]).apply(null,arguments)};var _LogicalOr=Module[\"_LogicalOr\"]=function(){return(_LogicalOr=Module[\"_LogicalOr\"]=Module[\"asm\"][\"LogicalOr\"]).apply(null,arguments)};var _LogicalXor=Module[\"_LogicalXor\"]=function(){return(_LogicalXor=Module[\"_LogicalXor\"]=Module[\"asm\"][\"LogicalXor\"]).apply(null,arguments)};var _Max=Module[\"_Max\"]=function(){return(_Max=Module[\"_Max\"]=Module[\"asm\"][\"Max\"]).apply(null,arguments)};var _MaxPool=Module[\"_MaxPool\"]=function(){return(_MaxPool=Module[\"_MaxPool\"]=Module[\"asm\"][\"MaxPool\"]).apply(null,arguments)};var _MaxPool3D=Module[\"_MaxPool3D\"]=function(){return(_MaxPool3D=Module[\"_MaxPool3D\"]=Module[\"asm\"][\"MaxPool3D\"]).apply(null,arguments)};var _MaxPool3DGrad=Module[\"_MaxPool3DGrad\"]=function(){return(_MaxPool3DGrad=Module[\"_MaxPool3DGrad\"]=Module[\"asm\"][\"MaxPool3DGrad\"]).apply(null,arguments)};var _MaxPoolGrad=Module[\"_MaxPoolGrad\"]=function(){return(_MaxPoolGrad=Module[\"_MaxPoolGrad\"]=Module[\"asm\"][\"MaxPoolGrad\"]).apply(null,arguments)};var _MaxPoolWithArgmax=Module[\"_MaxPoolWithArgmax\"]=function(){return(_MaxPoolWithArgmax=Module[\"_MaxPoolWithArgmax\"]=Module[\"asm\"][\"MaxPoolWithArgmax\"]).apply(null,arguments)};var _Maximum=Module[\"_Maximum\"]=function(){return(_Maximum=Module[\"_Maximum\"]=Module[\"asm\"][\"Maximum\"]).apply(null,arguments)};var _Mean=Module[\"_Mean\"]=function(){return(_Mean=Module[\"_Mean\"]=Module[\"asm\"][\"Mean\"]).apply(null,arguments)};var _Min=Module[\"_Min\"]=function(){return(_Min=Module[\"_Min\"]=Module[\"asm\"][\"Min\"]).apply(null,arguments)};var _Minimum=Module[\"_Minimum\"]=function(){return(_Minimum=Module[\"_Minimum\"]=Module[\"asm\"][\"Minimum\"]).apply(null,arguments)};var _MirrorPad=Module[\"_MirrorPad\"]=function(){return(_MirrorPad=Module[\"_MirrorPad\"]=Module[\"asm\"][\"MirrorPad\"]).apply(null,arguments)};var _Mod=Module[\"_Mod\"]=function(){return(_Mod=Module[\"_Mod\"]=Module[\"asm\"][\"Mod\"]).apply(null,arguments)};var _Multinomial=Module[\"_Multinomial\"]=function(){return(_Multinomial=Module[\"_Multinomial\"]=Module[\"asm\"][\"Multinomial\"]).apply(null,arguments)};var _Multiply=Module[\"_Multiply\"]=function(){return(_Multiply=Module[\"_Multiply\"]=Module[\"asm\"][\"Multiply\"]).apply(null,arguments)};var _Neg=Module[\"_Neg\"]=function(){return(_Neg=Module[\"_Neg\"]=Module[\"asm\"][\"Neg\"]).apply(null,arguments)};var _NonMaxSuppressionV3=Module[\"_NonMaxSuppressionV3\"]=function(){return(_NonMaxSuppressionV3=Module[\"_NonMaxSuppressionV3\"]=Module[\"asm\"][\"NonMaxSuppressionV3\"]).apply(null,arguments)};var _NonMaxSuppressionV4=Module[\"_NonMaxSuppressionV4\"]=function(){return(_NonMaxSuppressionV4=Module[\"_NonMaxSuppressionV4\"]=Module[\"asm\"][\"NonMaxSuppressionV4\"]).apply(null,arguments)};var _NonMaxSuppressionV5=Module[\"_NonMaxSuppressionV5\"]=function(){return(_NonMaxSuppressionV5=Module[\"_NonMaxSuppressionV5\"]=Module[\"asm\"][\"NonMaxSuppressionV5\"]).apply(null,arguments)};var _NotEqual=Module[\"_NotEqual\"]=function(){return(_NotEqual=Module[\"_NotEqual\"]=Module[\"asm\"][\"NotEqual\"]).apply(null,arguments)};var _OneHot=Module[\"_OneHot\"]=function(){return(_OneHot=Module[\"_OneHot\"]=Module[\"asm\"][\"OneHot\"]).apply(null,arguments)};var _PadV2=Module[\"_PadV2\"]=function(){return(_PadV2=Module[\"_PadV2\"]=Module[\"asm\"][\"PadV2\"]).apply(null,arguments)};var _Pow=Module[\"_Pow\"]=function(){return(_Pow=Module[\"_Pow\"]=Module[\"asm\"][\"Pow\"]).apply(null,arguments)};var _Prelu=Module[\"_Prelu\"]=function(){return(_Prelu=Module[\"_Prelu\"]=Module[\"asm\"][\"Prelu\"]).apply(null,arguments)};var _Prod=Module[\"_Prod\"]=function(){return(_Prod=Module[\"_Prod\"]=Module[\"asm\"][\"Prod\"]).apply(null,arguments)};var _RealDiv=Module[\"_RealDiv\"]=function(){return(_RealDiv=Module[\"_RealDiv\"]=Module[\"asm\"][\"RealDiv\"]).apply(null,arguments)};var _Reciprocal=Module[\"_Reciprocal\"]=function(){return(_Reciprocal=Module[\"_Reciprocal\"]=Module[\"asm\"][\"Reciprocal\"]).apply(null,arguments)};var _Relu=Module[\"_Relu\"]=function(){return(_Relu=Module[\"_Relu\"]=Module[\"asm\"][\"Relu\"]).apply(null,arguments)};var _Relu6=Module[\"_Relu6\"]=function(){return(_Relu6=Module[\"_Relu6\"]=Module[\"asm\"][\"Relu6\"]).apply(null,arguments)};var _ResizeBilinear=Module[\"_ResizeBilinear\"]=function(){return(_ResizeBilinear=Module[\"_ResizeBilinear\"]=Module[\"asm\"][\"ResizeBilinear\"]).apply(null,arguments)};var _ResizeBilinearGrad=Module[\"_ResizeBilinearGrad\"]=function(){return(_ResizeBilinearGrad=Module[\"_ResizeBilinearGrad\"]=Module[\"asm\"][\"ResizeBilinearGrad\"]).apply(null,arguments)};var _ResizeNearestNeighbor=Module[\"_ResizeNearestNeighbor\"]=function(){return(_ResizeNearestNeighbor=Module[\"_ResizeNearestNeighbor\"]=Module[\"asm\"][\"ResizeNearestNeighbor\"]).apply(null,arguments)};var _ResizeNearestNeighborGrad=Module[\"_ResizeNearestNeighborGrad\"]=function(){return(_ResizeNearestNeighborGrad=Module[\"_ResizeNearestNeighborGrad\"]=Module[\"asm\"][\"ResizeNearestNeighborGrad\"]).apply(null,arguments)};var _Reverse=Module[\"_Reverse\"]=function(){return(_Reverse=Module[\"_Reverse\"]=Module[\"asm\"][\"Reverse\"]).apply(null,arguments)};var _RotateWithOffset=Module[\"_RotateWithOffset\"]=function(){return(_RotateWithOffset=Module[\"_RotateWithOffset\"]=Module[\"asm\"][\"RotateWithOffset\"]).apply(null,arguments)};var _Round=Module[\"_Round\"]=function(){return(_Round=Module[\"_Round\"]=Module[\"asm\"][\"Round\"]).apply(null,arguments)};var _Rsqrt=Module[\"_Rsqrt\"]=function(){return(_Rsqrt=Module[\"_Rsqrt\"]=Module[\"asm\"][\"Rsqrt\"]).apply(null,arguments)};var _ScatterNd=Module[\"_ScatterNd\"]=function(){return(_ScatterNd=Module[\"_ScatterNd\"]=Module[\"asm\"][\"ScatterNd\"]).apply(null,arguments)};var _SearchSorted=Module[\"_SearchSorted\"]=function(){return(_SearchSorted=Module[\"_SearchSorted\"]=Module[\"asm\"][\"SearchSorted\"]).apply(null,arguments)};var _SelectV2=Module[\"_SelectV2\"]=function(){return(_SelectV2=Module[\"_SelectV2\"]=Module[\"asm\"][\"SelectV2\"]).apply(null,arguments)};var _Selu=Module[\"_Selu\"]=function(){return(_Selu=Module[\"_Selu\"]=Module[\"asm\"][\"Selu\"]).apply(null,arguments)};var _Sigmoid=Module[\"_Sigmoid\"]=function(){return(_Sigmoid=Module[\"_Sigmoid\"]=Module[\"asm\"][\"Sigmoid\"]).apply(null,arguments)};var _Sign=Module[\"_Sign\"]=function(){return(_Sign=Module[\"_Sign\"]=Module[\"asm\"][\"Sign\"]).apply(null,arguments)};var _Sin=Module[\"_Sin\"]=function(){return(_Sin=Module[\"_Sin\"]=Module[\"asm\"][\"Sin\"]).apply(null,arguments)};var _Sinh=Module[\"_Sinh\"]=function(){return(_Sinh=Module[\"_Sinh\"]=Module[\"asm\"][\"Sinh\"]).apply(null,arguments)};var _Softmax=Module[\"_Softmax\"]=function(){return(_Softmax=Module[\"_Softmax\"]=Module[\"asm\"][\"Softmax\"]).apply(null,arguments)};var _Softplus=Module[\"_Softplus\"]=function(){return(_Softplus=Module[\"_Softplus\"]=Module[\"asm\"][\"Softplus\"]).apply(null,arguments)};var _SparseFillEmptyRows=Module[\"_SparseFillEmptyRows\"]=function(){return(_SparseFillEmptyRows=Module[\"_SparseFillEmptyRows\"]=Module[\"asm\"][\"SparseFillEmptyRows\"]).apply(null,arguments)};var _SparseReshape=Module[\"_SparseReshape\"]=function(){return(_SparseReshape=Module[\"_SparseReshape\"]=Module[\"asm\"][\"SparseReshape\"]).apply(null,arguments)};var _SparseSegmentReduction=Module[\"_SparseSegmentReduction\"]=function(){return(_SparseSegmentReduction=Module[\"_SparseSegmentReduction\"]=Module[\"asm\"][\"SparseSegmentReduction\"]).apply(null,arguments)};var _SparseToDense=Module[\"_SparseToDense\"]=function(){return(_SparseToDense=Module[\"_SparseToDense\"]=Module[\"asm\"][\"SparseToDense\"]).apply(null,arguments)};var _Sqrt=Module[\"_Sqrt\"]=function(){return(_Sqrt=Module[\"_Sqrt\"]=Module[\"asm\"][\"Sqrt\"]).apply(null,arguments)};var _Square=Module[\"_Square\"]=function(){return(_Square=Module[\"_Square\"]=Module[\"asm\"][\"Square\"]).apply(null,arguments)};var _SquaredDifference=Module[\"_SquaredDifference\"]=function(){return(_SquaredDifference=Module[\"_SquaredDifference\"]=Module[\"asm\"][\"SquaredDifference\"]).apply(null,arguments)};var _Step=Module[\"_Step\"]=function(){return(_Step=Module[\"_Step\"]=Module[\"asm\"][\"Step\"]).apply(null,arguments)};var _StridedSlice=Module[\"_StridedSlice\"]=function(){return(_StridedSlice=Module[\"_StridedSlice\"]=Module[\"asm\"][\"StridedSlice\"]).apply(null,arguments)};var _Sub=Module[\"_Sub\"]=function(){return(_Sub=Module[\"_Sub\"]=Module[\"asm\"][\"Sub\"]).apply(null,arguments)};var _Sum=Module[\"_Sum\"]=function(){return(_Sum=Module[\"_Sum\"]=Module[\"asm\"][\"Sum\"]).apply(null,arguments)};var _Tan=Module[\"_Tan\"]=function(){return(_Tan=Module[\"_Tan\"]=Module[\"asm\"][\"Tan\"]).apply(null,arguments)};var _Tanh=Module[\"_Tanh\"]=function(){return(_Tanh=Module[\"_Tanh\"]=Module[\"asm\"][\"Tanh\"]).apply(null,arguments)};var _TensorScatterUpdate=Module[\"_TensorScatterUpdate\"]=function(){return(_TensorScatterUpdate=Module[\"_TensorScatterUpdate\"]=Module[\"asm\"][\"TensorScatterUpdate\"]).apply(null,arguments)};var _Tile=Module[\"_Tile\"]=function(){return(_Tile=Module[\"_Tile\"]=Module[\"asm\"][\"Tile\"]).apply(null,arguments)};var _TopK=Module[\"_TopK\"]=function(){return(_TopK=Module[\"_TopK\"]=Module[\"asm\"][\"TopK\"]).apply(null,arguments)};var _Transform=Module[\"_Transform\"]=function(){return(_Transform=Module[\"_Transform\"]=Module[\"asm\"][\"Transform\"]).apply(null,arguments)};var _Transpose=Module[\"_Transpose\"]=function(){return(_Transpose=Module[\"_Transpose\"]=Module[\"asm\"][\"Transpose\"]).apply(null,arguments)};var __FusedMatMul=Module[\"__FusedMatMul\"]=function(){return(__FusedMatMul=Module[\"__FusedMatMul\"]=Module[\"asm\"][\"_FusedMatMul\"]).apply(null,arguments)};var _malloc=Module[\"_malloc\"]=function(){return(_malloc=Module[\"_malloc\"]=Module[\"asm\"][\"malloc\"]).apply(null,arguments)};var _free=Module[\"_free\"]=function(){return(_free=Module[\"_free\"]=Module[\"asm\"][\"free\"]).apply(null,arguments)};var ___errno_location=Module[\"___errno_location\"]=function(){return(___errno_location=Module[\"___errno_location\"]=Module[\"asm\"][\"__errno_location\"]).apply(null,arguments)};var stackSave=Module[\"stackSave\"]=function(){return(stackSave=Module[\"stackSave\"]=Module[\"asm\"][\"stackSave\"]).apply(null,arguments)};var stackRestore=Module[\"stackRestore\"]=function(){return(stackRestore=Module[\"stackRestore\"]=Module[\"asm\"][\"stackRestore\"]).apply(null,arguments)};var stackAlloc=Module[\"stackAlloc\"]=function(){return(stackAlloc=Module[\"stackAlloc\"]=Module[\"asm\"][\"stackAlloc\"]).apply(null,arguments)};var dynCall_iijjiiii=Module[\"dynCall_iijjiiii\"]=function(){return(dynCall_iijjiiii=Module[\"dynCall_iijjiiii\"]=Module[\"asm\"][\"dynCall_iijjiiii\"]).apply(null,arguments)};var dynCall_jiji=Module[\"dynCall_jiji\"]=function(){return(dynCall_jiji=Module[\"dynCall_jiji\"]=Module[\"asm\"][\"dynCall_jiji\"]).apply(null,arguments)};Module[\"cwrap\"]=cwrap;var calledRun;dependenciesFulfilled=function runCaller(){if(!calledRun)run();if(!calledRun)dependenciesFulfilled=runCaller};function run(args){args=args||arguments_;if(runDependencies>0){return}preRun();if(runDependencies>0){return}function doRun(){if(calledRun)return;calledRun=true;Module[\"calledRun\"]=true;if(ABORT)return;initRuntime();readyPromiseResolve(Module);if(Module[\"onRuntimeInitialized\"])Module[\"onRuntimeInitialized\"]();postRun()}if(Module[\"setStatus\"]){Module[\"setStatus\"](\"Running...\");setTimeout(function(){setTimeout(function(){Module[\"setStatus\"](\"\")},1);doRun()},1)}else{doRun()}}if(Module[\"preInit\"]){if(typeof Module[\"preInit\"]==\"function\")Module[\"preInit\"]=[Module[\"preInit\"]];while(Module[\"preInit\"].length>0){Module[\"preInit\"].pop()()}}run();var listenersAdded;if(beforeListeners){listenersAdded={uncaughtException:process.listeners(\"uncaughtException\").filter(function(listener){return!beforeListeners.uncaughtException.indexOf(listener)>-1}),unhandledRejection:process.listeners(\"unhandledRejection\").filter(function(listener){return!beforeListeners.unhandledRejection.indexOf(listener)>-1})}}var actualModule;if(typeof WasmBackendModule!==\"undefined\"){actualModule=WasmBackendModule}else if(typeof WasmBackendModuleThreadedSimd!==\"undefined\"){actualModule=WasmBackendModuleThreadedSimd}else{throw new Error(\"Could not find wasm module in post.js\")}if(listenersAdded){var tmpDispose=actualModule[\"_dispose\"];actualModule[\"_dispose\"]=function(){tmpDispose();listenersAdded.uncaughtException.forEach(function(listener){process.removeListener(\"uncaughtException\",listener)});listenersAdded.unhandledRejection.forEach(function(listener){process.removeListener(\"unhandledRejection\",listener)})}}\n\n\n  return WasmBackendModule.ready\n}\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = WasmBackendModule;\nelse if (typeof define === 'function' && define['amd'])\n  define([], function() { return WasmBackendModule; });\nelse if (typeof exports === 'object')\n  exports[\"WasmBackendModule\"] = WasmBackendModule;\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './flags_wasm';\n\nimport {backend_util, BackendTimingInfo, DataStorage, DataType, deprecationWarn, engine, env, KernelBackend, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasmModule, WasmFactoryConfig} from '../wasm-out/tfjs-backend-wasm';\nimport {BackendWasmThreadedSimdModule} from '../wasm-out/tfjs-backend-wasm-threaded-simd';\nimport * as wasmFactoryThreadedSimd_import from '../wasm-out/tfjs-backend-wasm-threaded-simd.js';\n// @ts-ignore\nimport {wasmWorkerContents} from '../wasm-out/tfjs-backend-wasm-threaded-simd.worker.js';\nimport * as wasmFactory_import from '../wasm-out/tfjs-backend-wasm.js';\n\n// This workaround is required for importing in Node.js without using\n// the node bundle (for testing). This would not be necessary if we\n// flipped esModuleInterop to true, but we likely can't do that since\n// google3 does not use it.\nconst wasmFactoryThreadedSimd = (wasmFactoryThreadedSimd_import.default ||\n                                 wasmFactoryThreadedSimd_import) as\n    typeof wasmFactoryThreadedSimd_import.default;\nconst wasmFactory = (wasmFactory_import.default || wasmFactory_import) as\n    typeof wasmFactory_import.default;\n\ninterface TensorData {\n  id: number;\n  memoryOffset: number;\n  shape: number[];\n  dtype: DataType;\n  refCount: number;\n  /** Only used for string tensors, storing encoded bytes. */\n  stringBytes?: Uint8Array[];\n}\n\nexport type DataId = object;  // object instead of {} to force non-primitive.\n\nexport class BackendWasm extends KernelBackend {\n  // 0 is reserved for null data ids.\n  private dataIdNextNumber = 1;\n  dataIdMap: DataStorage<TensorData>;\n\n  constructor(public wasm: BackendWasmModule|BackendWasmThreadedSimdModule) {\n    super();\n    this.wasm.tfjs.initWithThreadsCount(threadsCount);\n    actualThreadsCount = this.wasm.tfjs.getThreadsCount();\n    this.dataIdMap = new DataStorage(this, engine());\n  }\n\n  override write(\n      values: backend_util.BackendValues|null, shape: number[],\n      dtype: DataType): DataId {\n    const dataId = {id: this.dataIdNextNumber++};\n    this.move(dataId, values, shape, dtype, 1);\n    return dataId;\n  }\n\n  override numDataIds(): number {\n    return this.dataIdMap.numDataIds();\n  }\n\n  override async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  override move(\n      dataId: DataId, values: backend_util.BackendValues|null, shape: number[],\n      dtype: DataType, refCount: number): void {\n    const id = this.dataIdNextNumber++;\n    if (dtype === 'string') {\n      const stringBytes = values as Uint8Array[];\n      this.dataIdMap.set(\n          dataId,\n          {id, stringBytes, shape, dtype, memoryOffset: null, refCount});\n      return;\n    }\n\n    const size = util.sizeFromShape(shape);\n    const numBytes = size * util.bytesPerElement(dtype);\n\n    // `>>> 0` is needed for above 2GB allocations because wasm._malloc returns\n    // a signed int32 instead of an unsigned int32.\n    // https://v8.dev/blog/4gb-wasm-memory\n    const memoryOffset = this.wasm._malloc(numBytes) >>> 0;\n\n    this.dataIdMap.set(dataId, {id, memoryOffset, shape, dtype, refCount});\n\n    this.wasm.tfjs.registerTensor(id, size, memoryOffset);\n\n    if (values != null) {\n      this.wasm.HEAPU8.set(\n          new Uint8Array(\n              (values as backend_util.TypedArray).buffer,\n              (values as backend_util.TypedArray).byteOffset, numBytes),\n          memoryOffset);\n    }\n  }\n\n  override async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n\n  override readSync(dataId: DataId, start?: number, end?: number):\n      backend_util.BackendValues {\n    const {memoryOffset, dtype, shape, stringBytes} =\n        this.dataIdMap.get(dataId);\n    if (dtype === 'string') {\n      // Slice all elements.\n      if ((start == null || start === 0) &&\n          (end == null || end >= stringBytes.length)) {\n        return stringBytes;\n      }\n      return stringBytes.slice(start, end);\n    }\n    start = start || 0;\n    end = end || util.sizeFromShape(shape);\n    const bytesPerElement = util.bytesPerElement(dtype);\n    const bytes = this.wasm.HEAPU8.slice(\n        memoryOffset + start * bytesPerElement,\n        memoryOffset + end * bytesPerElement);\n    return typedArrayFromBuffer(bytes.buffer, dtype);\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released, false otherwise.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  override disposeData(dataId: DataId, force = false): boolean {\n    if (this.dataIdMap.has(dataId)) {\n      const data = this.dataIdMap.get(dataId);\n      data.refCount--;\n      if (!force && data.refCount > 0) {\n        return false;\n      }\n\n      this.wasm._free(data.memoryOffset);\n      this.wasm.tfjs.disposeData(data.id);\n      this.dataIdMap.delete(dataId);\n    }\n    return true;\n  }\n\n  /** Return refCount of a `TensorData`. */\n  override refCount(dataId: DataId): number {\n    if (this.dataIdMap.has(dataId)) {\n      const tensorData = this.dataIdMap.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  override incRef(dataId: DataId) {\n    const data = this.dataIdMap.get(dataId);\n    if (data != null) {\n      data.refCount++;\n    }\n  }\n\n  override floatPrecision(): 32 {\n    return 32;\n  }\n\n  // Returns the memory offset of a tensor. Useful for debugging and unit\n  // testing.\n  getMemoryOffset(dataId: DataId): number {\n    return this.dataIdMap.get(dataId).memoryOffset;\n  }\n\n  override dispose() {\n    this.wasm.tfjs.dispose();\n    if ('PThread' in this.wasm) {\n      this.wasm.PThread.terminateAllThreads();\n    }\n    this.wasm = null;\n  }\n\n  override memory() {\n    return {unreliable: false};\n  }\n\n  /**\n   * Make a tensor info for the output of an op. If `memoryOffset` is not\n   * present, this method allocates memory on the WASM heap. If `memoryOffset`\n   * is present, the memory was allocated elsewhere (in c++) and we just record\n   * the pointer where that memory lives.\n   */\n  makeOutput(\n      shape: number[], dtype: DataType, memoryOffset?: number,\n      values?: backend_util.BackendValues): TensorInfo {\n    let dataId: {};\n    if (memoryOffset == null) {\n      dataId = this.write(values ?? null, shape, dtype);\n    } else {\n      const id = this.dataIdNextNumber++;\n      dataId = {id};\n      this.dataIdMap.set(dataId, {id, memoryOffset, shape, dtype, refCount: 1});\n      const size = util.sizeFromShape(shape);\n      this.wasm.tfjs.registerTensor(id, size, memoryOffset);\n    }\n    return {dataId, shape, dtype};\n  }\n\n  typedArrayFromHeap({shape, dtype, dataId}: TensorInfo):\n      backend_util.TypedArray {\n    const buffer = this.wasm.HEAPU8.buffer;\n    const {memoryOffset} = this.dataIdMap.get(dataId);\n    const size = util.sizeFromShape(shape);\n    switch (dtype) {\n      case 'float32':\n        return new Float32Array(buffer, memoryOffset, size);\n      case 'int32':\n        return new Int32Array(buffer, memoryOffset, size);\n      case 'bool':\n        return new Uint8Array(buffer, memoryOffset, size);\n      default:\n        throw new Error(`Unknown dtype ${dtype}`);\n    }\n  }\n}\n\nfunction createInstantiateWasmFunc(path: string) {\n  // this will be replace by rollup plugin patchWechatWebAssembly in\n  // minprogram's output.\n  // tslint:disable-next-line:no-any\n  return (imports: any, callback: any) => {\n    util.fetch(path, {credentials: 'same-origin'}).then((response) => {\n      if (!response['ok']) {\n        imports.env.a(`failed to load wasm binary file at '${path}'`);\n      }\n      response.arrayBuffer().then(binary => {\n        WebAssembly.instantiate(binary, imports).then(output => {\n          callback(output.instance, output.module);\n        });\n      });\n    });\n    return {};\n  };\n}\n\n/**\n * Returns the path of the WASM binary.\n * @param simdSupported whether SIMD is supported\n * @param threadsSupported whether multithreading is supported\n * @param wasmModuleFolder the directory containing the WASM binaries.\n */\nfunction getPathToWasmBinary(\n    simdSupported: boolean, threadsSupported: boolean,\n    wasmModuleFolder: string) {\n  if (wasmPath != null) {\n    // If wasmPath is defined, the user has supplied a full path to\n    // the vanilla .wasm binary.\n    return wasmPath;\n  }\n\n  let path: WasmBinaryName = 'tfjs-backend-wasm.wasm';\n  if (simdSupported && threadsSupported) {\n    path = 'tfjs-backend-wasm-threaded-simd.wasm';\n  } else if (simdSupported) {\n    path = 'tfjs-backend-wasm-simd.wasm';\n  }\n\n  if (wasmFileMap != null) {\n    if (wasmFileMap[path] != null) {\n      return wasmFileMap[path];\n    }\n  }\n\n  return wasmModuleFolder + path;\n}\n\n/**\n * Initializes the wasm module and creates the js <--> wasm bridge.\n *\n * NOTE: We wrap the wasm module in a object with property 'wasm' instead of\n * returning Promise<BackendWasmModule> to avoid freezing Chrome (last tested\n * in Chrome 76).\n */\nexport async function init(): Promise<{wasm: BackendWasmModule}> {\n  const [simdSupported, threadsSupported] = await Promise.all([\n    env().getAsync('WASM_HAS_SIMD_SUPPORT'),\n    env().getAsync('WASM_HAS_MULTITHREAD_SUPPORT')\n  ]);\n\n  return new Promise((resolve, reject) => {\n    const factoryConfig: WasmFactoryConfig = {};\n\n    /**\n     * This function overrides the Emscripten module locateFile utility.\n     * @param path The relative path to the file that needs to be loaded.\n     * @param prefix The path to the main JavaScript file's directory.\n     */\n    factoryConfig.locateFile = (path, prefix) => {\n      if (path.endsWith('.worker.js')) {\n        // Escape '\\n' because Blob will turn it into a newline.\n        // There should be a setting for this, but 'endings: \"native\"' does\n        // not seem to work.\n        const response = (wasmWorkerContents as string).replace(/\\n/g, '\\\\n');\n        const blob = new Blob([response], {type: 'application/javascript'});\n        return URL.createObjectURL(blob);\n      }\n\n      if (path.endsWith('.wasm')) {\n        return getPathToWasmBinary(\n            simdSupported as boolean, threadsSupported as boolean,\n            wasmPathPrefix != null ? wasmPathPrefix : prefix);\n      }\n      return prefix + path;\n    };\n\n    // Use the instantiateWasm override when system fetch is not available.\n    // Reference:\n    // https://github.com/emscripten-core/emscripten/blob/2bca083cbbd5a4133db61fbd74d04f7feecfa907/tests/manual_wasm_instantiate.html#L170\n    if (customFetch) {\n      factoryConfig.instantiateWasm =\n          createInstantiateWasmFunc(getPathToWasmBinary(\n              simdSupported as boolean, threadsSupported as boolean,\n              wasmPathPrefix != null ? wasmPathPrefix : ''));\n    }\n\n    let initialized = false;\n    factoryConfig.onAbort = () => {\n      if (initialized) {\n        // Emscripten already called console.warn so no need to double log.\n        return;\n      }\n      if (initAborted) {\n        // Emscripten calls `onAbort` twice, resulting in double error\n        // messages.\n        return;\n      }\n      initAborted = true;\n      const rejectMsg =\n          'Make sure the server can serve the `.wasm` file relative to the ' +\n          'bundled js file. For more details see https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-wasm/README.md#using-bundlers';\n      reject({message: rejectMsg});\n    };\n\n    let wasm: Promise<BackendWasmModule>;\n    // If `wasmPath` has been defined we must initialize the vanilla module.\n    if (threadsSupported && simdSupported && wasmPath == null) {\n      factoryConfig.mainScriptUrlOrBlob = new Blob(\n          [`var WasmBackendModuleThreadedSimd = ` +\n           wasmFactoryThreadedSimd.toString()],\n          {type: 'text/javascript'});\n      wasm = wasmFactoryThreadedSimd(factoryConfig);\n    } else {\n      // The wasmFactory works for both vanilla and SIMD binaries.\n      wasm = wasmFactory(factoryConfig);\n    }\n\n    // The `wasm` promise will resolve to the WASM module created by\n    // the factory, but it might have had errors during creation. Most\n    // errors are caught by the onAbort callback defined above.\n    // However, some errors, such as those occurring from a\n    // failed fetch, result in this promise being rejected. These are\n    // caught and re-rejected below.\n    wasm.then((module) => {\n          initialized = true;\n          initAborted = false;\n\n          const voidReturnType: string = null;\n          // Using the tfjs namespace to avoid conflict with emscripten's API.\n          module.tfjs = {\n            init: module.cwrap('init', null, []),\n            initWithThreadsCount:\n                module.cwrap('init_with_threads_count', null, ['number']),\n            getThreadsCount: module.cwrap('get_threads_count', 'number', []),\n            registerTensor: module.cwrap(\n                'register_tensor', null,\n                [\n                  'number',  // id\n                  'number',  // size\n                  'number',  // memoryOffset\n                ]),\n            disposeData:\n                module.cwrap('dispose_data', voidReturnType, ['number']),\n            dispose: module.cwrap('dispose', voidReturnType, []),\n          };\n\n          resolve({wasm: module});\n        })\n        .catch(reject);\n  });\n}\n\nfunction typedArrayFromBuffer(\n    buffer: ArrayBuffer, dtype: DataType): backend_util.TypedArray {\n  switch (dtype) {\n    case 'float32':\n      return new Float32Array(buffer);\n    case 'int32':\n      return new Int32Array(buffer);\n    case 'bool':\n      return new Uint8Array(buffer);\n    default:\n      throw new Error(`Unknown dtype ${dtype}`);\n  }\n}\n\nconst wasmBinaryNames = [\n  'tfjs-backend-wasm.wasm', 'tfjs-backend-wasm-simd.wasm',\n  'tfjs-backend-wasm-threaded-simd.wasm'\n] as const ;\ntype WasmBinaryName = typeof wasmBinaryNames[number];\n\nlet wasmPath: string = null;\nlet wasmPathPrefix: string = null;\nlet wasmFileMap: {[key in WasmBinaryName]?: string} = {};\nlet initAborted = false;\nlet customFetch = false;\n\n/**\n * @deprecated Use `setWasmPaths` instead.\n * Sets the path to the `.wasm` file which will be fetched when the wasm\n * backend is initialized. See\n * https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-wasm/README.md#using-bundlers\n * for more details.\n * @param path wasm file path or url\n * @param usePlatformFetch optional boolean to use platform fetch to download\n *     the wasm file, default to false.\n *\n * @doc {heading: 'Environment', namespace: 'wasm'}\n */\nexport function setWasmPath(path: string, usePlatformFetch = false): void {\n  deprecationWarn(\n      'setWasmPath has been deprecated in favor of setWasmPaths and' +\n      ' will be removed in a future release.');\n  if (initAborted) {\n    throw new Error(\n        'The WASM backend was already initialized. Make sure you call ' +\n        '`setWasmPath()` before you call `tf.setBackend()` or `tf.ready()`');\n  }\n  wasmPath = path;\n  customFetch = usePlatformFetch;\n}\n\n/**\n * Configures the locations of the WASM binaries.\n *\n * ```js\n * setWasmPaths({\n *  'tfjs-backend-wasm.wasm': 'renamed.wasm',\n *  'tfjs-backend-wasm-simd.wasm': 'renamed-simd.wasm',\n *  'tfjs-backend-wasm-threaded-simd.wasm': 'renamed-threaded-simd.wasm'\n * });\n * tf.setBackend('wasm');\n * ```\n *\n * @param prefixOrFileMap This can be either a string or object:\n *  - (string) The path to the directory where the WASM binaries are located.\n *     Note that this prefix will be used to load each binary (vanilla,\n *     SIMD-enabled, threading-enabled, etc.).\n *  - (object) Mapping from names of WASM binaries to custom\n *     full paths specifying the locations of those binaries. This is useful if\n *     your WASM binaries are not all located in the same directory, or if your\n *     WASM binaries have been renamed.\n * @param usePlatformFetch optional boolean to use platform fetch to download\n *     the wasm file, default to false.\n *\n * @doc {heading: 'Environment', namespace: 'wasm'}\n */\nexport function setWasmPaths(\n    prefixOrFileMap: string|{[key in WasmBinaryName]?: string},\n    usePlatformFetch = false): void {\n  if (initAborted) {\n    throw new Error(\n        'The WASM backend was already initialized. Make sure you call ' +\n        '`setWasmPaths()` before you call `tf.setBackend()` or ' +\n        '`tf.ready()`');\n  }\n\n  if (typeof prefixOrFileMap === 'string') {\n    wasmPathPrefix = prefixOrFileMap;\n  } else {\n    wasmFileMap = prefixOrFileMap;\n    const missingPaths =\n        wasmBinaryNames.filter(name => wasmFileMap[name] == null);\n    if (missingPaths.length > 0) {\n      throw new Error(\n          `There were no entries found for the following binaries: ` +\n          `${missingPaths.join(',')}. Please either call setWasmPaths with a ` +\n          `map providing a path for each binary, or with a string indicating ` +\n          `the directory where all the binaries can be found.`);\n    }\n  }\n\n  customFetch = usePlatformFetch;\n}\n\n/** Used in unit tests. */\nexport function resetWasmPath(): void {\n  wasmPath = null;\n  wasmPathPrefix = null;\n  wasmFileMap = {};\n  customFetch = false;\n  initAborted = false;\n}\n\nlet threadsCount = -1;\nlet actualThreadsCount = -1;\n\n/**\n * Sets the number of threads that will be used by XNNPACK to create\n * threadpool (default to the number of logical CPU cores).\n *\n * This must be called before calling `tf.setBackend('wasm')`.\n */\nexport function setThreadsCount(numThreads: number) {\n  threadsCount = numThreads;\n}\n\n/**\n * Gets the actual threads count that is used by XNNPACK.\n *\n * It is set after the backend is intialized.\n */\nexport function getThreadsCount(): number {\n  if (actualThreadsCount === -1) {\n    throw new Error(`WASM backend not initialized.`);\n  }\n  return actualThreadsCount;\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '4.13.0';\nexport {version};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_wasm';\n\nimport {registerBackend} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm, init} from './backend_wasm';\n\nexport {BackendWasm, getThreadsCount, setThreadsCount, setWasmPath, setWasmPaths} from './backend_wasm';\nexport {version as version_wasm} from './version';\n\nconst WASM_PRIORITY = 2;\nregisterBackend('wasm', async () => {\n  const {wasm} = await init();\n  return new BackendWasm(wasm);\n}, WASM_PRIORITY);\n"],"names":["CppDType","FusableActivation","wasmFusedMatMul","_fusedMatMulConfig","kernelName","_FusedMatMul","backendName","setupFunc","backend","wasm","cwrap","kernelFunc","args","inputs","attrs","a","b","bias","preluActivationWeights","dtype","Error","transposeA","transposeB","activation","leakyreluAlpha","aId","dataIdMap","get","dataId","id","bId","biasId","biasData","shape","length","preluActivationWeightsId","fusedActivation","leftDim","rightDim","batchDims","broadcast_util","assertAndGetBroadcastShape","slice","out","makeOutput","outId","aShapeBytes","Uint8Array","Int32Array","buffer","bShapeBytes","createUnaryKernelConfig","outType","wasmFunc","x","xId","util","sizeFromShape","absConfig","Abs","acosConfig","Acos","acoshConfig","Acosh","createBinaryKernelConfig","supportsFullBroadcast","outputType","newShape","backend_util","addConfig","Add","addNConfig","AddN","inputIds","map","inputIdsBytes","identity","tensor","readSync","inVals","typedArrayFromHeap","set","identityConfig","Identity","wasmTranspose","transpose","reducedShape","perm","newPerm","i","push","minValIdx","j","removeOneSizeDims","permIsNoOp","outShape","inShape","Array","computeOutShape","cloned","permBytes","xShapeBytes","transposeConfig","Transpose","permuteAxesAndTranspose","axis","xShape","xRank","originalAxes","parseAxisParam","axes","permutedAxes","getAxesPermutation","xTransposed","inputWasTransposed","getInnerMostAxes","transposed","wasmAll","allConfig","All","keepDims","inputId","input","inputRank","assertAxesAreInnerMostDims","reduceShape","computeOutAndReduceShapes","reduceSize","disposeData","expandShapeToKeepDim","wasmAny","anyConfig","Any","createArgMinMaxKernelConfig","transposedId","outerSize","innerSize","argMaxConfig","ArgMax","argMinConfig","ArgMin","asinConfig","Asin","asinhConfig","Asinh","atanConfig","Atan","atan2Config","Atan2","atanhConfig","Atanh","wasmAvgPool","avgPoolConfig","AvgPool","filterSize","strides","pad","dimRoundingMode","convInfo","computePool2DInfo","filterHeight","filterWidth","padTop","padInfo","top","padRight","right","padBottom","bottom","padLeft","left","strideHeight","strideWidth","channels","inChannels","dataFormat","dilationWidth","dilationHeight","wasmAvgPool3D","avgPool3DConfig","AvgPool3D","computePool3DInfo","batchSize","inDepth","inHeight","inWidth","outDepth","outHeight","outWidth","strideDepth","dilationDepth","effectiveFilterDepth","effectiveFilterHeight","effectiveFilterWidth","front","wasmAvgPool3DGrad","avgPool3DGradConfig","AvgPool3DGrad","dy","dx","filterDepth","wasmAvgPoolGrad","avgPoolGradConfig","AvgPoolGrad","reshape","xSize","$shape","inferFromImplicitShape","assert","incRef","reshapeConfig","Reshape","wasmBatchMatMul","batchMatMulConfig","BatchMatMul","aRank","bRank","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","concat","b3dShape","a3d","b3d","a3dId","b3dId","batchDim","Math","max","sliceImpl","vals","begin","size","isContinous","slice_util","isSliceContinous","xStrides","computeStrides","flatOffset","computeFlatOffset","subarray","decodedData","fromUint8ToStringArray","inBuf","outBuf","outLoc","indexToLoc","inLoc","idx","fromStringArrayToUint8","values","RowPartitionType","StringNGramsOp","constructor","separator","nGramWidths","leftPad","rightPad","padWidth","preserveShortSequences","this","encodeString","preserveShort","getPadWidth","nGramWidth","min","getNumNGrams","createNGrams","data","splitIndex","output","outputStartIndex","numNGrams","nGramIndex","leftPadding","rightPadding","numTokens","dataStartIndex","nGramSize","n","nGram","nextNGramIndex","appendToNGram","str","forEach","value","compute","splits","inputDataSize","splitsSize","prevSplit","validSplits","numBatchItems","nGramsSplits","getArrayFromDType","empty","nGrams","outputStartIdx","dataLength","split","delimiters","skipEmpty","result","delimiter","f","indexOf","token","tokenStart","begin_","size_","parseSliceParams","xVals","outData","stringBytes","res","sliceImplCPU","outVals","rank","xStride","outOffset","beginI","beginJ","endI","xOffset","slice2d","xStride1","xStride2","beginK","endJ","slice3d","xStride3","endK","beginL","k","slice4d","sliceConfig","Slice","batchToSpaceNDConfig","BatchToSpaceND","blockShape","crops","prod","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","xReshaped","xTransposedReshaped","wasmBincount","bincountConfig","Bincount","weights","hasWeights","p","v","tensorId","bitwiseAndConfig","BitwiseAnd","broadcastArgsConfig","BroadcastArgs","s0","s1","s0Vals","s1Vals","broadcastShape","from","undefined","cast","castConfig","Cast","ceilConfig","Ceil","wasmClip","clipByValueConfig","ClipByValue","clipValueMin","clipValueMax","shapes","t","assertParamsConsistent","$inputs","filter","inputs2D","inputsValShapes","simplyConcat","offset","colOffset","tIdx","row","resIdx","col","concatImplCPU","finalOutShape","sumInnerDims","innerDims","innerDim","inOffset","concatConfig","Concat","wasmConv2d","conv2DConfig","Conv2D","filterId","dilations","$dataFormat","convertConv2DDataFormat","computeConv2DInfo","inputChannels","outputChannels","outChannels","isSamePad","type","wasmConv2DBackpropInput","conv2DBackpropInputConfig","Conv2DBackpropInput","inputShape","topPad","isChannelsLast","dxStrides","dyStrides","fltS0","fltS1","fltS2","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","dyId","wasmConv3D","conv3DConfig","Conv3D","computeConv3DInfo","wasmConv3DBackpropFilterV2","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","filterShape","dw","wasmConv3DBackpropInputV2","conv3DBackpropInputV2Config","Conv3DBackpropInputV2","cosConfig","Cos","coshConfig","Cosh","InterpolationMethod","wasmCropAndResize","cropAndResizeConfig","CropAndResize","method","extrapolationValue","cropSize","image","boxes","boxInd","numBoxes","cropHeight","cropWidth","castedData","imagesData","imagesId","boxesId","boxIndId","imagesShapeBytes","wasmCumprod","cumprodConfig","Cumprod","exclusive","reverse","permutation","permutedX","permutedAxis","permutedOut","finalDim","permutedXId","permutedOutId","getUndoAxesPermutation","wasmCumsum","cumsumConfig","Cumsum","wasmDenseBincount","denseBincountConfig","DenseBincount","binaryOutput","wasmDepthToSpace","depthToSpaceConfig","DepthToSpace","blockSize","outputHeight","outputWidth","outputDepth","outputShape","xStridesBytes","outputShapeBytes","outStridesBytes","wasmDepthwiseConv2d","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","$dilations","wasmDiag","diagConfig","Diag","wasmDilation2D","dilation2DConfig","Dilation2D","dilationInfo","computeDilation2DInfo","wasmDilation2DBackpropFilter","dilation2DBackpropFilterConfig","Dilation2DBackpropFilter","gradients","wasmDilation2DBackpropInput","dilation2DBackpropInputConfig","Dilation2DBackpropInput","eluConfig","Elu","wasmEluGrad","eluGradConfig","EluGrad","y","equalConfig","Equal","erfConfig","Erf","expConfig","Exp","expandDims","dim","$dim","splice","expandDimsConfig","ExpandDims","expm1Config","Expm1","fill","inferDtype","fillConfig","Fill","wasmFlipLeftRight","flipLeftRightConfig","FlipLeftRight","imageId","batch","imageHeight","imageWidth","numChannels","floorConfig","Floor","floorDivConfig","FloorDiv","wasmBatchNorm","fusedBatchNormConfig","FusedBatchNorm","varianceEpsilon","mean","variance","scale","meanId","varianceId","offsetId","scaleId","wasmFusedConv2d","fusedConv2DConfig","FusedConv2D","wasmFusedDepthwiseConv2d","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","wasmGatherNd","gatherNdConfig","GatherNd","params","indices","resultShape","numSlices","gather_util","prepareAndValidate","indicesShape","sliceRank","indicesId","stridesBytes","wasmGather","gatherV2Config","GatherV2","parsedAxis","indicesVals","axisDim","index","shapeInfo","segment_util","collectGatherOpShapeInfo","flattenX","dimSize","indicesSize","flattenIndex","flattenOutputShape","stridesSize","greaterConfig","Greater","greaterEqualConfig","GreaterEqual","isFiniteConfig","IsFinite","isInfConfig","IsInf","isNaNConfig","IsNan","leakyReluConfig","LeakyRelu","alpha","lessConfig","Less","lessEqualConfig","LessEqual","wasmLinSpace","linSpaceConfig","LinSpace","start","stop","num","numInt","floor","logConfig","Log","log1pConfig","Log1p","logicalAndConfig","LogicalAnd","logicalNotConfig","LogicalNot","logicalOrConfig","LogicalOr","logicalXorConfig","LogicalXor","wasmLRN","lrnConfig","LRN","depthRadius","beta","wasmLRNGrad","lrnGradConfig","LRNGrad","wasmMax","maxConfig","Max","reductionIndices","maximumConfig","Maximum","wasmMaxPool","maxPoolConfig","MaxPool","wasmMaxPool3D","maxPool3DConfig","MaxPool3D","wasmMaxPool3DGrad","maxPool3DGradConfig","MaxPool3DGrad","wasmMaxPoolGrad","maxPoolGradConfig","MaxPoolGrad","wasmMaxPoolWithArgmax","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","includeBatchInIndex","eitherStridesOrDilationsAreOne","pooled","indexes","wasmMean","meanConfig","Mean","reductionAxes","castedInput","wasmMin","minConfig","Min","minimumConfig","Minimum","MirrorPaddingMode","wasmMirrorPad","mirrorPadConfig","MirrorPad","paddings","mode","prePaddingsFlat","padTuple","postPaddingsFlat","prePaddingsBytes","postPaddingsBytes","softmax","logits","softmaxConfig","Softmax","wasmMultinomial","multinomialConfig","Multinomial","numSamples","seed","normalized","probabilities","numEvents","modConfig","Mod","multiplyConfig","Multiply","negConfig","Neg","parseResultStruct","resOffset","HEAPU8","pSelectedIndices","selectedSize","pSelectedScores","pValidOutputs","_free","nonMaxSuppressionV3Config","NonMaxSuppressionV3","iouThreshold","maxOutputSize","scoreThreshold","scores","scoresId","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","notEqualConfig","NotEqual","wasmOneHot","oneHotConfig","OneHot","depth","onValue","offValue","onesLikeConfig","OnesLike","packConfig","Pack","assertShapesMatch","intermediateTensorInfos","expandedT","wasmPadV2","padV2Config","PadV2","constantValue","powConfig","Pow","wasmPrelu","preluConfig","Prelu","weightsId","wasmProd","prodConfig","Prod","rangeConfig","Range","step","makeZerosTypedArray","numElements","abs","ceil","rangeImplCPU","realDivConfig","RealDiv","reciprocalConfig","Reciprocal","reluConfig","Relu","relu6Config","Relu6","wasmResizeBilinear","resizeBilinearConfig","ResizeBilinear","images","alignCorners","halfPixelCenters","newHeight","newWidth","oldHeight","oldWidth","xData","wasmResizeBilinearGrad","resizeBilinearGradConfig","ResizeBilinearGrad","wasmResizeNearestNeighbor","resizeNearestNeighborConfig","ResizeNearestNeighbor","wasmResizeNearestNeighborGrad","resizeNearestNeighborGradConfig","ResizeNearestNeighborGrad","wasmReverse","reverseConfig","Reverse","dims","axesBytes","outShapeBytes","wasmRotate","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","getImageCenter","fillValues","fillBytes","roundConfig","Round","rsqrtConfig","Rsqrt","wasmScatterNd","scatterNdConfig","ScatterNd","updates","numUpdates","outputSize","scatter_util","calculateShapes","updatesId","wasmSearchSorted","searchSortedConfig","SearchSorted","sortedSequence","side","wasmSelect","selectConfig","Select","condition","e","conditionId","tId","eId","cRank","tRank","seluConfig","Selu","sigmoidConfig","Sigmoid","signConfig","Sign","sinConfig","Sin","sinhConfig","Sinh","softplusConfig","Softplus","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","flattenShape","paddedXReshaped","paddedXT","wasmSparseFillEmptyRows","sparseFillEmptyRowsConfig","SparseFillEmptyRows","denseShape","defaultValue","indicesCount","denseRows","maxOutputIndicesShape","valuesId","defaultValueId","outputIndices","outputIndicesId","outputValues","outputValuesId","emptyRowIndicator","emptyRowIndicatorId","reverseIndexMap","reverseIndexMapId","exceptionValues","exceptionValuesId","outputRows","exceptionValuesArray","exceptionMessage","getSparseFillEmptyRowsIndicesDenseShapeMismatch","getSparseFillEmptyRowsNegativeIndexErrorMessage","getSparseFillEmptyRowsOutOfRangeIndexErrorMessage","resizedIndices","resizedValues","wasmSparseReshape","sparseReshapeConfig","SparseReshape","inputIndices","inputIndicesId","inputShapeId","newShapeId","nnz","outputRank","newIndices","newIndicesId","outputShapeId","getSparseReshapeMultipleNegativeOneOutputDimErrorMessage","getSparseReshapeNegativeOutputDimErrorMessage","getSparseReshapeEmptyTensorZeroOutputDimErrorMessage","inputShapeValues","outputShapeValues","getSparseReshapeInputOutputMultipleErrorMessage","getSparseReshapeInputOutputMismatchErrorMessage","wasmSparseSegmentReduction","setup","sparseSegmentReduction","isMean","segmentIds","numIndices","segmentIdsBack","getSparseSegmentReductionNegativeSegmentIdsErrorMessage","segmentIdsId","outputId","getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage","getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage","getSparseSegmentReductionIndicesOutOfRangeErrorMessage","sparseSegmentMeanConfig","SparseSegmentMean","sparseSegmentSumConfig","SparseSegmentSum","wasmSparseToDense","sparseToDenseConfig","SparseToDense","sparseIndices","sparseValues","sparseIndicesId","sparseValuesId","splitVConfig","SplitV","numOrSizeSplits","$axis","splitSizes","prepareSplitSize","s","xSliceSize","xSlice","sqrtConfig","Sqrt","squareConfig","Square","squaredDifferenceConfig","SquaredDifference","wasmStep","stepConfig","Step","wasmStridedSlice","stridedSliceConfig","StridedSlice","end","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","finalShapeSparse","finalShape","isIdentity","sliceDim0","isSimpleSlice","$begin","$end","$strides","sliceInfo","sliced","beginBytes","endBytes","stringNGramsConfig","StringNGrams","dataSplits","$data","$dataSplits","stringNGramsImplCPU","nGramsOut","nGramsSplitsOut","stringSplitConfig","StringSplit","inputVals","delimiterVals","tokens","maxNumEntries","prevTokensLength","nEntries","c","stringSplitImplCPU","indicesOut","valuesOut","shapeOut","stringToHashBucketFastConfig","StringToHashBucketFast","numBuckets","fingerPrint64","modulo","getLowBitsUnsigned","stringToHashBucketFastImplCPU","subConfig","Sub","wasmSum","sumConfig","Sum","tanConfig","Tan","tanhConfig","Tanh","wasmTensorScatterUpdate","tensorScatterUpdateConfig","TensorScatterUpdate","wasmTile","wasmTopK","wasmTransform","kernelConfigs","Tile","reps","newShapeBytes","TopK","sorted","outValues","outValuesId","outIndices","outIndicesId","Transform","transforms","interpolation","fillMode","inputStrides","outputStrides","transformsId","interpolationModeId","fillModeId","Unique","uniqueElements","Map","inputBuffer","TensorBuffer","uniqueIndices","is1DTensor","element","toString","axisValues","m","join","existingIndex","uniqueIndex","outputTmpShape","outputBuffer","uniqueElementIndex","uniqueImplCPU","Unpack","numOutputs","outIndex","outs","ZerosLike","kernelConfig","registerKernel","ENV","env","registerFlag","async","WebAssembly","validate","MessageChannel","port1","postMessage","SharedArrayBuffer","_scriptDir","WasmBackendModuleThreadedSimd","document","currentScript","src","__filename","GROWABLE_HEAP_I8","wasmMemory","updateGlobalBufferAndViews","HEAP8","GROWABLE_HEAP_U8","GROWABLE_HEAP_I32","HEAP32","GROWABLE_HEAP_U32","HEAPU32","GROWABLE_HEAP_F64","HEAPF64","readyPromiseResolve","readyPromiseReject","beforeListeners","Module","Promise","resolve","reject","process","listeners","uncaughtException","unhandledRejection","read_","readAsync","readBinary","moduleOverrides","Object","assign","quit_","status","toThrow","ENVIRONMENT_IS_WEB","window","ENVIRONMENT_IS_WORKER","importScripts","ENVIRONMENT_IS_NODE","versions","node","ENVIRONMENT_IS_PTHREAD","scriptDirectory","locateFile","path","fs","require$$0","nodePath","require$$1","nodeWorkerThreads","dirname","__dirname","filename","binary","isFileURI","URL","normalize","readFileSync","ret","onload","onerror","readFile","err","replace","ex","ExitStatus","reason","keepRuntimeAlive","require","console","error","global","Worker","self","location","href","substr","lastIndexOf","url","xhr","XMLHttpRequest","open","send","responseText","responseType","response","performance","require$$3","defaultPrint","log","bind","defaultPrintErr","warn","writeSync","wasmBinary","wasmModule","noExitRuntime","abort","EXITSTATUS","ABORT","UTF8Decoder","TextDecoder","UTF8ArrayToString","heapOrArray","maxBytesToRead","endIdx","endPtr","decode","u0","u1","u2","String","fromCharCode","ch","buf","Int8Array","Int16Array","Uint16Array","Uint32Array","Float32Array","Float64Array","wasmTable","INITIAL_MEMORY","Memory","initial","maximum","shared","byteLength","__ATPRERUN__","__ATINIT__","__ATPOSTRUN__","initRuntime","callRuntimeCallbacks","wasmBinaryFile","runDependencies","dependenciesFulfilled","what","RuntimeError","isDataURI","startsWith","getBinary","file","ASM_CONSTS","name","message","cleanupThread","pthread_ptr","text","worker","PThread","pthreads","returnWorkerToPool","spawnThread","threadParams","getNewWorker","runningWorkers","msg","cmd","start_routine","startRoutine","arg","runPthread","ref","transferList","loaded","_proc_exit","code","_emscripten_proxy_to_main_thread_js","terminateAllThreads","_exit","implicit","exitOnMainThread","unusedWorkers","tlsInitFunctions","init","initWorker","initMainThread","pthreadPoolSize","allocateUnusedWorker","setExitStatus","terminate","unref","__emscripten_thread_free_data","receiveObjectTransfer","threadInitTLS","loadWasmModuleToWorker","onFinishedLoading","onmessage","d","currentProxiedOperationCallerThread","_pthread_self","targetWorker","targetThread","executeNotifiedProxyingQueue","killThread","alert","target","lineno","on","handlers","handler","hasOwnProperty","urlOrBlob","pthreadMainJs","pop","callbacks","shift","returnCode","handleException","stackTop","stackSize","_emscripten_stack_set_limits","stackRestore","_emscripten_get_now","wasmTableMirror","pthreadCreateProxied","attr","___pthread_create_js","queue","Atomics","store","__emscripten_proxy_execute_task_queue","compareExchange","warnOnce","shown","withStackSave","stack","stackSave","sync","numCallArgs","arguments","outerArgs","serializedNumCallArgs","stackAlloc","_emscripten_run_in_main_runtime_thread_js","ptr","funcPtr","func","__emscripten_thread_exit","timeOrigin","now","_emscripten_receive_on_main_thread_js_callArgs","emscripten_realloc_buffer","grow","_fd_close","fd","_fd_seek","offset_low","offset_high","whence","newOffset","printCharBuffers","printChar","stream","curr","_fd_write","iov","iovcnt","pnum","len","getCFunc","ident","ccall","returnType","argTypes","opts","toC","string","outPtr","maxBytesToWrite","heap","outIdx","u","charCodeAt","stringToUTF8Array","stringToUTF8","array","arr","writeArrayToMemory","convertReturnValue","Boolean","cArgs","converter","apply","onDone","proxiedFunctionTable","asmLibraryArg","__emscripten_init_main_thread_js","tb","__emscripten_thread_init","__emscripten_thread_cleanup","thread","__pthread_create_js","_emscripten_default_pthread_stack_size","_emscripten_get_now_is_monotonic","_emscripten_notify_task_queue","targetThreadId","currThreadId","mainThreadId","setTimeout","_emscripten_set_offscreencanvas_size","width","height","emscripten_check_blocking_allowed","emscripten_date_now","Date","emscripten_get_heap_max","emscripten_get_now","emscripten_memcpy_big","dest","copyWithin","emscripten_num_logical_cores","require$$4","cpus","navigator","emscripten_receive_on_main_thread_js","emscripten_resize_heap","requestedSize","oldSize","multiple","maxHeapSize","cutDown","overGrownHeapSize","emscripten_unwind_to_js_event_loop","exit","fd_close","fd_seek","fd_write","memory","info","wasi_snapshot_preview1","receiveInstance","instance","module","tlsInitFunc","cb","exports","unshift","numWorkersToLoad","w","callback","removeRunDependency","receiveInstantiationResult","instantiateArrayBuffer","receiver","fetch","credentials","then","catch","getBinaryPromise","instantiate","instantiateStreaming","createWasm","calledRun","listenersAdded","actualModule","run","startWorker","preRun","doRun","postRun","numericArgs","every","runCaller","listener","WasmBackendModule","tmpDispose","removeListener","ready","wasmWorkerContents","wasmFactoryThreadedSimd","wasmFactoryThreadedSimd_import.default","wasmFactoryThreadedSimd_import","wasmFactory","wasmFactory_import.default","BackendWasm","KernelBackend","super","dataIdNextNumber","tfjs","initWithThreadsCount","threadsCount","actualThreadsCount","getThreadsCount","DataStorage","engine","write","move","numDataIds","kernelMs","refCount","memoryOffset","numBytes","bytesPerElement","_malloc","registerTensor","byteOffset","typedArrayFromBuffer","force","has","delete","floatPrecision","getMemoryOffset","dispose","unreliable","getPathToWasmBinary","simdSupported","threadsSupported","wasmModuleFolder","wasmPath","wasmFileMap","all","getAsync","factoryConfig","prefix","endsWith","blob","Blob","createObjectURL","wasmPathPrefix","customFetch","instantiateWasm","imports","arrayBuffer","initialized","onAbort","initAborted","mainScriptUrlOrBlob","wasmBinaryNames","setWasmPath","usePlatformFetch","deprecationWarn","setWasmPaths","prefixOrFileMap","missingPaths","setThreadsCount","numThreads","version","registerBackend"],"mappings":";;;;;;;;;;;;;;;;mhGAkBA,IAAYA,GASAC,GCJZ,IAAIC,IDLJ,SAAYF,GACVA,EAAAA,EAAA,QAAA,GAAA,UACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,OAAA,GAAA,SACAA,EAAAA,EAAA,UAAA,GAAA,WACD,CAND,CAAYA,KAAAA,GAMX,CAAA,IAGD,SAAYC,GACVA,EAAAA,EAAA,OAAA,GAAA,SACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,UAAA,GAAA,YACAA,EAAAA,EAAA,QAAA,GAAA,UACAA,EAAAA,EAAA,IAAA,GAAA,KACD,CARD,CAAYA,KAAAA,GAQX,CAAA,ICuEM,MAAME,GAAmC,CAC9CC,WAAYC,EACZC,YAAa,OACbC,UA/EF,SAAeC,GACbN,GAAkBM,EAAQC,KAAKC,MAAML,EAAc,KAAiB,CAClE,SACA,QACA,SACA,SACA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAgEEM,WA9DF,SAA0BC,GAKxB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3BG,EAACA,EAACC,EAAEA,EAACC,KAAEA,EAAIC,uBAAEA,GAA0BL,EAE7C,GAAgB,YAAZE,EAAEI,OAAmC,YAAZH,EAAEG,MAC7B,MAAM,IAAIC,MACN,+DAGN,MAAMC,WAACA,EAAUC,WAAEA,EAAUC,WAAEA,EAAUC,eAAEA,GAAkBV,EACvDW,EAAMjB,EAAQkB,UAAUC,IAAIZ,EAAEa,QAAQC,GACtCC,EAAMtB,EAAQkB,UAAUC,IAAIX,EAAEY,QAAQC,GAE5C,IAAIE,EAAS,EACb,GAAY,MAARd,EAAc,CAChB,MAAMe,EAAWxB,EAAQkB,UAAUC,IAAIV,EAAKW,QAC5C,GAA8B,IAA1BI,EAASC,MAAMC,OACjB,MAAM,IAAId,MAEN,uDAAQY,EAASC,MAAMC,WAE7BH,EAASC,EAASH,EACnB,CACD,MAAMM,EAAqD,MAA1BjB,EAC7B,EACAV,EAAQkB,UAAUC,IAAIT,EAAuBU,QAAQC,GACnDO,EACFnC,GAAkBsB,GAEtB,GAAuB,MAAnBa,EACF,MAAM,IAAIhB,MACN,GAAGG,uEAIT,MAAMc,EAAUhB,EAAaN,EAAEkB,MAAM,GAAKlB,EAAEkB,MAAM,GAC5CK,EAAWhB,EAAaN,EAAEiB,MAAM,GAAKjB,EAAEiB,MAAM,GAC7CM,EAAYC,EAAeC,2BAC7B1B,EAAEkB,MAAMS,MAAM,GAAI,GAAI1B,EAAEiB,MAAMS,MAAM,GAAI,IAEtCC,EAAMnC,EAAQoC,WAAW,IAAIL,EAAWF,EAASC,GAAWvB,EAAEI,OAC9D0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1CiB,EAAc,IAAIC,WAAW,IAAIC,WAAWjC,EAAEkB,OAAOgB,QACrDC,EAAc,IAAIH,WAAW,IAAIC,WAAWhC,EAAEiB,OAAOgB,QAO3D,OALA/C,GACIuB,EAAKqB,EAAa/B,EAAEkB,MAAMC,OAAQJ,EAAKoB,EAAalC,EAAEiB,MAAMC,OAC5Db,EAAYC,EAAYc,EAAiBL,EAAQI,EACjDX,GAAkB,EAAGqB,GAElBF,CACT,GCjFgB,SAAAQ,GACZ/C,EAAoBgD,GACtB,IAAIC,EA0BJ,MAAO,CAACjD,aAAYE,YAAa,OAAQC,UAxBzC,SAAmBC,GACjB6C,EAAW7C,EAAQC,KAAKC,MAAMN,EAAY,KAAiB,CACzD,SACA,SACA,UAEH,EAkBmDO,WAhBpD,SAAoBC,GAElB,MAAMJ,QAACA,EAASK,QAAQyC,EAACA,IAAM1C,EACzB2C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOmB,GAAWE,EAAEnC,OAC/C0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAGhD,OAAsC,IAAlC2B,EAAKC,cAAcd,EAAIV,QAI3BoB,EAASE,EAAKvD,GAASsD,EAAEnC,OAAQ0B,GAHxBF,CAKV,EAGH,CChCO,MAAMe,GAA0BP,GAAwBQ,GCClDC,GAA2BT,GAAwBU,GCAnDC,GAA4BX,GAAwBY,YCEjDC,GACZ5D,EAAoB6D,EACpB9C,GACF,IAAIkC,EA6CJ,MAAO,CAACjD,aAAYE,YAAa,OAAQC,UAxCzC,SAAmBC,GACjB6C,EAAW7C,EAAQC,KAAKC,MAAMN,EAAY,KAAiB,CACzD,SACA,QACA,SACA,SACA,QACA,SACA,SACA,UAEH,EA6BmDO,WA3BpD,SAAoBC,GAElB,MAAMJ,QAACA,EAAOK,OAAEA,GAAUD,GACpBG,EAACA,EAACC,EAAEA,GAAKH,EACTY,EAAMjB,EAAQkB,UAAUC,IAAIZ,EAAEa,QAAQC,GACtCC,EAAMtB,EAAQkB,UAAUC,IAAIX,EAAEY,QAAQC,GAEtCqC,EAAsB,MAAT/C,EAAgBA,EAAQJ,EAAEI,MACvCgD,EAAWC,EAAa3B,2BAA2B1B,EAAEkB,MAAOjB,EAAEiB,OAC9DU,EAAMnC,EAAQoC,WAAWuB,EAAUD,GAGzC,GAAqC,IAAjCV,EAAKC,cAAcU,GACrB,OAAOxB,EAGT,MAAMG,EAAc,IAAIC,WAAW,IAAIC,WAAWjC,EAAEkB,OAAOgB,QACrDC,EAAc,IAAIH,WAAW,IAAIC,WAAWhC,EAAEiB,OAAOgB,QACrDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OALyBwB,EACrB5B,EAAKqB,EAAa/B,EAAEkB,MAAMC,OAAQJ,EAAKoB,EAAalC,EAAEiB,MAAMC,OAC5DlC,GAASe,EAAEI,OAAQ0B,GAGhBF,CACR,EAGH,CCjDO,MAAM0B,GACTL,GAAyBM,GCD7B,IAAIjB,GA8BG,MAAMkB,GAA2B,CACtCnE,WAAYoE,EACZlE,YAAa,iBA5Bf,SAAmBE,GACjB6C,GAAW7C,EAAQC,KAAKC,MAAM8D,EAAM,KAAiB,CACnD,QACA,SACA,SACA,UAEJ,EAuBE7D,WArBF,SAAcC,GACZ,MAAMC,OAACA,EAAML,QAAEA,GAAWI,EACpB+B,EAAMnC,EAAQoC,WAAW/B,EAAO,GAAGoB,MAAOpB,EAAO,GAAGM,OAG1D,GAAsC,IAAlCqC,EAAKC,cAAcd,EAAIV,OACzB,OAAOU,EAGT,MAAM8B,EAAW5D,EAAO6D,KAAIpB,GAAK9C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,KAC3D8C,EAAgB,IAAI5B,WAAW,IAAIC,WAAWyB,GAAUxB,QACxDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAGhD,OAFAwB,GAASsB,EAAeF,EAASvC,OAAQlC,GAAS2C,EAAIxB,OAAQ0B,GAEvDF,CACT,GC7BM,SAAUiC,GAAShE,GAEvB,MAAOC,QAAQyC,EAACA,GAAE9C,QAAEA,GAAWI,EAE/B,GAAgB,WAAZ0C,EAAEnC,MACJ,OAAO0D,EAAOrE,EAAQsE,SAASxB,EAAE1B,QAAS0B,EAAErB,MAAOqB,EAAEnC,OAGvD,MAAMwB,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OACpC4D,EAASvE,EAAQwE,mBAAmB1B,GAG1C,OAFgB9C,EAAQwE,mBAAmBrC,GACnCsC,IAAIF,GACLpC,CACT,CAEO,MAAMuC,GAA+B,CAC1C9E,WAAY+E,EACZ7E,YAAa,OACbK,WAAYiE,IChBd,IAAIQ,GAgBE,SAAUC,GACZzE,GAGF,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAG1B0E,EAAcC,GAyCvB,SACItD,EAAiBsD,GACnB,MAAMpB,EAAqB,GACrBqB,EAAoB,GAC1B,IAAK,IAAIC,EAAI,EAAGA,EAAIxD,EAAMC,SAAUuD,EACjB,IAAbxD,EAAMwD,IACRtB,EAASuB,KAAKzD,EAAMwD,IAEC,IAAnBxD,EAAMsD,EAAKE,KACbD,EAAQE,KAAKH,EAAKE,IAGtB,IAAK,IAAIA,EAAI,EAAGA,EAAID,EAAQtD,SAAUuD,EAAG,CACvC,IAAIE,GAAa,EACjB,IAAK,IAAIC,EAAI,EAAGA,EAAIJ,EAAQtD,SAAU0D,EAChCJ,EAAQI,IAAMH,KACE,IAAfE,GAAoBH,EAAQG,GAAaH,EAAQI,MACpDD,EAAYC,GAGhBJ,EAAQG,GAAaF,CACtB,CACD,MAAO,CAACtB,EAAUqB,EACpB,CAhE+BK,CAAkBhF,EAAOyC,EAAErB,MAAOnB,EAAMyE,MAErE,IAAIO,GAAa,EACjB,IAAK,IAAIL,EAAI,EAAGA,EAAIF,EAAKrD,OAAQuD,IAC3BF,EAAKE,KAAOA,IACdK,GAAa,GAGjB,MAAMC,EAyBR,SAAyBC,EAAmBT,GAC1C,MAAMQ,EAAW,IAAIE,MAAMD,EAAQ9D,QACnC,IAAK,IAAIuD,EAAI,EAAGA,EAAIM,EAAS7D,OAAQuD,IACnCM,EAASN,GAAKO,EAAQT,EAAKE,IAE7B,OAAOM,CACT,CA/BmBG,CAAgBrF,EAAOyC,EAAErB,MAAOnB,EAAMyE,MACjDjC,EAAI,CACR1B,OAAQf,EAAOyC,EAAE1B,OACjBK,MAAOqD,EACPnE,MAAON,EAAOyC,EAAEnC,OAGlB,GAAI2E,EAAY,CACd,MAAMK,EAASvB,GAAS,CAAC/D,SAAQL,YAEjC,OADA2F,EAAOlE,MAAQ8D,EACRI,CACR,CAED,MAAMxD,EAAMnC,EAAQoC,WAAWmD,EAAUzC,EAAEnC,OACrCoC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCgB,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAC1CuE,EAAY,IAAIrD,WAAW,IAAIC,WAAWuC,GAAMtC,QAChDoD,EAAc,IAAItD,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QAK3D,OAHAmC,GACI7B,EAAK8C,EAAa/C,EAAErB,MAAMC,OAAQlC,GAASsD,EAAEnC,OAAQ0B,EAAOuD,EAC5Db,EAAKrD,QACFS,CACT,CAmCO,MAAM2D,GAAgC,CAC3ClG,WAAYmG,EACZjG,YAAa,OACbK,WAAY0E,GACZ9E,UAzFF,SAAeC,GACb4E,GAAgB5E,EAAQC,KAAKC,MAAM6F,EAAW,KAAiB,CAC7D,SACA,QACA,SACA,SACA,SACA,QACA,UAEJ,YCTgBC,GACZlD,EAAemD,EAAuBjG,GAMxC,MAAMkG,EAASpD,EAAErB,MACX0E,EAAQrD,EAAErB,MAAMC,OAEhB0E,EAAepD,EAAKqD,eAAeJ,EAAMC,GAC/C,IAAII,EAAOF,EACX,MAAMG,EAAe3C,EAAa4C,mBAAmBF,EAAMH,GAC3D,IAAIM,EAAc,KACdC,GAAqB,EACzB,GAAoB,MAAhBH,EAAsB,CACxB,MAAM5C,EAAqB,IAAI8B,MAAMU,GACrC,IAAK,IAAIlB,EAAI,EAAGA,EAAItB,EAASjC,OAAQuD,IACnCtB,EAASsB,GAAKiB,EAAOK,EAAatB,IAGpCqB,EAAO1C,EAAa+C,iBAAiBL,EAAK5E,OAAQyE,GAClDM,EACI5B,GAAU,CAACxE,OAAQ,CAACyC,KAAIxC,MAAO,CAACyE,KAAMwB,GAAevG,YAEzD,MAAM+C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACvBrB,EAAQkB,UAAUC,IAAIsF,EAAYrF,QAAQC,KAC1C0B,IACnB2D,GAAqB,EAExB,CAED,MAAO,CAACE,WAAYH,EAAaL,eAAcE,OAAMI,qBACvD,CCvCA,IAAIG,GAkDG,MAAMC,GAA0B,CACrClH,WAAYmH,EACZjH,YAAa,OACbC,UAnDF,SAAeC,GACb6G,GAAU7G,EAAQC,KAAKC,MAAM6G,EAAK,KAAe,CAAC,0BACpD,EAkDE5G,WAhDF,SAAaC,GAEX,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,EAAIe,SAAEA,GAAY1G,GACnBwC,EAACA,GAAKzC,EAEZ,IAAI4G,EADQjH,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAExC6F,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,GAAI0G,EAAoB,CAEtBQ,EAAQN,EACRK,EAFqBjH,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,EAG/D,CAED,MAAM8F,EAAYD,EAAMzF,MAAMC,OAC9BkC,EAAawD,2BAA2B,MAAOd,EAAMa,GACrD,MAAO5B,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO6E,GAClDiB,EAAavE,EAAKC,cAAcoE,GAEhClF,EAAMnC,EAAQoC,WAAWmD,EAAUzC,EAAEnC,OAC3C,GAAwC,IAApCqC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDwF,GAAQI,EAASM,EAAYlF,EAC9B,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAED,OAAOxB,CACT,GChDA,IAAIuF,GAkDG,MAAMC,GAA0B,CACrC/H,WAAYgI,EACZ9H,YAAa,OACbC,UAnDF,SAAeC,GACb0H,GAAU1H,EAAQC,KAAKC,MAAM0H,EAAK,KAAe,CAAC,0BACpD,EAkDEzH,WAhDF,SAAaC,GAEX,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,EAAIe,SAAEA,GAAY1G,GACnBwC,EAACA,GAAKzC,EAEZ,IAAI4G,EADQjH,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAExC6F,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,GAAI0G,EAAoB,CAEtBQ,EAAQN,EACRK,EAFqBjH,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,EAG/D,CAED,MAAM8F,EAAYD,EAAMzF,MAAMC,OAC9BkC,EAAawD,2BAA2B,MAAOd,EAAMa,GACrD,MAAO5B,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO6E,GAClDiB,EAAavE,EAAKC,cAAcoE,GAEhClF,EAAMnC,EAAQoC,WAAWmD,EAAUzC,EAAEnC,OAC3C,GAAwC,IAApCqC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDqG,GAAQT,EAASM,EAAYlF,EAC9B,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAED,OAAOxB,CACT,GChDM,SAAU0F,GAA4BjI,GAE1C,IAAIiD,EAsDJ,MAAO,CACLjD,aACAE,YAAa,OACbC,UArDF,SAAmBC,GACjB6C,EAAW7C,EAAQC,KAAKC,MAAMN,EAAY,KAAiB,CACzD,SACA,SACA,SACA,SACA,UAEH,EA8CCO,WA5CF,SAAoBC,GAKlB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,GAAQ3F,GACTwC,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAC5C,IAAI4F,EAAUlE,EACVmE,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAII,mBAAEA,GACrBV,GAAwBlD,EAAGmD,EAAMjG,GAErC,GAAI0G,EAAoB,CACtB,MAAMoB,EAAe9H,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,GAC1DyG,IAAiB/E,IAGnBmE,EAAQN,EACRK,EAAUa,EAEb,CAED,MAAMvC,EAAW2B,EAAMzF,MAAMS,MAAM,GAAI,GACjCC,EAAMnC,EAAQoC,WAAWmD,EAAU,SACnClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAC1C0G,EAAY/E,EAAKC,cAAcd,EAAIV,OACnCuG,EAAYd,EAAMzF,MAAM6E,EAAK,IAQnC,OAPAzD,EAASoE,EAASzH,GAAS0H,EAAMvG,OAAQoH,EAAWC,EAAW3F,GAE3DqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG1Be,CACR,EAQH,CChEO,MAAM8F,GAA6BJ,GAA4BK,GCAzDC,GAA6BN,GAA4BO,GCAzDC,GAA2B1F,GAAwB2F,GCAnDC,GAA4B5F,GAAwB6F,GCApDC,GAA2B9F,GAAwB+F,GCAnDC,GACTnF,GAAyBoF,GCDhBC,GAA4BlG,GAAwBmG,GCAjE,IAAIC,GAoEG,MAAMC,GAA8B,CACzCpJ,WAAYqJ,EACZnJ,YAAa,OACbC,UAjEF,SAAeC,GACb+I,GAAc/I,EAAQC,KAAKC,MAAM+I,EAAS,KAAiB,CACzD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAiDE9I,WA/CF,SACIC,GACF,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,EAE3B0C,EAAIzC,EAAOyC,EACXC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,IAEtC6H,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,GAAmB/I,EAC9CgJ,EAAW1F,EAAa2F,kBAC1BzG,EAAErB,MAAOyH,EAAYC,EAAS,EAAmBC,EAAKC,GAEpDG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAASJ,EAASK,QAAQC,IAC1BC,EAAWP,EAASK,QAAQG,MAC5BC,EAAYT,EAASK,QAAQK,OAC7BC,EAAUX,EAASK,QAAQO,KAC3BC,EAAeb,EAASa,aACxBC,EAAcd,EAASc,YACvBC,EAAWf,EAASgB,WAE1B,GAA4B,iBAAxBhB,EAASiB,WACX,MAAM,IAAI3J,MAEN,6CAAG0I,EAASiB,2CAGlB,GAA+B,IAA3BjB,EAASkB,eAAmD,IAA5BlB,EAASmB,eAC3C,MAAM,IAAI7J,MAEN,0EAAQ0I,EAASmB,mBAAmBnB,EAASkB,mBAGnD,MAAMrI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAU,WAC5ClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OAJA0H,GACIhG,EAAKD,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAI+H,EAAcC,EACvDC,EAAQG,EAAUE,EAAWE,EAASE,EAAcC,EAAaC,EACjEhI,GACGF,CACT,GClEA,IAAIuI,GA+EG,MAAMC,GAAgC,CAC3C/K,WAAYgL,EACZ9K,YAAa,OACbC,UAzEF,SAAeC,GACb0K,GAAgB1K,EAAQC,KAAKC,MAAM,YAAa,KAAM,CACpD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAiDEC,WA/CI,SAAoBC,GAKxB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,EAAekB,WAAEA,GAAcjK,EAE1DgJ,EAAW1F,EAAaiH,kBAC1B/H,EAAErB,MAAmDyH,EAAYC,EACnD,EAAGC,EAAKC,EAAiBkB,GACrCpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAUzC,EAAEnC,OA4BpD,OA1BA+J,GACI1K,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAClCiI,EAASwB,UAGOxB,EAASgB,WACzBhB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAASiC,qBACTjC,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd/H,CACT,GC7EA,IAAIwJ,GAsFG,MAAMC,GAAoC,CAC/ChM,WAAYiM,EACZ/L,YAAa,OACbC,UA/EF,SAAeC,GACb2L,GAAoB3L,EAAQC,KAAKC,MAAM,gBAAiB,KAAM,CAC5D,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAoDEC,WAlDI,SAAwBC,GAK5B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0L,GAACA,EAAE5E,MAAEA,GAAS7G,GACd6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,GAAmB/I,EAE9CgJ,EAAW1F,EAAaiH,kBAC1B3D,EAAMzF,MAAmDyH,EACzDC,EAAuB,EAAGC,EAAKC,GAC7B0C,EAAK/L,EAAQoC,WAAW8E,EAAMzF,MAAOyF,EAAMvG,OA+BjD,OA7BAgL,GACI3L,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjCiI,EAASwB,UAGOxB,EAASgB,WACzBhB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAASiC,qBACTjC,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,KACjBZ,EAAS0C,YACT1C,EAASE,aACTF,EAASG,aAENsC,CACT,GCpFA,IAAIE,GAsEG,MAAMC,GAAkC,CAC7CtM,WAAYuM,EACZrM,YAAa,OACbC,UAjEF,SAAeC,GACbiM,GAAkBjM,EAAQC,KAAKC,MAAM,cAAe,KAAM,CACxD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EA6CEC,WA3CI,SAAsBC,GAK1B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0L,GAACA,EAAE5E,MAAEA,GAAS7G,GACd6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,GAAO9I,EAE7BgJ,EAAW1F,EAAa2F,kBAC1BrC,EAAMzF,MAA2CyH,EAAYC,EAC/C,EAAGC,GACf2C,EAAK/L,EAAQoC,WAAW8E,EAAMzF,MAAOyF,EAAMvG,OAwBjD,OAtBAsL,GACIjM,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjCiI,EAASwB,UAGOxB,EAASgB,WACzBhB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAASa,aACTb,EAASc,YACTd,EAASmB,eACTnB,EAASkB,cACTlB,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,KACjBZ,EAASE,aACTF,EAASG,aAENsC,CACT,GCpEM,SAAUK,GACZhM,GACF,MAAMC,OAACA,EAAMC,MAAEA,GAASF,GAClB0C,EAACA,GAAKzC,GACNoB,MAACA,GAASnB,EAEV+L,EAAQrJ,EAAKC,cAAcH,EAAErB,OAC7B6K,EAAStJ,EAAKuJ,uBAAuB9K,EAAO4K,GASlD,OAPArJ,EAAKwJ,OACDH,IAAUrJ,EAAKC,cAAcqJ,IAC7B,IAAM,cAAcA,iBAAsBxJ,EAAErB,0EAIhDrB,EAAKJ,QAAQyM,OAAO3J,EAAE1B,QACf,CAACA,OAAQ0B,EAAE1B,OAAQK,MAAO6K,EAAQ3L,MAAOmC,EAAEnC,MACpD,CAEO,MAAM+L,GAA8B,CACzC9M,WAAY+M,EACZ7M,YAAa,OACbK,WAAYiM,ICpBd,IAAIQ,GA4FG,MAAMC,GAAkC,CAC7CjN,WAAYkN,EACZhN,YAAa,OACbC,UA1FF,SAAeC,GACb4M,GAAkB5M,EAAQC,KAAKC,MAAM4M,EAAa,KAAiB,CACjE,SACA,QACA,SACA,SACA,QACA,SACA,SACA,SACA,UAEJ,EA+EE3M,WA7EF,SAAqBC,GAKnB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3BG,EAACA,EAACC,EAAEA,GAAKH,GACTQ,WAACA,EAAUC,WAAEA,GAAcR,EAEjC,GAAgB,YAAZC,EAAEI,OAAmC,YAAZH,EAAEG,MAC7B,MAAM,IAAIC,MACN,8DAGN,MAAMmM,EAAQxM,EAAEkB,MAAMC,OAChBsL,EAAQxM,EAAEiB,MAAMC,OAEhBuL,EAAcpM,EAAaN,EAAEkB,MAAMsL,EAAQ,GAAKxM,EAAEkB,MAAMsL,EAAQ,GAChEG,EAAcpM,EAAaN,EAAEiB,MAAMuL,EAAQ,GAAKxM,EAAEiB,MAAMuL,EAAQ,GAEhEG,EAActM,EAAaN,EAAEkB,MAAMsL,EAAQ,GAAKxM,EAAEkB,MAAMsL,EAAQ,GAChEK,EAActM,EAAaN,EAAEiB,MAAMuL,EAAQ,GAAKxM,EAAEiB,MAAMuL,EAAQ,GAEhEK,EAAa9M,EAAEkB,MAAMS,MAAM,GAAI,GAC/BoL,EAAa9M,EAAEiB,MAAMS,MAAM,GAAI,GAE/BqL,EAAYvK,EAAKC,cAAcoK,GAC/BG,EAAYxK,EAAKC,cAAcqK,GAI/B/H,EAFoBvD,EAAeC,2BACrC1B,EAAEkB,MAAMS,MAAM,GAAI,GAAI1B,EAAEiB,MAAMS,MAAM,GAAI,IACTuL,OAAO,CAACN,EAAaC,IAExDpK,EAAKwJ,OACDS,IAAgBC,GAChB,IAAM,kCAAkCD,WACjCC,6BAAuC3M,EAAEkB,aACzCjB,EAAEiB,wBAAwBZ,oBACVC,kBAE3B,MAEM4M,EAAW5M,EAAa,CAAC0M,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAGjDO,EAAMvB,GAAQ,CAAC/L,OAAQ,CAACyC,EAAGvC,GAAIP,UAASM,MAAO,CAACmB,MANrCZ,EAAa,CAAC0M,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,MAMjDW,EAAMxB,GAAQ,CAAC/L,OAAQ,CAACyC,EAAGtC,GAAIR,UAASM,MAAO,CAACmB,MAAOiM,KAEvDG,EAAQ7N,EAAQkB,UAAUC,IAAIwM,EAAIvM,QAAQC,GAC1CyM,EAAQ9N,EAAQkB,UAAUC,IAAIyM,EAAIxM,QAAQC,GAE1CQ,EAAUhB,EAAa8M,EAAIlM,MAAM,GAAKkM,EAAIlM,MAAM,GAChDK,EAAWhB,EAAa8M,EAAInM,MAAM,GAAKmM,EAAInM,MAAM,GACjDsM,EAAWC,KAAKC,IAAIV,EAAWC,GAE/BrL,EAAMnC,EAAQoC,WAAW,CAAC2L,EAAUlM,EAASC,GAAW6L,EAAIhN,OAC5D0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1CiB,EAAc,IAAIC,WAAW,IAAIC,WAAWmL,EAAIlM,OAAOgB,QACvDC,EAAc,IAAIH,WAAW,IAAIC,WAAWoL,EAAInM,OAAOgB,QAU7D,OARAmK,GACIiB,EAAOvL,EAAaqL,EAAIlM,MAAMC,OAAQoM,EAAOpL,EAC7CkL,EAAInM,MAAMC,OAAQb,EAAYC,EAAYuB,GAE9CrC,EAAQwH,YAAYmG,EAAIvM,QACxBpB,EAAQwH,YAAYoG,EAAIxM,QAExBe,EAAIV,MAAQ8D,EACLpD,CACT,GC3FM,SAAU+L,GACZC,EAAqBC,EAAiBC,EAAgB5M,EACtDd,GACF,MAAM2N,EAAcC,EAAWC,iBAAiB/M,EAAO2M,EAAOC,GACxD3M,EAASsB,EAAKC,cAAcoL,GAC5BI,EAAWzL,EAAK0L,eAAejN,GAErC,GAAI6M,EAAa,CACf,MAAMK,EAAaJ,EAAWK,kBAAkBR,EAAOK,GAEvD,MAAc,WAAV9N,EACMwN,EAAsBjM,MAAMyM,EAAYA,EAAajN,GAGvDyM,EAAoBU,SAASF,EAAYA,EAAajN,EAC/D,CAED,MAAMoN,EAAwB,WAAVnO,EAChBiD,EAAamL,uBAAuBZ,GACpCA,EAEEa,EAAQvM,EAAOhB,EAAOd,EAAOmO,GAC7BG,EAASxM,EAAO4L,EAAM1N,GAC5B,IAAK,IAAIsE,EAAI,EAAGA,EAAIgK,EAAOZ,OAAQpJ,EAAG,CACpC,MAAMiK,EAASD,EAAOE,WAAWlK,GAC3BmK,EAAQF,EAAOhL,KAAI,CAACmL,EAAajK,IAAMiK,EAAMjB,EAAMhJ,KACzD6J,EAAOxK,IAAIuK,EAAM7N,OAAOiO,MAAWF,EACpC,CAED,MAAc,WAAVvO,EACKiD,EAAa0L,uBAAuBL,EAAOM,QAE7CN,EAAOM,MAChB,CCpC0B3L,EAAa4L,iBCMvC,MAAMC,GAQJC,YACIC,EAAmBC,EAAuBC,EAC1CC,EAAkBC,EAAkBC,GACtCC,KAAKN,UAAY3M,EAAKkN,aAAaP,GACnCM,KAAKL,YAAcA,EACnBK,KAAKJ,QAAU7M,EAAKkN,aAAaL,GACjCI,KAAKH,SAAW9M,EAAKkN,aAAaJ,GAClCG,KAAKF,SAAWA,EAChBE,KAAKE,cAAgBH,CACtB,CAEOI,YAAYC,GAIlB,OAAOrC,KAAKsC,IACRL,KAAKF,SAAW,EAAIM,EAAa,EAAIJ,KAAKF,SAAUM,EAAa,EACtE,CAEOE,aAAa7O,EAAgB2O,GACnC,MAAMN,EAAWE,KAAKG,YAAYC,GAClC,OAAOrC,KAAKC,IAAI,EAAKvM,EAAS,EAAIqO,EAAYM,EAAc,EAC7D,CAEOG,aACJC,EAAoBC,EAAoBC,EACxCC,EAA0BC,EAAmBR,GAC/C,IAAK,IAAIS,EAAa,EAAGA,EAAaD,IAAaC,EAAY,CAC7D,MAAMf,EAAWE,KAAKG,YAAYC,GAC5BU,EAAc/C,KAAKC,IAAI,EAAG8B,EAAWe,GACrCE,EACFhD,KAAKC,IAAI,EAAG8B,GAAYc,GAAaC,EAAa,KAChDG,EAAYZ,GAAcU,EAAcC,GACxCE,EACFR,GAAcK,EAAc,EAAI,EAAID,EAAaf,GAIrD,IAAIoB,EAAY,EAEhBA,GAAaJ,EAAcd,KAAKJ,QAAQnO,OAExC,IAAK,IAAI0P,EAAI,EAAGA,EAAIH,IAAaG,EAC/BD,GAAaV,EAAKS,EAAiBE,GAAG1P,OAGxCyP,GAAaH,EAAef,KAAKH,SAASpO,OAG1CyP,IADsBJ,EAAcC,EAAeC,EAAY,GAClChB,KAAKN,UAAUjO,OAG5CiP,EAAOC,EAAmBE,GAAc,IAAIvO,WAAW4O,GACvD,MAAME,EAAQV,EAAOC,EAAmBE,GAExC,IAAIQ,EAAiB,EACrB,MAAMC,EAAiBC,GACnBA,EAAIC,SAASC,GAAUL,EAAMC,KAAoBI,IAErD,IAAK,IAAIN,EAAI,EAAGA,EAAIL,IAAeK,EACjCG,EAActB,KAAKJ,SACnB0B,EAActB,KAAKN,WAGrB,IAAK,IAAIyB,EAAI,EAAGA,EAAIH,EAAY,IAAKG,EACnCG,EAAcd,EAAKS,EAAiBE,IACpCG,EAActB,KAAKN,WAIrB,GAAIsB,EAAY,EAAG,CAIjBM,EAAcd,EAAKS,EAAiBD,EAAY,IAChD,IAAK,IAAIG,EAAI,EAAGA,EAAIJ,IAAgBI,EAClCG,EAActB,KAAKN,WACnB4B,EAActB,KAAKH,SAEtB,KAAM,CAKL,IAAK,IAAIsB,EAAI,EAAGA,EAAIJ,EAAe,IAAKI,EACtCG,EAActB,KAAKH,UACnByB,EAActB,KAAKN,WAErB4B,EAActB,KAAKH,SACpB,CACF,CACF,CAKM6B,QAAQlB,EAAoBmB,GAIjC,MAAMC,EAAgBpB,EAAK/O,OACrBoQ,EAAaF,EAAOlQ,OAC1B,GAAIoQ,EAAa,EAAG,CAClB,IAAIC,EAAYH,EAAO,GACvB,GAAkB,IAAdG,EACF,MAAM,IAAInR,MAAM,oCAAoCmR,KAEtD,IAAK,IAAI9M,EAAI,EAAGA,EAAI6M,IAAc7M,EAAG,CACnC,IAAI+M,EAAcJ,EAAO3M,IAAM8M,EAE/B,GADAC,EAAcA,GAAgBJ,EAAO3M,IAAM4M,GACtCG,EACH,MAAM,IAAIpR,MAAM,uBAAuBgR,EAAO3M,mBAC1C8M,MAAcF,MAEpBE,EAAYH,EAAO3M,EACpB,CACD,GAAI8M,IAAcF,EAChB,MAAM,IAAIjR,MAAM,gDACZiR,UAAsBE,IAE7B,CAED,MAAME,EAAgBH,EAAa,EAC7BI,EAAelP,EAAKmP,kBAAkB,QAASL,GAErD,GAAsB,IAAlBD,GAAsC,IAAfC,EAAkB,CAC3C,MAAMM,EAAsB,IAAI3M,MAAMoM,GACtC,IAAK,IAAI5M,EAAI,EAAGA,GAAKgN,IAAiBhN,EACpCiN,EAAajN,GAAK,EAEpB,MAAO,CAACmN,EAAOF,EAChB,CAEDA,EAAa,GAAK,EAClB,IAAK,IAAIjN,EAAI,EAAGA,GAAKgN,IAAiBhN,EAAG,CACvC,MAAMvD,EAASkQ,EAAO3M,GAAK2M,EAAO3M,EAAI,GACtC,IAAI4L,EAAY,EAChBZ,KAAKL,YAAY6B,SAASpB,IACxBQ,GAAaZ,KAAKM,aAAa7O,EAAQ2O,EAAW,IAEhDJ,KAAKE,eAAiBzO,EAAS,GAAmB,IAAdmP,IACtCA,EAAY,GAEdqB,EAAajN,GAAKiN,EAAajN,EAAI,GAAK4L,CACzC,CAED,MAAMwB,EAAuB,IAAI5M,MAAMyM,EAAaD,IAEpD,IAAK,IAAIhN,EAAI,EAAGA,EAAIgN,IAAiBhN,EAAG,CACtC,MAAMyL,EAAakB,EAAO3M,GAC1B,IAAIqN,EAAiBJ,EAAajN,GAalC,GAZAgL,KAAKL,YAAY6B,SAASpB,IACxB,MAAM3O,EAASkQ,EAAO3M,EAAI,GAAK2M,EAAO3M,GAChC4L,EAAYZ,KAAKM,aAAa7O,EAAQ2O,GAC5CJ,KAAKO,aACDC,EAAMC,EAAY2B,EAAQC,EAAgBzB,EAAWR,GACzDiC,GAAkBzB,CAAS,IAOzBZ,KAAKE,eAAiBmC,IAAmBJ,EAAajN,GAAI,CAC5D,MAAMsN,EAAaX,EAAO3M,EAAI,GAAK2M,EAAO3M,GAG1C,GAAmB,IAAfsN,EACF,SAKF,MAAMlC,EAAakC,EAAa,EAAItC,KAAKF,SACnCc,EAAY,EAClBZ,KAAKO,aACDC,EAAMC,EAAY2B,EAAQC,EAAgBzB,EAAWR,EAC1D,CACF,CACD,MAAO,CAACgC,EAAQH,EACjB,EClMH,SAASM,GACLhB,EAAiBiB,EAAwBC,EACzCC,GACF,IAAKnB,EAAI9P,OACP,OAGF,GAA0B,IAAtB+Q,EAAW/Q,OAAc,CAC3B,IAAK,IAAIuD,EAAI,EAAGA,EAAIuM,EAAI9P,SAAUuD,EAChC0N,EAAOzN,KAAKsM,EAAI3C,SAAS5J,EAAGA,EAAI,IAElC,MACD,CAED,GAA0B,IAAtBwN,EAAW/Q,OAAc,CAC3B,MAAMkR,EAAYH,EAAW,GAC7B,IAAII,EAAIrB,EAAIsB,QAAQF,GACpB,MAAc,IAAPC,GAAU,CACf,MAAME,EAAQvB,EAAI3C,SAAS,EAAGgE,GACzBH,GAA8B,IAAjBK,EAAMrR,QACtBiR,EAAOzN,KAAK6N,GAGdF,GADArB,EAAMA,EAAI3C,SAASgE,EAAI,IACfC,QAAQF,EACjB,CAID,YAHKF,GAA4B,IAAflB,EAAI9P,QACpBiR,EAAOzN,KAAKsM,GAGf,CAGD,IAAIwB,EAAa,EACjB,IAAK,IAAI/N,EAAI,EAAGA,EAAIuM,EAAI9P,OAAS,EAAGuD,IAClC,GAAKA,IAAMuM,EAAI9P,SAA4C,IAAhC+Q,EAAWK,QAAQtB,EAAIvM,IAAa,CAC7D,MAAM8N,EAAQvB,EAAI3C,SAASmE,EAAY/N,GAClCyN,GAA8B,IAAjBK,EAAMrR,QACtBiR,EAAOzN,KAAK6N,GAEdC,EAAa/N,EAAI,CAClB,CAEL,CCvCM,SAAU/C,GACZ9B,GACF,MAAOC,QAAQyC,EAACA,GAAIxC,OAAO8N,MAACA,EAAKC,KAAEA,GAAKrO,QAAEA,GAAWI,GAE9C6S,EAAQC,GAAS3E,EAAW4E,iBAAiBrQ,EAAGsL,EAAOC,GAExDC,EAAcC,EAAWC,iBAAiB1L,EAAErB,MAAOwR,EAAQC,GAC3DE,EAAQpT,EAAQsE,SAASxB,EAAE1B,QAC3Be,EAAMnC,EAAQoC,WAAW8Q,EAAOpQ,EAAEnC,OAClC8N,EAAWzL,EAAK0L,eAAe5L,EAAErB,OACjC4R,EAAUrT,EAAQkB,UAAUC,IAAIgB,EAAIf,QAE1C,GAAIkN,EAAa,CACf,MAAMK,EAAaJ,EAAWK,kBAAkBqE,EAAQxE,GAExD,GAAgB,WAAZ3L,EAAEnC,MACJ0S,EAAQC,YACHF,EACIlR,MAAMyM,EAAYA,EAAa3L,EAAKC,cAAciQ,QACtD,CACWlT,EAAQwE,mBAAmBrC,GACnCsC,IACH2O,EACIvE,SAASF,EAAYA,EAAa3L,EAAKC,cAAciQ,IAC/D,CAED,OAAO/Q,CACR,CAED,GAAgB,WAAZW,EAAEnC,MAAoB,CACxB,MAAM4S,EAAMC,GAAaJ,EAAOH,EAAQC,EAAOpQ,EAAErB,MAAOqB,EAAEnC,OAE1D,OADA0S,EAAQC,YAAcC,EACfpR,CACR,CAED,MAAMsR,EAAUzT,EAAQwE,mBAAmBrC,GACrCuR,EAAO5Q,EAAErB,MAAMC,OACrB,GAAa,IAATgS,GAsBN,SACIN,EAAgCO,EAChCF,EAAkCrF,EAClCC,GACF,IAAIuF,EAAY,EAChB,MAAMC,EAASzF,EAAM,GACf0F,EAAS1F,EAAM,GACf2F,EAAOF,EAASxF,EAAK,GAC3B,IAAK,IAAIpJ,EAAI4O,EAAQ5O,EAAI8O,EAAM9O,IAAK,CAClC,MAAM+O,EAAU/O,EAAI0O,EAAUG,EAC9BL,EAAQhP,IAAI2O,EAAMvE,SAASmF,EAASA,EAAU3F,EAAK,IAAKuF,GACxDA,GAAavF,EAAK,EACnB,CACH,CAlCI4F,CACIb,EAAqB3E,EAAS,GAAIgF,EAASR,EAC3CC,QACC,GAAa,IAATQ,GAiCb,SACIN,EAAgCc,EAAkBC,EAClDV,EAAkCrF,EAClCC,GACF,IAAIuF,EAAY,EAChB,MAAMC,EAASzF,EAAM,GACf0F,EAAS1F,EAAM,GACfgG,EAAShG,EAAM,GACf2F,EAAOF,EAASxF,EAAK,GACrBgG,EAAOP,EAASzF,EAAK,GAC3B,IAAK,IAAIpJ,EAAI4O,EAAQ5O,EAAI8O,EAAM9O,IAC7B,IAAK,IAAIG,EAAI0O,EAAQ1O,EAAIiP,EAAMjP,IAAK,CAClC,MAAM4O,EAAU/O,EAAIiP,EAAW9O,EAAI+O,EAAWC,EAC9CX,EAAQhP,IAAI2O,EAAMvE,SAASmF,EAASA,EAAU3F,EAAK,IAAKuF,GACxDA,GAAavF,EAAK,EACnB,CAEL,CAjDIiG,CACIlB,EAAqB3E,EAAS,GAAIA,EAAS,GAAIgF,EAC/CR,EAAoCC,QACnC,GAAa,IAATQ,GAgDb,SACIN,EAAgCc,EAAkBC,EAClDI,EAAkBd,EAClBrF,EACAC,GACF,IAAIuF,EAAY,EAChB,MAAMC,EAASzF,EAAM,GACf0F,EAAS1F,EAAM,GACfgG,EAAShG,EAAM,GACf2F,EAAOF,EAASxF,EAAK,GACrBgG,EAAOP,EAASzF,EAAK,GACrBmG,EAAOJ,EAAS/F,EAAK,GACrBoG,EAASrG,EAAM,GAErB,IAAK,IAAInJ,EAAI4O,EAAQ5O,EAAI8O,EAAM9O,IAC7B,IAAK,IAAIG,EAAI0O,EAAQ1O,EAAIiP,EAAMjP,IAC7B,IAAK,IAAIsP,EAAIN,EAAQM,EAAIF,EAAME,IAAK,CAClC,MAAMV,EAAU/O,EAAIiP,EAAW9O,EAAI+O,EAAWO,EAAIH,EAAWE,EAC7DhB,EAAQhP,IAAI2O,EAAMvE,SAASmF,EAASA,EAAU3F,EAAK,IAAKuF,GACxDA,GAAavF,EAAK,EACnB,CAGP,CAtEIsG,CACIvB,EAAqB3E,EAAS,GAAIA,EAAS,GAAIA,EAAS,GAAIgF,EAC5DR,EACAC,OACC,CACL,MAAMK,EACFC,GAAaJ,EAAOH,EAAQC,EAAOpQ,EAAErB,MAAOqB,EAAEnC,OAClD8S,EAAQhP,IAAI8O,EACb,CAED,OAAOpR,CACT,CA6DO,MAAMyS,GAA4B,CACvChV,WAAYiV,EACZ/U,YAAa,OACbK,WAAY+B,IChFP,MAAM4S,GAAqC,CAChDlV,WAAYmV,EACZjV,YAAa,OACbK,WAzCF,SAAwBC,GAKtB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN2U,WAACA,EAAUC,MAAEA,GAAS3U,EAEtB4U,EAAOF,EAAWG,QAAO,CAAC5U,EAAGC,IAAMD,EAAIC,IAEvC4U,EAAWxR,EAAayR,YAAYvS,EAAErB,MAAOuT,EAAYE,GACzDI,EAAW1R,EAAa2R,YAAYH,EAAS1T,OAAQsT,EAAWtT,QAChE8T,EACF5R,EAAa6R,oBAAoB3S,EAAErB,MAAOuT,EAAYE,GACpDQ,EACF9R,EAAa+R,oBAAoBV,EAAOD,EAAWtT,QACjDkU,EACFhS,EAAaiS,aAAaL,EAAkBP,EAAOD,EAAWtT,QAE5DoU,EAAY1J,GAAQ,CAAC/L,OAAQ,CAACyC,KAAI9C,UAASM,MAAO,CAACmB,MAAO2T,KAC1D3O,EACF5B,GAAU,CAACxE,OAAQ,CAACyC,EAAGgT,GAAY9V,UAASM,MAAO,CAACyE,KAAMuQ,KACxDS,EAAsB3J,GACxB,CAAC/L,OAAQ,CAACyC,EAAG2D,GAAczG,UAASM,MAAO,CAACmB,MAAO+T,KACjD7C,EAASzQ,GAAM,CACnB7B,OAAQ,CAACyC,EAAGiT,GACZ/V,UACAM,MAAO,CAAC8N,MAAOsH,EAAkBrH,KAAMuH,KAOzC,OAJA5V,EAAQwH,YAAYsO,EAAU1U,QAC9BpB,EAAQwH,YAAYf,EAAYrF,QAChCpB,EAAQwH,YAAYuO,EAAoB3U,QAEjCuR,CACT,GCvCA,IAAIqD,GAoCG,MAAMC,GAA+B,CAC1CrW,WAAYsW,EACZpW,YAAa,OACbC,UAnCF,SAAeC,GACbgW,GAAehW,EAAQC,KAAKC,MAAMgW,EAAU,KAAe,CACzD,SACA,SACA,UACA,SACA,SACA,UAEJ,EA2BE/V,WAzBF,SACIC,GAEF,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B0C,EAACA,EAACqT,QAAEA,GAAW9V,GACfgO,KAACA,GAAQ/N,EAET8V,EAA0D,IAA7CD,EAAQ1U,MAAM0T,QAAO,CAACkB,EAAGC,IAAMD,EAAIC,GAAG,GACnD/Q,EAA8B,IAAnBzC,EAAErB,MAAMC,OAAe,CAAC2M,GAAQ,CAACvL,EAAErB,MAAM,GAAI4M,GACxDlM,EAAMnC,EAAQoC,WAAWmD,EAAU4Q,EAAQxV,OAEjD,SAAS4V,EAASzT,GAChB,OAAO9C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,EACxC,CAKD,OAJA2U,GACIO,EAASzT,GAAIuL,EAAM+H,EAAYG,EAASJ,GAAU3W,GAAS2W,EAAQxV,OACnE4V,EAASpU,IAENA,CACT,GChCaqU,GACThT,GAAyBiT,GCatB,MAAMC,GAAoC,CAC/C9W,WAAY+W,EACZ7W,YAAa,OACbK,WArBI,SAAwBC,GAI5B,MAAMC,OAACA,EAAML,QAAEA,GAAWI,GACpBwW,GAACA,EAAEC,GAAEA,GAAMxW,EAEXyW,EAAS9W,EAAQwE,mBAAmBoS,GACpCG,EAAS/W,EAAQwE,mBAAmBqS,GAEpCG,EAAiBpT,EAAa3B,2BAChCwD,MAAMwR,KAAKH,GAASrR,MAAMwR,KAAKF,IAEnC,OAAO/W,EAAQoC,WACX,CAAC4U,EAAetV,QAAS,aAA0BwV,EACxC,IAAI1U,WAAWwU,GAChC,GCdM,SAAUG,GACZ/W,GAEF,MAAOC,QAAQyC,EAACA,GAAIxC,OAAOK,MAACA,GAAMX,QAAEA,GAAWI,EACzC+B,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOd,GAClC4D,EAASvE,EAAQwE,mBAAmB1B,GAG1C,OAFgB9C,EAAQwE,mBAAmBrC,GACnCsC,IAAIF,GACLpC,CACT,CAEO,MAAMiV,GAA2B,CACtCxX,WAAYyX,EACZvX,YAAa,OACbK,WAAYgX,IChBDG,GAA2B3U,GAAwB4U,GCChE,IAAIC,GA0BG,MAAMC,GAAkC,CAC7C7X,WAAY8X,EACZ5X,YAAa,OACbC,UA3BF,SAAeC,GACbwX,GAAWxX,EAAQC,KAAKC,MAAMwX,EAAa,KAAiB,CAC1D,SACA,SACA,SACA,UAEJ,EAqBEvX,WAnBF,SAAcC,GAKZ,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACNsX,aAACA,EAAYC,aAAEA,GAAgBtX,EAC/ByC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OACpC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAEhD,OADAmW,GAASzU,EAAK4U,EAAcC,EAAcvV,GACnCF,CACT,GCrBM,SAAUsL,GACZrN,GACF,MAAMC,OAACA,EAAML,QAAEA,GAAWI,EAEpB6F,EAAOjD,EAAKqD,eAAejG,EAAKE,MAAM2F,KAAM5F,EAAO,GAAGoB,OAAO,GAE7DoW,EAASxX,EAAO6D,KAAI4T,GAAKA,EAAErW,QACjCmC,EAAamU,uBAAuBF,EAAQ5R,GAE5C,IAAIV,EAAW3B,EAAa8B,gBAAgBrF,EAAO6D,KAAI4T,GAAKA,EAAErW,QAAQwE,GAGtE,MAAM+R,EAAU3X,EAAO4X,QAAOH,GAAK9U,EAAKC,cAAc6U,EAAErW,OAAS,IACjE,GAAuB,IAAnBuW,EAAQtW,OACV,OAAO0C,GAAS,CAAC/D,OAAQ,CAACyC,EAAGkV,EAAQ,IAAKhY,YAG5C,MAAMmC,EAAMnC,EAAQoC,WAAWmD,EAAUlF,EAAO,GAAGM,OAEnD,GAAqC,IAAjCqC,EAAKC,cAAcsC,GACrB,OAAOpD,EAGT,GAAyB,WAArB6V,EAAQ,GAAGrX,MAAoB,CAQjC,MAAMuX,EAAWF,EAAQ9T,KAAI4T,IAC3B,MAAM9P,EAAYhF,EAAKC,cAAc6U,EAAErW,MAAMS,MAAM+D,IAEnD,OAAOmG,GAAQ,CAAC/L,OAAQ,CAACyC,EAAGgV,GAAI9X,UAASM,MAAO,CAACmB,MADnC,EAAE,EAAGuG,KACsC,IAGrDmQ,EAAkBD,EAAShU,KAAI4T,IAC5B,CAAC3J,KAAMnO,EAAQsE,SAASwT,EAAE1W,QAASK,MAAOqW,EAAErW,UAIrD8D,EACI3B,EAAa8B,gBAAgBwS,EAAShU,KAAI4T,GAAKA,EAAErW,QAAQ,GAC7D,MAAM2W,EAAwC,IAAzBF,EAAS,GAAGzW,MAAM,GACjCgS,EClDJ,SACFpT,EAAuDkF,EACvD5E,EAAiByX,GACnB,MAAM3E,EAAUzQ,EAAKmP,kBAAkBxR,EAAOqC,EAAKC,cAAcsC,IAEjE,GAAI6S,GAA0B,WAAVzX,EAAoB,CAEtC,IAAI0X,EAAS,EACbhY,EAAOoR,SAAQvK,IACb,MAAMmH,EAAOrL,EAAKC,cAAciE,EAAMzF,OAErCgS,EAAuBhP,IAAIyC,EAAMiH,KAAoBkK,GACtDA,GAAUhK,CAAI,GAEjB,KAAM,CACL,IAAIiK,EAAY,EAEhBjY,EAAOoR,SAAQvK,IACb,MAAM4H,EAAwB,WAAVnO,EAChBiD,EAAamL,uBAAuB7H,EAAMiH,MAC1CjH,EAAMiH,KAEV,IAAIoK,EAAO,EAEX,IAAK,IAAIC,EAAM,EAAGA,EAAMtR,EAAMzF,MAAM,KAAM+W,EAAK,CAC7C,MAAMC,EAASD,EAAMjT,EAAS,GAAK+S,EACnC,IAAK,IAAII,EAAM,EAAGA,EAAMxR,EAAMzF,MAAM,KAAMiX,EACxCjF,EAAQgF,EAASC,GAAO5J,EAAYyJ,IAEvC,CAEDD,GAAapR,EAAMzF,MAAM,EAAE,GAE9B,CAED,OAAOgS,CACT,CDcoBkF,CACIR,EAAiB5S,EAAUlF,EAAO,GAAGM,MACrCyX,GAEdQ,EACFhV,EAAa8B,gBAAgBsS,EAAQ9T,KAAI4T,GAAKA,EAAErW,QAAQwE,GAE5D9D,EAAIV,MAAQmX,EAMZ,OALgB5Y,EAAQkB,UAAUC,IAAIgB,EAAIf,QAClCkS,YAAc1P,EAAa0L,uBAAuBmE,GAE1DyE,EAASzG,SAAQqG,GAAK9X,EAAQwH,YAAYsQ,EAAE1W,UAErCe,CACR,CAED,MAAM4L,EAAW/K,EAAKC,cAAc+U,EAAQ,GAAGvW,MAAMS,MAAM,EAAG+D,IAC9D,IAAI4S,EAAe,EACnB,MAAMC,EAAYd,EAAQ9T,KAAIgD,IAC5B,MAAM6R,EAAW/V,EAAKC,cAAciE,EAAMzF,MAAMS,MAAM+D,IAEtD,OADA4S,GAAgBE,EACTA,CAAQ,IAEXxU,EAASyT,EAAQ9T,KAAIgD,GAASlH,EAAQwE,mBAAmB0C,KACzDuM,EAAUzT,EAAQwE,mBAAmBrC,GAC3C,IAAK,IAAI3B,EAAI,EAAGA,EAAIuN,EAAUvN,IAAK,CACjC,IAAIoT,EAAYpT,EAAIqY,EACpB,IAAK,IAAI5T,EAAI,EAAGA,EAAIV,EAAO7C,OAAQuD,IAAK,CACtC,MAAM8T,EAAWD,EAAU7T,GACrB+T,EAAWxY,EAAIuY,EACf5K,EAAO5J,EAAOU,GAAG4J,SAASmK,EAAUA,EAAWD,GACrDtF,EAAQhP,IAAI0J,EAAMyF,GAClBA,GAAamF,CACd,CACF,CACD,OAAO5W,CACT,CAEO,MAAM8W,GAA6B,CACxCrZ,WAAYsZ,EACZpZ,YAAa,OACbK,WAAYsN,IEzFd,IAAI0L,GA4EG,MAAMC,GAA6B,CACxCxZ,WAAYyZ,EACZvZ,YAAa,OACbC,UAvEF,SAAeC,GACbmZ,GAAanZ,EAAQC,KAAKC,MAAMmZ,EAAQ,KAAiB,CACvD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAkDElZ,WAhDF,SACIC,GACF,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAE3B0C,EAACA,EAACmV,OAAEA,GAAU5X,EACd0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCiY,EAAWtZ,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,IAEhD8H,QAACA,EAAOoQ,UAAEA,EAASnQ,IAAEA,EAAGC,gBAAEA,EAAekB,WAAEA,GAAcjK,EACzDkZ,EAAc5V,EAAa6V,wBAAwBlP,GACnDjB,EAAW1F,EAAa8V,kBACzB5W,EAAerB,MAAQwW,EAAoBxW,MAAO0H,EAASoQ,EAC5DnQ,EAAKC,GAAiB,EAAOmQ,GAE3BhQ,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAASJ,EAASK,QAAQC,IAC1BC,EAAWP,EAASK,QAAQG,MAC5BC,EAAYT,EAASK,QAAQK,OAC7BC,EAAUX,EAASK,QAAQO,KAC3BO,EAAiBnB,EAASmB,eAC1BD,EAAgBlB,EAASkB,cACzBL,EAAeb,EAASa,aACxBC,EAAcd,EAASc,YACvBuP,EAAgBrQ,EAASgB,WACzBsP,EAAiBtQ,EAASuQ,YAC1BC,EAAsC,SAA1BxQ,EAASK,QAAQoQ,KAAkB,EAAI,EAEzD,GAA4B,iBAAxBzQ,EAASiB,WACX,MAAM,IAAI3J,MAEN,oDAAG0I,EAASiB,2CAGlB,MAAMpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAU,WAC5ClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OALA8X,GACIpW,EAAKD,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAI6X,EAAU9P,EACnDC,EAAaC,EAAQG,EAAUE,EAAWE,EAAS6P,EACnDrP,EAAgBD,EAAeL,EAAcC,EAAauP,EAC1DC,EAAgBvX,GACbF,CACT,GC1EA,IAAI6X,GAqGG,MAAMC,GAA0C,CACrDra,WAAYsa,EACZpa,YAAa,OACbC,UA9FF,SAAeC,GACbga,GAA0Bha,EAAQC,KAAKC,MAAMga,EAAqB,KAAM,CACtE,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAiEE/Z,WA/DF,SAA6BC,GAK3B,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B0L,GAACA,EAAEmM,OAAEA,GAAU5X,GACf8I,QAACA,EAAOC,IAAEA,EAAGmB,WAAEA,EAAUlB,gBAAEA,EAAe8Q,WAAEA,GAAc7Z,EAI1DkZ,EAAc5V,EAAa6V,wBAAwBlP,GACnDjB,EAAW1F,EAAa8V,kBAC1BS,EAAYlC,EAAOxW,MAA2C0H,EAJhD,EAKHC,EAAKC,GAAiB,EAAuBmQ,IACtD1O,UACJA,EAAStB,aACTA,EAAYC,YACZA,EAAWa,WACXA,EAAUU,SACVA,EAAQC,QACRA,EAAO4O,YACPA,EAAW1O,UACXA,EAASC,SACTA,EAAQjB,aACRA,EAAYC,YACZA,GACEd,EAEE8Q,EAAS5Q,EAAe,EAAIF,EAASK,QAAQC,IAC7CiG,EAAUpG,EAAc,EAAIH,EAASK,QAAQO,KAE7CmQ,EAAyC,iBAAxB/Q,EAASiB,WAC1B+P,EAAYtX,EAAK0L,eAAepF,EAAS9D,SACzC+U,EAAYvX,EAAK0L,eAAe5C,EAAGrK,QAClC+Y,EAAOC,EAAOC,GAAS1X,EAAK0L,eAAeuJ,EAAOxW,OACnDkZ,EAAeL,EAAU,GACzBM,EAAaP,EAAiBC,EAAU,GAAKA,EAAU,GACvDO,EAAaR,EAAiBC,EAAU,GAAK,EAC7CQ,EAAiBT,EAAiB,EAAIC,EAAU,GAChDS,EAAeR,EAAU,GACzBS,EAAaX,EAAiBE,EAAU,GAAKA,EAAU,GACvDU,EAAaZ,EAAiBE,EAAU,GAAK,EAC7CW,EAAiBb,EAAiB,EAAIE,EAAU,GAEhDpY,EAAMnC,EAAQoC,WAAWkH,EAAS9D,QAAS,WAC3CnD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAC1C8Z,EAAOnb,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACxCiY,EAAWtZ,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GAQtD,OANA2Y,GACImB,EAAM7B,EAAUxO,EAAWtB,EAAcC,EAAauB,EAAUC,EAChEX,EAAYa,EAAWC,EAAUyO,EAAa1P,EAAcC,EAC5DgQ,EAAQvK,EAAS2K,EAAOC,EAAOC,EAAOC,EAAcC,EACpDC,EAAYC,EAAgBC,EAAcC,EAAYC,EACtDC,EAAgB7Y,GACbF,CACT,GCnGA,IAAIiZ,GAyFG,MAAMC,GAA6B,CACxCzb,WAAY0b,EACZxb,YAAa,OACbC,UAnFF,SAAeC,GACbob,GAAapb,EAAQC,KAAKC,MAAMob,EAAQ,KAAM,CAC5C,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAyDEnb,WAvDI,SAAiBC,GAKrB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,EAACmV,OAAEA,GAAU5X,GACd8I,QAACA,EAAOC,IAAEA,EAAGmQ,UAAEA,GAAajZ,EAClC,GAAgB,YAAZwC,EAAEnC,MACJ,MAAM,IAAIC,MAAM,yCAAyCkC,EAAEnC,SAE7D,GAAqB,YAAjBsX,EAAOtX,MACT,MAAM,IAAIC,MACN,8CAA8CqX,EAAOtX,SAG3D,MAAM2I,EAAW1F,EAAa2X,kBAC1BzY,EAAErB,MACFwW,EAAOxW,MAAmD0H,EAC1DoQ,EAAWnQ,GAETjH,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAUzC,EAAEnC,OA2BpD,OA1BAya,GACIpb,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAClCiI,EAASwB,UACTxB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAASgB,WACThB,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAASuQ,YACTvQ,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAAS0C,YACT1C,EAASE,aACTF,EAASG,YACTH,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd/H,CACT,GCvFA,IAAIqZ,GA0FG,MAAMC,GAA6C,CACxD7b,WAAY8b,EACZ5b,YAAa,OACbC,UApFF,SAAeC,GACbwb,GACIxb,EAAQC,KAAKC,MAAMwb,EAAwB,KAAM,CAC/C,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,EAyDEvb,WAvDI,SAAiCC,GAKrC,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,EAACgJ,GAAEA,GAAMzL,GACV8I,QAACA,EAAOC,IAAEA,EAAGuS,YAAEA,GAAerb,EAEpC,GAAgB,YAAZwC,EAAEnC,MACJ,MAAM,IAAIC,MAAM,0CAA0CkC,EAAEnC,SAE9D,GAAiB,YAAbmL,EAAGnL,MACL,MAAM,IAAIC,MAAM,8CAA8CkL,EAAGnL,SAGnE,MAAM2I,EAAW1F,EAAa2X,kBAC1BzY,EAAErB,MAAmDka,EAAaxS,EACpD,EAAGC,GAEfwS,EAAK5b,EAAQoC,WAAWkH,EAASqS,YAAa7P,EAAGnL,OA4BvD,OA1BA6a,GACIxb,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAIya,EAAGxa,QAAQC,GACjCiI,EAASwB,UACTxB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAASgB,WACThB,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAASuQ,YACTvQ,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAAS0C,YACT1C,EAASE,aACTF,EAASG,YACTH,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd0R,CACT,GCxFA,IAAIC,GAyFG,MAAMC,GAA4C,CACvDlc,WAAYmc,EACZjc,YAAa,OACbC,UAnFF,SAAeC,GACb6b,GAA4B7b,EAAQC,KAAKC,MAAM6b,EAAuB,KAAM,CAC1E,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAyDE5b,WAvDI,SAAgCC,GAKpC,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0L,GAACA,EAAEmM,OAAEA,GAAU5X,GACf+I,IAACA,EAAGD,QAAEA,EAAOgR,WAAEA,GAAc7Z,EACnC,GAAiB,YAAbwL,EAAGnL,MACL,MAAM,IAAIC,MAAM,0CAA0CkL,EAAGnL,SAE/D,GAAqB,YAAjBsX,EAAOtX,MACT,MAAM,IAAIC,MACN,8CAA8CqX,EAAOtX,SAG3D,MAAM2I,EAAW1F,EAAa2X,kBAC1BpB,EAAYlC,EAAOxW,MACnB0H,EAAuB,EAAGC,GAExB2C,EAAK/L,EAAQoC,WAAWkH,EAAS9D,QAASsG,EAAGnL,OA4BnD,OA1BAkb,GACI7b,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjCiI,EAASwB,UACTxB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAASgB,WACThB,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAASuQ,YACTvQ,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAAS0C,YACT1C,EAASE,aACTF,EAASG,YACTH,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd6B,CACT,GCvFaiQ,GAA0BrZ,GAAwBsZ,GCDlDC,GAA2BvZ,GAAwBwZ,GCIhE,IAAKC,GAKL,IAAIC,IALJ,SAAKD,GACHA,EAAAA,EAAA,SAAA,GAAA,WACAA,EAAAA,EAAA,QAAA,GAAA,SACD,CAHD,CAAKA,KAAAA,GAGJ,CAAA,IAkEM,MAAME,GAAoC,CAC/C1c,WAAY2c,EACZzc,YAAa,OACbC,UA9DF,SAAeC,GACbqc,GAAoBrc,EAAQC,KAAKC,MAAMqc,EAAe,KAAe,CACnE,SACA,SACA,SACA,SACA,QACA,SACA,SACA,SACA,SACA,UAEJ,EAkDEpc,WAhDF,SAAuBC,GAKrB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3Boc,OAACA,EAAMC,mBAAEA,EAAkBC,SAAEA,GAAYpc,GACzCqc,MAACA,EAAKC,MAAEA,EAAKC,OAAEA,GAAUxc,EAEzByc,EAAWF,EAAMnb,MAAM,IAEtBsb,EAAYC,GAAaN,EAC1BnX,EAAW,CAACuX,EAAUC,EAAYC,EAAWL,EAAMlb,MAAM,IAE/D,IACIwb,EADAC,EAAald,EAAQkB,UAAUC,IAAIwb,EAAMvb,QAEzB,YAAhBub,EAAMhc,QACRsc,EAAa9F,GAAK,CAACnX,UAASK,OAAQ,CAACyC,EAAG6Z,GAAQrc,MAAO,CAACK,MAAO,aAC/Duc,EAAald,EAAQkB,UAAUC,IAAI8b,EAAW7b,SAGhD,MAAM+b,EAAWD,EAAW7b,GACtB+b,EAAUpd,EAAQkB,UAAUC,IAAIyb,EAAMxb,QAAQC,GAC9Cgc,EAAWrd,EAAQkB,UAAUC,IAAI0b,EAAOzb,QAAQC,GAEhDc,EAAMnC,EAAQoC,WAAWmD,EAAU,WACnClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1Cic,EAAmB,IAAI/a,WAAW,IAAIC,WAAWma,EAAMlb,OAAOgB,QAapE,OAXA4Z,GACIc,EAAUC,EAASC,EAAUP,EAAUQ,EAAkBP,EACzDC,EACAZ,GAAoBI,GAEpBC,EAAoBpa,GAEN,MAAd4a,GACFjd,EAAQwH,YAAYyV,EAAW7b,QAG1Be,CACT,GClEA,IAAIob,GAoDG,MAAMC,GAA8B,CACzC5d,WAAY6d,EACZ3d,YAAa,OACbC,UApDF,SAAeC,GACbud,GAAcvd,EAAQC,KAAKC,MAAMud,EAAS,KAAiB,CACzD,SACA,SACA,SACA,SACA,SACA,UAEJ,EA4CEtd,WA1CI,SACJC,GAEA,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN4F,KAACA,EAAIyX,UAAEA,EAASC,QAAEA,GAAWrd,EAC7B6F,EAAQrD,EAAErB,MAAMC,OAEtBsB,EAAKwJ,OAAmB,YAAZ1J,EAAEnC,OAAmC,UAAZmC,EAAEnC,OACrC,IAAM,4BAA4BmC,EAAEnC,sCAEtC,MAAMid,EAAcha,EAAa4C,mBAAmB,CAACP,GAAOE,GAC5D,IAAI0X,EAAY/a,EACI,OAAhB8a,IACFC,EAAYhZ,GAAU,CAACxE,OAAQ,CAACyC,KAAIxC,MAAO,CAACyE,KAAM6Y,GAAc5d,aAElE,MAAM8d,EAAela,EAAa+C,iBAAiB,EAAGR,GAAO,GAC7DvC,EAAawD,2BAA2B,UAAW,CAAC0W,GAAe3X,GAEnE,MAAM4X,EAAc/d,EAAQoC,WAAWyb,EAAUpc,MAAOoc,EAAUld,OAC5Dqd,EAAWH,EAAUpc,MAAMqc,GAC3BG,EAAcje,EAAQkB,UAAUC,IAAI0c,EAAUzc,QAAQC,GACtD6c,EAAgBle,EAAQkB,UAAUC,IAAI4c,EAAY3c,QAAQC,GAChEkc,GAAYU,EAAaP,EAAY,EAAI,EAAGC,EAAU,EAAI,EAAGK,EACjDE,EAAe1e,GAASsD,EAAEnC,QAGtC,IAAIwB,EAAM4b,EACV,GAAoB,OAAhBH,EAAsB,CAExBzb,EAAM0C,GACJ,CAACxE,OAAQ,CAACyC,EAAGib,GAAczd,MAAO,CAACyE,KAFbnB,EAAaua,uBAAuBP,IAEC5d,YAC7DA,EAAQwH,YAAYqW,EAAUzc,QAC9BpB,EAAQwH,YAAYuW,EAAY3c,OACjC,CACD,OAAOe,CACT,GClDA,IAAIic,GAoDG,MAAMC,GAA6B,CACxCze,WAAY0e,EACZxe,YAAa,OACbC,UApDF,SAAeC,GACboe,GAAape,EAAQC,KAAKC,MAAMoe,EAAQ,KAAiB,CACvD,SACA,SACA,SACA,SACA,SACA,UAEJ,EA4CEne,WA1CI,SACJC,GAEA,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN4F,KAACA,EAAIyX,UAAEA,EAASC,QAAEA,GAAWrd,EAC7B6F,EAAQrD,EAAErB,MAAMC,OAEtBsB,EAAKwJ,OAAmB,YAAZ1J,EAAEnC,OAAmC,UAAZmC,EAAEnC,OACrC,IAAM,2BAA2BmC,EAAEnC,sCAErC,MAAMid,EAAcha,EAAa4C,mBAAmB,CAACP,GAAOE,GAC5D,IAAI0X,EAAY/a,EACI,OAAhB8a,IACFC,EAAYhZ,GAAU,CAACxE,OAAQ,CAACyC,KAAIxC,MAAO,CAACyE,KAAM6Y,GAAc5d,aAElE,MAAM8d,EAAela,EAAa+C,iBAAiB,EAAGR,GAAO,GAC7DvC,EAAawD,2BAA2B,SAAU,CAAC0W,GAAe3X,GAElE,MAAM4X,EAAc/d,EAAQoC,WAAWyb,EAAUpc,MAAOoc,EAAUld,OAC5Dqd,EAAWH,EAAUpc,MAAMqc,GAC3BG,EAAcje,EAAQkB,UAAUC,IAAI0c,EAAUzc,QAAQC,GACtD6c,EAAgBle,EAAQkB,UAAUC,IAAI4c,EAAY3c,QAAQC,GAChE+c,GAAWH,EAAaP,EAAY,EAAI,EAAGC,EAAU,EAAI,EAAGK,EACjDE,EAAe1e,GAASsD,EAAEnC,QAGrC,IAAIwB,EAAM4b,EACV,GAAoB,OAAhBH,EAAsB,CAExBzb,EAAM0C,GACJ,CAACxE,OAAQ,CAACyC,EAAGib,GAAczd,MAAO,CAACyE,KAFbnB,EAAaua,uBAAuBP,IAEC5d,YAC7DA,EAAQwH,YAAYqW,EAAUzc,QAC9BpB,EAAQwH,YAAYuW,EAAY3c,OACjC,CACD,OAAOe,CACT,GCrDA,IAAIoc,GA2CG,MAAMC,GAAoC,CAC/C5e,WAAY6e,EACZ3e,YAAa,OACbC,UAzCF,SAAeC,GACbue,GAAoBve,EAAQC,KAAKC,MAAM,gBAAiB,KAAe,CACrE,SACA,QACA,SACA,SACA,UACA,SACA,SACA,UACA,UAEJ,EA8BEC,WA5BF,SAAuBC,GAKrB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B0C,EAACA,EAACqT,QAAEA,GAAW9V,GACfgO,KAACA,EAAIqQ,aAAEA,GAAgBpe,EAEvB8V,EAA0D,IAA7CD,EAAQ1U,MAAM0T,QAAO,CAACkB,EAAGC,IAAMD,EAAIC,GAAG,GACnD/Q,EAA8B,IAAnBzC,EAAErB,MAAMC,OAAe,CAAC2M,GAAQ,CAACvL,EAAErB,MAAM,GAAI4M,GACxDlM,EAAMnC,EAAQoC,WAAWmD,EAAU4Q,EAAQxV,OAEjD,SAAS4V,EAASzT,GAChB,OAAO9C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,EACxC,CAMD,OALAkd,GACIhI,EAASzT,GAAI,IAAIP,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QACpDK,EAAErB,MAAMC,OAAQ2M,EAAM+H,EAAYG,EAASJ,GAC3C3W,GAAS2W,EAAQxV,OAAQ+d,EAAcnI,EAASpU,IAE7CA,CACT,GC1CA,IAAIwc,GA6DG,MAAMC,GAAmC,CAC9Chf,WAAYif,EACZ/e,YAAa,OACbC,UA3DF,SAAeC,GACb2e,GAAmB3e,EAAQC,KAAKC,MAAM2e,EAAc,KAAe,CACjE,SACA,SACA,SACA,QACA,SACA,QACA,QACA,SACA,UAEJ,EAgDE1e,WA9CI,SAAuBC,GAK3B,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACNye,UAACA,EAASvU,WAAEA,GAAcjK,EAE1BwK,EAAYhI,EAAErB,MAAM,GAKpBsd,GAJ8B,SAAfxU,EAAyBzH,EAAErB,MAAM,GAAKqB,EAAErB,MAAM,IAIhCqd,EAC7BE,GAJ6B,SAAfzU,EAAyBzH,EAAErB,MAAM,GAAKqB,EAAErB,MAAM,IAIjCqd,EAC3BG,GAJ6B,SAAf1U,EAAyBzH,EAAErB,MAAM,GAAKqB,EAAErB,MAAM,KAIhCqd,EAAYA,GAExCI,EAA8B,SAAf3U,EACjB,CAACO,EAAWiU,EAAcC,EAAaC,GACvC,CAACnU,EAAWmU,EAAaF,EAAcC,GAErC7c,EAAMnC,EAAQoC,WAAW8c,EAAa,WAGtCnc,EADQ/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QACpBC,GACZ8d,EACF,IAAI5c,WAAW,IAAIC,WAAWQ,EAAK0L,eAAe5L,EAAErB,QAAQgB,QAE1D2c,EAAmB,IAAI7c,WAAW,IAAIC,WAAW0c,GAAazc,QAC9D4c,EACF,IAAI9c,WAAW,IAAIC,WAAWQ,EAAK0L,eAAewQ,IAAczc,QAE9DJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OAJAsd,GACI5b,EAAK+b,EAF2B,SAAfvU,EAAwB,EAAI,EAEf4U,EAAerc,EAAErB,MAAMC,OAAS,EAC9D0d,EAAkBC,EAAiBH,EAAYxd,OAAQW,GAEpDF,CACT,GC3DA,IAAImd,GAmFG,MAAMC,GAA4C,CACvD3f,WAAY4f,EACZ1f,YAAa,OACbC,UA9EF,SAAeC,GACbsf,GACItf,EAAQC,KAAKC,MAAMsf,EAAuB,KAAiB,CACzD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,EAwDErf,WAtDF,SAAyBC,GAKvB,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAE3B0C,EAACA,EAACmV,OAAEA,GAAU5X,EACd0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCiY,EAAWtZ,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,IAEhD8H,QAACA,EAAOoQ,UAAEA,EAASnQ,IAAEA,EAAGC,gBAAEA,GAAmB/I,EAE7Cmf,EAA0B,MAAblG,EAAoB,CAAC,EAAG,GAAKA,EAE1CjQ,EAAW1F,EAAa8V,kBACzB5W,EAAerB,MAAQwW,EAAoBxW,MAAO0H,EAClDsW,EAA0CrW,EAAKC,GAChD,GAEEG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAASJ,EAASK,QAAQC,IAC1BC,EAAWP,EAASK,QAAQG,MAC5BC,EAAYT,EAASK,QAAQK,OAC7BC,EAAUX,EAASK,QAAQO,KAC3BO,EAAiBnB,EAASmB,eAC1BD,EAAgBlB,EAASkB,cACzBL,EAAeb,EAASa,aACxBC,EAAcd,EAASc,YACvBuP,EAAgBrQ,EAASgB,WACzBsP,EAAiBtQ,EAASuQ,YAC1BC,EAAsC,SAA1BxQ,EAASK,QAAQoQ,KAAkB,EAAI,EAEzD,GAA4B,iBAAxBzQ,EAASiB,WACX,MAAM,IAAI3J,MAEN,mEAAG0I,EAASiB,2CAGlB,MAAMpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAU,WAC5ClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OALAie,GACIvc,EAAKD,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAI6X,EAAU9P,EACnDC,EAAaC,EAAQG,EAAUE,EAAWE,EAAS6P,EACnDrP,EAAgBD,EAAeL,EAAcC,EAAauP,EAC1DC,EAAgBvX,GACbF,CACT,GC/EA,IAAIud,GA0BG,MAAMC,GAA2B,CACtC/f,WAAYggB,EACZ9f,YAAa,OACbC,UA1BF,SAAeC,GACb0f,GAAW1f,EAAQC,KAAKC,MAAM,OAAQ,KAAM,CAC1C,SACA,SACA,SACA,UAEJ,EAoBEC,WAlBI,SAAeC,GAEnB,MAAMC,OAACA,EAAML,QAAEA,GAAWI,GACpB0C,EAACA,GAAKzC,EAENgM,EAAQrJ,EAAKC,cAAcH,EAAErB,OAC7BU,EAAMnC,EAAQoC,WAAW,IAAIU,EAAErB,SAAUqB,EAAErB,OAAQqB,EAAEnC,OAK3D,OAHA+e,GACI1f,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAAI7B,GAASsD,EAAEnC,OAAQ0L,EACvDrM,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,IAC/Bc,CACT,GCzBA,IAAI0d,GA2EG,MAAMC,GAAiC,CAC5ClgB,WAAYmgB,EACZjgB,YAAa,OACbC,UAvEF,SAAeC,GACb6f,GAAiB7f,EAAQC,KAAKC,MAAM6f,EAAY,KAAM,CACpD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAmDE5f,WAjDI,SAAqBC,GAKzB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,EAACmV,OAAEA,GAAU5X,GACd8I,QAACA,EAAOC,IAAEA,EAAGmQ,UAAEA,GAAajZ,EAElC,GAAIwC,EAAEnC,QAAUsX,EAAOtX,MACrB,MAAM,IAAIC,MACN,+DACIkC,EAAEnC,aAAasX,EAAOtX,SAGhC,MAAMqf,EAAepc,EAAaqc,sBAC9Bnd,EAAErB,MACFwW,EAAOxW,MAAmC0H,EAASC,EACpC,OAAQmQ,GAErBpX,EAAMnC,EAAQoC,WAAW4d,EAAaza,SAAUzC,EAAEnC,OAsBxD,OApBAkf,GACI7f,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAClC7B,GAASsD,EAAEnC,OACXqf,EAAalV,UACHkV,EAAa1V,WACvB0V,EAAahV,SACbgV,EAAa/U,QACb+U,EAAa7U,UACb6U,EAAa5U,SACb4U,EAAa7V,aACb6V,EAAa5V,YACb4V,EAAavV,eACbuV,EAAaxV,cACbwV,EAAaxW,aACbwW,EAAavW,YACbuW,EAAarW,QAAQC,IACrBoW,EAAarW,QAAQO,MAElB/H,CACT,GCxEA,IAAI+d,GA+EG,MAAMC,GAA+C,CAC1DvgB,WAAYwgB,GACZtgB,YAAa,OACbC,UA1EF,SAAeC,GACbkgB,GACIlgB,EAAQC,KAAKC,MAAMkgB,GAA0B,KAAM,CACjD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,EAoDEjgB,WAlDI,SAAmCC,GAKvC,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,EAACmV,OAAEA,EAAMnM,GAAEA,GAAMzL,GAClB8I,QAACA,EAAOC,IAAEA,EAAGmQ,UAAEA,GAAajZ,EAElC,GAAIwC,EAAEnC,QAAUsX,EAAOtX,OAASmC,EAAEnC,QAAUmL,EAAGnL,MAC7C,MAAM,IAAIC,MACN,oFACIkC,EAAEnC,UAAUsX,EAAOtX,cAAcmL,EAAGnL,SAG9C,MAAMqf,EAAepc,EAAaqc,sBAC9Bnd,EAAErB,MACFwW,EAAOxW,MAAmC0H,EAASC,EACpC,OAAQmQ,GAErB8G,EAAYrgB,EAAQoC,WAAW6V,EAAOxW,MAAOwW,EAAOtX,OAuB1D,OArBAuf,GACIlgB,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAIkf,EAAUjf,QAAQC,GACxC7B,GAASsD,EAAEnC,OACXqf,EAAalV,UACHkV,EAAa1V,WACvB0V,EAAahV,SACbgV,EAAa/U,QACb+U,EAAa7U,UACb6U,EAAa5U,SACb4U,EAAa7V,aACb6V,EAAa5V,YACb4V,EAAavV,eACbuV,EAAaxV,cACbwV,EAAaxW,aACbwW,EAAavW,YACbuW,EAAarW,QAAQC,IACrBoW,EAAarW,QAAQO,MAElBmW,CACT,GC7EA,IAAIC,GA+EG,MAAMC,GAA8C,CACzD3gB,WAAY4gB,GACZ1gB,YAAa,OACbC,UA1EF,SAAeC,GACbsgB,GACItgB,EAAQC,KAAKC,MAAMsgB,GAAyB,KAAM,CAChD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,EAoDErgB,WAlDI,SAAkCC,GAKtC,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,EAACmV,OAAEA,EAAMnM,GAAEA,GAAMzL,GAClB8I,QAACA,EAAOC,IAAEA,EAAGmQ,UAAEA,GAAajZ,EAElC,GAAIwC,EAAEnC,QAAUsX,EAAOtX,OAASmC,EAAEnC,QAAUmL,EAAGnL,MAC7C,MAAM,IAAIC,MACN,mFACIkC,EAAEnC,UAAUsX,EAAOtX,cAAcmL,EAAGnL,SAG9C,MAAMqf,EAAepc,EAAaqc,sBAC9Bnd,EAAErB,MACFwW,EAAOxW,MAAmC0H,EAASC,EACpC,OAAQmQ,GAErB8G,EAAYrgB,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OAuBhD,OArBA2f,GACItgB,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAIkf,EAAUjf,QAAQC,GACxC7B,GAASsD,EAAEnC,OACXqf,EAAalV,UACHkV,EAAa1V,WACvB0V,EAAahV,SACbgV,EAAa/U,QACb+U,EAAa7U,UACb6U,EAAa5U,SACb4U,EAAa7V,aACb6V,EAAa5V,YACb4V,EAAavV,eACbuV,EAAaxV,cACbwV,EAAaxW,aACbwW,EAAavW,YACbuW,EAAarW,QAAQC,IACrBoW,EAAarW,QAAQO,MAElBmW,CACT,GChFaI,GAA0B9d,GAAwB+d,ICC/D,IAAIC,GAuBG,MAAMC,GAA8B,CACzChhB,WAAYihB,GACZ/gB,YAAa,OACbC,UAxBF,SAAeC,GACb2gB,GAAc3gB,EAAQC,KAAKC,MAAM2gB,GAAS,KAAM,CAC9C,SACA,SACA,UAEJ,EAmBE1gB,WAjBI,SAAkBC,GAEtB,MAAMC,OAACA,EAAML,QAAEA,GAAWI,GACpB0L,GAACA,EAAEgV,EAAEA,GAAKzgB,EAEV8B,EAAMnC,EAAQoC,WAAW0e,EAAErf,MAAO,WAClC8U,EAAYzT,GACT9C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAGzC,OADAsf,GAAYpK,EAASuK,GAAIvK,EAASzK,GAAKyK,EAASpU,IACzCA,CACT,GCrBa4e,GACTvd,GAAyBwd,GAFC,EAE6B,QCD9CC,GAA0Bte,GAAwBue,ICDlDC,GAA0Bxe,GAAwBye,GAAK,WCE9D,SAAUC,GAAWjhB,GAKzB,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAC3B8G,MAACA,GAAS7G,GACVihB,IAACA,GAAOhhB,EAER6G,EAAYD,EAAMzF,MAAMC,OACxBiC,EAAWuD,EAAMzF,MAAMS,QAC7B,IAAIqf,EAAOD,EAWX,OAVIA,EAAM,IAERte,EAAKwJ,SACCrF,EAAY,IAAMma,GACpB,IAAM,mCAAoCna,EAAY,OAClDA,OACRoa,EAAOpa,EAAYma,EAAM,GAE3B3d,EAAS6d,OAAOD,EAAM,EAAG,GAElBnV,GAAQ,CAAC/L,OAAQ,CAACyC,EAAGoE,GAAQlH,UAASM,MAAO,CAACmB,MAAOkC,IAC9D,CAEO,MAAM8d,GAAiC,CAC5C7hB,WAAY8hB,GACZ5hB,YAAa,OACbK,WAAYkhB,IC9BDM,GACThf,GAAwBif,GAAO,WCC7B,SAAUC,GAAKzhB,GACnB,MAAOE,OAAOmB,MAACA,EAAKiQ,MAAEA,GAAM1R,QAAEA,GAAWI,EACzC,IAAKE,OAAOK,MAACA,IAAUP,EAEvBO,EAAQA,GAASqC,EAAK8e,WAAWpQ,GAEjC,MAAMvP,EAAMnC,EAAQoC,WAAWX,EAAOd,GAGtC,OAFgBX,EAAQwE,mBAAmBrC,GACnC0f,KAAKnQ,GACNvP,CACT,CAEO,MAAM4f,GAA2B,CACtCniB,WAAYoiB,GACZliB,YAAa,OACbK,WAAY0hB,IChBd,IAAII,GA+BG,MAAMC,GAAoC,CAC/CtiB,WAAYuiB,GACZriB,YAAa,OACbK,WAnBI,SACFC,GACF,MAAMC,OAACA,EAAML,QAAEA,GAAWI,GACpBuc,MAACA,GAAStc,EAEV8B,EAAMnC,EAAQoC,WAAWua,EAAMlb,MAAOkb,EAAMhc,OAC5CyhB,EAAUpiB,EAAQkB,UAAUC,IAAIwb,EAAMvb,QAAQC,GAC9CgB,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,IAEzCghB,EAAOC,EAAaC,EAAYC,GAAe7F,EAAMlb,MAI5D,OAFAwgB,GACIG,EAASC,EAAOC,EAAaC,EAAYC,EAAangB,GACnDF,CACT,EAMEpC,UA/BF,SAAeC,GACbiiB,GAAoBjiB,EAAQC,KAAKC,MAAMiiB,GAAe,KAAiB,CACrE,SACA,SACA,SACA,SACA,SACA,UAEJ,GCfaM,GAA4B9f,GAAwB+f,ICGpDC,GACTnf,GAAyBof,ICF7B,IAAIC,GAqCG,MAAMC,GAAqC,CAChDljB,WAAYmjB,GACZjjB,YAAa,OACbC,UApCF,SAAeC,GACb6iB,GAAgB7iB,EAAQC,KAAKC,MACzB6iB,GAAgB,KAChB,CAAC,SAAU,SAAU,SAAU,SAAU,SAAU,SAAU,UACnE,EAiCE5iB,WA/BF,SAAwBC,GAKtB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B4iB,gBAACA,GAAmB1iB,GACpBwC,EAACA,EAACmgB,KAAEA,EAAIC,SAAEA,EAAQ7K,OAAEA,EAAM8K,MAAEA,GAAS9iB,EACrC0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtC+hB,EAASpjB,EAAQkB,UAAUC,IAAI8hB,EAAK7hB,QAAQC,GAC5CgiB,EAAarjB,EAAQkB,UAAUC,IAAI+hB,EAAS9hB,QAAQC,GACpDiiB,EAAqB,MAAVjL,EAAiBrY,EAAQkB,UAAUC,IAAIkX,EAAOjX,QAAQC,GAAK,EACtEkiB,EAAmB,MAATJ,EAAgBnjB,EAAQkB,UAAUC,IAAIgiB,EAAM/hB,QAAQC,GAAK,EAEnEc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OAE1C,GAAoC,IAAhCqC,EAAKC,cAAcH,EAAErB,OACvB,OAAOU,EAGT,MAAME,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAIhD,OAFAwhB,GACI9f,EAAKqgB,EAAQC,EAAYC,EAAUC,EAASP,EAAiB3gB,GAC1DF,CACT,GCjCA,IAAIqhB,GA8HG,MAAMC,GAAkC,CAC7C7jB,WAAY8jB,GACZ5jB,YAAa,OACbC,UAvHF,SAAeC,GACbwjB,GAAkBxjB,EAAQC,KAAKC,MAAMwjB,GAAa,KAAiB,CACjE,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EA8FEvjB,WA5FF,SAAqBC,GAKnB,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAC3B0C,EAACA,EAACmV,OAAEA,EAAMxX,KAAEA,EAAIC,uBAAEA,GAA0BL,GAC5C8I,QACJA,EAAOC,IACPA,EAAGmQ,UACHA,EAAShP,WACTA,EAAUlB,gBACVA,EAAetI,WACfA,EAAUC,eACVA,GACEV,EAEEgJ,EAAW1F,EAAa8V,kBACzB5W,EAAerB,MAAQwW,EAAoBxW,MAAO0H,EAASoQ,EAC5DnQ,EAAKC,GAEHzH,EACFnC,GAAkBsB,GAEtB,GAAuB,MAAnBa,EACF,MAAM,IAAIhB,MACN,GAAGG,uEAIT,MAAMgC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCiY,EAAWtZ,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GAEhDuY,EAAiBtQ,EAASuQ,YAEhC,IAAItY,EAAS,EACb,GAAY,MAARd,EAAc,CAChB,MAAMe,EAAWxB,EAAQkB,UAAUC,IAAIV,EAAKW,QAC5C,GAA8B,IAA1BI,EAASC,MAAMC,OACjB,MAAM,IAAId,MAEN,sDAAQY,EAASC,MAAMC,WAE7B,GAAIF,EAASC,MAAM,KAAOmY,EACxB,MAAM,IAAIhZ,MACN,2BAA2BY,EAASC,wDACImY,MAE9CrY,EAASC,EAASH,EACnB,CAED,MAAMmI,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAASJ,EAASK,QAAQC,IAC1BC,EAAWP,EAASK,QAAQG,MAC5BC,EAAYT,EAASK,QAAQK,OAC7BC,EAAUX,EAASK,QAAQO,KAC3BO,EAAiBnB,EAASmB,eAC1BD,EAAgBlB,EAASkB,cACzBL,EAAeb,EAASa,aACxBC,EAAcd,EAASc,YACvBuP,EAAgBrQ,EAASgB,WACzBwP,EAAsC,SAA1BxQ,EAASK,QAAQoQ,KAAkB,EAAI,EACnDjP,EAAYxB,EAASwB,UACrBE,EAAW1B,EAAS0B,SACpBC,EAAU3B,EAAS2B,QAEzB,GAAmB,SAAfV,EACF,MAAM,IAAI3J,MAEN,yDAAG2J,0BAGT,MAAMpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAU,WAC5ClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAC1CM,EAAqD,MAA1BjB,EAC7B,EACAV,EAAQkB,UAAUC,IAAIT,EAAuBU,QAAQC,GAQzD,OANAmiB,GACIzgB,EAAK+H,EAAWE,EAAUC,EAASqO,EAAU9P,EAAcC,EAC3DlI,EAAQmI,EAAQG,EAAUE,EAAWE,EAAS6P,EAAWrP,EACzDD,EAAeL,EAAcC,EAAauP,EAAeC,EACzDhY,EAAiBD,EAA0BX,GAAkB,EAAGqB,GAE7DF,CACT,GC5HA,IAAIwhB,GA+HG,MAAMC,GAA2C,CACtDhkB,WAAYikB,GACZ/jB,YAAa,OACbC,UAxHF,SAAeC,GACb2jB,GACI3jB,EAAQC,KAAKC,MAAM2jB,GAAsB,KAAiB,CACxD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,EA8FE1jB,WA5FF,SAA8BC,GAK5B,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAC3B0C,EAACA,EAACmV,OAAEA,EAAMxX,KAAEA,EAAIC,uBAAEA,GAA0BL,GAC5C8I,QACJA,EAAOC,IACPA,EAAGmQ,UACHA,EAAShP,WACTA,EAAUlB,gBACVA,EAAetI,WACfA,EAAUC,eACVA,GACEV,EAEEgJ,EAAW1F,EAAa8V,kBACzB5W,EAAerB,MAAQwW,EAAoBxW,MAAO0H,EAASoQ,EAC5DnQ,EAAKC,GAAiB,GAEpBzH,EACFnC,GAAkBsB,GAEtB,GAAuB,MAAnBa,EACF,MAAM,IAAIhB,MACN,GAAGG,gFAIT,MAAMgC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCiY,EAAWtZ,EAAQkB,UAAUC,IAAI8W,EAAO7W,QAAQC,GAEhDuY,EAAiBtQ,EAASuQ,YAEhC,IAAItY,EAAS,EACb,GAAY,MAARd,EAAc,CAChB,MAAMe,EAAWxB,EAAQkB,UAAUC,IAAIV,EAAKW,QAC5C,GAA8B,IAA1BI,EAASC,MAAMC,OACjB,MAAM,IAAId,MAEN,+DAAQY,EAASC,MAAMC,WAE7B,GAAIF,EAASC,MAAM,KAAOmY,EACxB,MAAM,IAAIhZ,MACN,oCAAoCY,EAASC,wDACLmY,MAE9CrY,EAASC,EAASH,EACnB,CAED,MAAMmI,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAASJ,EAASK,QAAQC,IAC1BC,EAAWP,EAASK,QAAQG,MAC5BC,EAAYT,EAASK,QAAQK,OAC7BC,EAAUX,EAASK,QAAQO,KAC3BO,EAAiBnB,EAASmB,eAC1BD,EAAgBlB,EAASkB,cACzBL,EAAeb,EAASa,aACxBC,EAAcd,EAASc,YACvBuP,EAAgBrQ,EAASgB,WACzBwP,EAAsC,SAA1BxQ,EAASK,QAAQoQ,KAAkB,EAAI,EACnDjP,EAAYxB,EAASwB,UACrBE,EAAW1B,EAAS0B,SACpBC,EAAU3B,EAAS2B,QAEzB,GAAmB,SAAfV,EACF,MAAM,IAAI3J,MAEN,kEAAG2J,0BAGT,MAAMpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAU,WAC5ClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAC1CM,EAAqD,MAA1BjB,EAC7B,EACAV,EAAQkB,UAAUC,IAAIT,EAAuBU,QAAQC,GAQzD,OANAsiB,GACI5gB,EAAK+H,EAAWE,EAAUC,EAASqO,EAAU9P,EAAcC,EAC3DlI,EAAQmI,EAAQG,EAAUE,EAAWE,EAAS6P,EAAWrP,EACzDD,EAAeL,EAAcC,EAAauP,EAAeC,EACzDhY,EAAiBD,EAA0BX,GAAkB,EAAGqB,GAE7DF,CACT,GC7HA,IAAI2hB,GAiDG,MAAMC,GAA+B,CAC1CnkB,WAAYokB,GACZlkB,YAAa,OACbC,UA/CF,SAAeC,GACb8jB,GAAe9jB,EAAQC,KAAKC,MAAM8jB,GAAU,KAAe,CACzD,SACA,SACA,SACA,SACA,SACA,SACA,QACA,UAEJ,EAqCE7jB,WAnCF,SAAkBC,GAEhB,MAAMJ,QAACA,EAAOK,OAAEA,GAAUD,GACpB6jB,OAACA,EAAMC,QAAEA,GAAW7jB,GAEnB8jB,EAAaC,EAAWxO,EAAWzM,GACtCkb,GAAYC,mBAAmBL,EAAQC,GAErC/hB,EAAMnC,EAAQoC,WAAW+hB,EAAaF,EAAOtjB,OACnD,GAAkB,IAAdyjB,EACF,OAAOjiB,EAGT,MAAMoiB,EAAeL,EAAQziB,MACvB+iB,EAAYD,EAAaA,EAAa7iB,OAAS,GAG/CqB,EADQ/C,EAAQkB,UAAUC,IAAI8iB,EAAO7iB,QACzBC,GAEZojB,EADczkB,EAAQkB,UAAUC,IAAI+iB,EAAQ9iB,QACpBC,GAExBqjB,EAAe,IAAIniB,WAAW,IAAIC,WAAW2G,GAAS1G,QAEtDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAKhD,OAJAyiB,GACI/gB,EAAKvD,GAASykB,EAAOtjB,OAAQ8jB,EAAWL,EAAWI,EAAW5O,EAC9D8O,EAAcriB,GAEXF,CACT,GC9CA,IAAIwiB,GA4FG,MAAMC,GAA+B,CAC1ChlB,WAAYilB,GACZ/kB,YAAa,OACbC,UA1FF,SAAeC,GACb2kB,GAAa3kB,EAAQC,KAAKC,MAAM,SAAU,KAAe,CACvD,SACA,SACA,QACA,SACA,SACA,SACA,QACA,UAEJ,EAgFEC,WA9EF,SACIC,GAEF,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B0C,EAACA,EAACohB,QAAEA,GAAW7jB,GACf4F,KAACA,EAAIlE,UAAEA,GAAazB,EAGpBwkB,EAAa9hB,EAAKqD,eAAeJ,EAAMnD,EAAErB,OAAO,GAChDsjB,EAAc/kB,EAAQsE,SAAS4f,EAAQ9iB,QACvC4jB,EAAUliB,EAAErB,MAAMqjB,GACxB,IAAK,IAAI7f,EAAI,EAAGA,EAAI8f,EAAYrjB,SAAUuD,EAAG,CAC3C,MAAMggB,EAAQF,EAAY9f,GAC1BjC,EAAKwJ,OACDyY,GAASD,EAAU,GAAKC,GAAS,GACjC,IACI,6BAA6BA,mBAAuBD,EAAU,MACvE,CAED,MAAME,EAAYthB,EAAauhB,aAAaC,yBACxCtiB,EAAaohB,EAAmBY,EAAY/iB,GAE1CsjB,EAAWjZ,GAAQ,CACvB/L,OAAQ,CAACyC,KACTxC,MAAO,CACLmB,MAAO,CACLyjB,EAAUpa,UAAWoa,EAAUnd,UAAWmd,EAAUI,QACpDJ,EAAUtP,YAGd5V,YAEIulB,EAAcviB,EAAKC,cAAcihB,EAAQziB,OACzC+jB,EAAepZ,GAAQ,CAC3B/L,OAAQ,CAACyC,EAAGohB,GACZ5jB,MAAO,CAACmB,MAAO,CAACyjB,EAAUpa,UAAWya,EAAcL,EAAUpa,YAC7D9K,YAEIylB,EAAqB,CACzBP,EAAUpa,UAAWoa,EAAUnd,UAAWwd,EAAcL,EAAUpa,UAClEoa,EAAUtP,WAGNzT,EAAMnC,EAAQoC,WAAWqjB,EAAoB3iB,EAAEnC,OACrD,GAAoC,IAAhCqC,EAAKC,cAAcH,EAAErB,OACvB,OAAOU,EAET,MAAMujB,EAAcL,EAAS5jB,MAAMC,OAAS,EAGtCqB,EADQ/C,EAAQkB,UAAUC,IAAIkkB,EAASjkB,QAC3BC,GAGZojB,EADczkB,EAAQkB,UAAUC,IAAIqkB,EAAapkB,QACzBC,GAExBgB,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1C8d,EAAgB,IAAI5c,WACtB,IAAIC,WAAWQ,EAAK0L,eAAe2W,EAAS5jB,QAAQgB,QAClD4c,EAAkB,IAAI9c,WACxB,IAAIC,WAAWQ,EAAK0L,eAAe+W,IAAqBhjB,QAW5D,OATAkiB,GACI5hB,EAAKvD,GAASsD,EAAEnC,OAAQwe,EAAeuG,EAAajB,EACpDS,EAAUpa,UAAWuU,EAAiBhd,GAE1CrC,EAAQwH,YAAY6d,EAASjkB,QAC7BpB,EAAQwH,YAAYge,EAAapkB,QAGjCe,EAAIV,MAAQyjB,EAAUhG,YACf/c,CACT,GC7FawjB,GACTniB,GAAyBoiB,GAFC,EAE+B,QCDhDC,GACTriB,GAAyBsiB,GAFC,EAEoC,QCDrDC,GACTpjB,GAAwBqjB,GAAU,QCDzBC,GAA4BtjB,GAAwBujB,GAAO,QCA3DC,GAA4BxjB,GAAwByjB,GAAO,QCExE,IAAIvjB,GA+BG,MAAMwjB,GAAgC,CAC3CzmB,WAAY0mB,GACZxmB,YAAa,OACbC,UA/BF,SAAmBC,GACjB6C,GAAW7C,EAAQC,KAAKC,MAAMomB,GAAW,KAAiB,CACxD,SACA,SACA,SACA,UAEJ,EAyBEnmB,WAvBI,SACFC,GAGF,MAAOC,QAAQyC,EAACA,GAAIxC,OAAOimB,MAACA,GAAMvmB,QAAEA,GAAWI,EAEzC2C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAGtCc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAO,WAExC,GAAoC,IAAhCuB,EAAKC,cAAcH,EAAErB,OAAc,CACrC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDwB,GAASE,EAAKvD,GAASsD,EAAEnC,OAAQ4lB,EAAOlkB,EACzC,CAED,OAAOF,CACT,GChCaqkB,GACThjB,GAAyBijB,GAFC,EAE4B,QCA7CC,GACTljB,GAAyBmjB,GAFC,EAEiC,QCD/D,IAAIC,GA0BG,MAAMC,GAA+B,CAC1CjnB,WAAYknB,GACZhnB,YAAa,OACbC,UA1BF,SAAeC,GACb4mB,GAAe5mB,EAAQC,KAAKC,MAAM4mB,GAAU,KAAM,CAChD,SACA,SACA,SACA,UAEJ,EAoBE3mB,WAlBI,SAAmBC,GAEvB,MAAME,MAACA,EAAKN,QAAEA,GAAWI,GACnB2mB,MAACA,EAAKC,KAAEA,EAAIC,IAAEA,GAAO3mB,EAIrB4mB,EAASlZ,KAAKmZ,MAAMF,GAEpB9kB,EAAMnC,EAAQoC,WAAW,CAAC8kB,GAAS,WAEzC,OADAN,GAAa5mB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAAI0lB,EAAOC,EAAME,GACzD/kB,CACT,GC1BailB,GAA0BzkB,GAAwB0kB,ICElDC,GAA4B3kB,GAAwB4kB,ICDpDC,GACThkB,GAAyBikB,GAFC,EAEkC,QCAnDC,GACX/kB,GAAwBglB,ICFbC,GACTpkB,GAAyBqkB,GAFC,EAEiC,QCDlDC,GACTtkB,GAAyBukB,GAFC,EAEkC,QCAhE,IAAIC,GA2CG,MAAMC,GAA0B,CACrCroB,WAAYsoB,GACZpoB,YAAa,OACbC,UA1CF,SAAeC,GACbgoB,GAAUhoB,EAAQC,KAAKC,MAAMgoB,GAAK,KAAM,CACtC,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAiCE/nB,WA/BI,SAAcC,GAKlB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN8nB,YAACA,EAAW1nB,KAAEA,EAAI8lB,MAAEA,EAAK6B,KAAEA,GAAQ9nB,EAEzC,GAAgB,YAAZwC,EAAEnC,MACJ,MAAM,IAAIC,MAAM,wCAGlB,MAAMuB,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OAW1C,OATAqnB,GACIhoB,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GACrByB,EAAErB,MAAM,GACrB0mB,EACA1nB,EACA8lB,EACA6B,GAEGjmB,CACT,GCzCA,IAAIkmB,GAgDG,MAAMC,GAA8B,CACzC1oB,WAAY2oB,GACZzoB,YAAa,OACbC,UA/CF,SAAeC,GACbqoB,GAAcroB,EAAQC,KAAKC,MAAMqoB,GAAS,KAAM,CAC9C,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAoCEpoB,WAlCI,SAAkBC,GAKtB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,EAACge,EAAEA,EAAChV,GAAEA,GAAMzL,GACb8nB,YAACA,EAAW1nB,KAAEA,EAAI8lB,MAAEA,EAAK6B,KAAEA,GAAQ9nB,EAEzC,GAAgB,YAAZwC,EAAEnC,OAAmC,YAAZmgB,EAAEngB,OACd,YAAbmL,EAAGnL,MACL,MAAM,IAAIC,MAAM,uDAGlB,MAAMmL,EAAK/L,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OAazC,OAXA0nB,GACIroB,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI2f,EAAE1f,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACpByK,EAAGrK,MAAM,GACtB0mB,EACA1nB,EACA8lB,EACA6B,GAEGrc,CACT,GC3CA,IAAIyc,GAwDG,MAAMC,GAA0B,CACrC7oB,WAAY8oB,GACZ5oB,YAAa,OACbC,UAxDF,SAAeC,GACbwoB,GAAUxoB,EAAQC,KAAKC,MAAMwoB,GAAK,KAAe,CAC/C,SACA,SACA,SACA,UAEJ,EAkDEvoB,WAhDF,SAAaC,GAEX,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC1BuoB,iBAAkB1iB,EAAIe,SAAEA,GAAY1G,GACrCwC,EAACA,GAAKzC,EAEZ,IAAI4G,EADQjH,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAExC6F,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,GAAI0G,EAAoB,CAEtBQ,EAAQN,EACRK,EAFqBjH,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,EAG/D,CAED,MAAM8F,EAAYD,EAAMzF,MAAMC,OAC9BkC,EAAawD,2BAA2B,MAAOd,EAAMa,GACrD,MAAO5B,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO6E,GAClDiB,EAAavE,EAAKC,cAAcoE,GAEhClF,EAAMnC,EAAQoC,WAAWmD,EAAUzC,EAAEnC,OAC3C,GAAwC,IAApCqC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDmnB,GAAQvhB,EAASzH,GAASsD,EAAEnC,OAAQ4G,EAAYlF,EACjD,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAED,OAAOxB,CACT,GC1DaymB,GACTplB,GAAyBqlB,ICA7B,IAAIC,GAkFG,MAAMC,GAA8B,CACzCnpB,WAAYopB,GACZlpB,YAAa,OACbC,UA9EF,SAAeC,GACb8oB,GAAc9oB,EAAQC,KAAKC,MAAM8oB,GAAS,KAAiB,CACzD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EA2DE7oB,WAzDF,SACIC,GACF,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,EAE3B0C,EAAIzC,EAAOyC,EACXC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAU5C2B,EAAKwJ,OACW,YAAZ1J,EAAEnC,OACF,IACI,0DAA0DmC,EAAEnC,WAEpE,MAAMuI,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,GAAmB/I,EAC9CgJ,EAAW1F,EAAa2F,kBAC1BzG,EAAErB,MAAOyH,EAAYC,EAAS,EAAmBC,EAAKC,GAEpDG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAASJ,EAASK,QAAQC,IAC1BC,EAAWP,EAASK,QAAQG,MAC5BC,EAAYT,EAASK,QAAQK,OAC7BC,EAAUX,EAASK,QAAQO,KAC3BO,EAAiBnB,EAASmB,eAC1BD,EAAgBlB,EAASkB,cACzBL,EAAeb,EAASa,aACxBC,EAAcd,EAASc,YACvBuP,EAAgBrQ,EAASgB,WACzBsP,EAAiBtQ,EAASuQ,YAEhC,GAA4B,iBAAxBvQ,EAASiB,WACX,MAAM,IAAI3J,MAEN,6CAAG0I,EAASiB,2CAGlB,MAAMpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAU,WAC5ClD,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OAJAynB,GACI/lB,EAAKD,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAIqB,EAAErB,MAAM,GAAI+H,EAAcC,EACvDC,EAAQG,EAAUE,EAAWE,EAASQ,EAAgBD,EACtDL,EAAcC,EAAauP,EAAeC,EAAgBvX,GACvDF,CACT,GChFA,IAAI8mB,GA+EG,MAAMC,GAAgC,CAC3CtpB,WAAYupB,GACZrpB,YAAa,OACbC,UAzEF,SAAeC,GACbipB,GAAgBjpB,EAAQC,KAAKC,MAAM,YAAa,KAAM,CACpD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAiDEC,WA/CI,SAAoBC,GAKxB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,EAAekB,WAAEA,GAAcjK,EAE1DgJ,EAAW1F,EAAaiH,kBAC1B/H,EAAErB,MAAmDyH,EAAYC,EACnD,EAAGC,EAAKC,EAAiBkB,GACrCpI,EAAMnC,EAAQoC,WAAWkH,EAAS/D,SAAUzC,EAAEnC,OA4BpD,OA1BAsoB,GACIjpB,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAClCiI,EAASwB,UAGOxB,EAASgB,WACzBhB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAASiC,qBACTjC,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd/H,CACT,GC7EA,IAAIinB,GAiFG,MAAMC,GAAoC,CAC/CzpB,WAAY0pB,GACZxpB,YAAa,OACbC,UA3EF,SAAeC,GACbopB,GAAoBppB,EAAQC,KAAKC,MAAM,gBAAiB,KAAM,CAC5D,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAkDEC,WAhDI,SAAwBC,GAK5B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0L,GAACA,EAAE5E,MAAEA,GAAS7G,GACd6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,GAAmB/I,EAE9CgJ,EAAW1F,EAAaiH,kBAC1B3D,EAAMzF,MAAmDyH,EACzDC,EAAuB,EAAGC,EAAKC,GAC7B0C,EAAK/L,EAAQoC,WAAW8E,EAAMzF,MAAOyF,EAAMvG,OA6BjD,OA3BAyoB,GACIppB,EAAQkB,UAAUC,IAAI+F,EAAM9F,QAAQC,GACpCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjCiI,EAASwB,UAGOxB,EAASgB,WACzBhB,EAASyB,QACTzB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS4B,SACT5B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAAS+B,YACT/B,EAASa,aACTb,EAASc,YACTd,EAASgC,cACThC,EAASmB,eACTnB,EAASkB,cACTlB,EAASiC,qBACTjC,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQ+B,MACjBpC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd6B,CACT,GC/EA,IAAIwd,GAoEG,MAAMC,GAAkC,CAC7C5pB,WAAY6pB,GACZ3pB,YAAa,OACbC,UA/DF,SAAeC,GACbupB,GAAkBvpB,EAAQC,KAAKC,MAAM,cAAe,KAAM,CACxD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EA4CEC,WA1CI,SAAsBC,GAK1B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0L,GAACA,EAAE5E,MAAEA,GAAS7G,GACd6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGC,gBAAEA,GAAmB/I,EAE9CgJ,EAAW1F,EAAa2F,kBAC1BrC,EAAMzF,MAA2CyH,EAAYC,EAC/C,EAAGC,EAAKC,GACpB0C,EAAK/L,EAAQoC,WAAW8E,EAAMzF,MAAOyF,EAAMvG,OAuBjD,OArBA4oB,GACIvpB,EAAQkB,UAAUC,IAAI+F,EAAM9F,QAAQC,GACpCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjCiI,EAASwB,UAGOxB,EAASgB,WACzBhB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAASa,aACTb,EAASc,YACTd,EAASmB,eACTnB,EAASkB,cACTlB,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd6B,CACT,GChEA,IAAI2d,GAkFG,MAAMC,GAAwC,CACnD/pB,WAAYgqB,GACZ9pB,YAAa,OACbC,UA7EF,SAAeC,GACb0pB,GAAwB1pB,EAAQC,KAAKC,MAAM,oBAAqB,KAAM,CACpE,SACA,SACA,SACA,SACA,UACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAwDEC,WAtDI,SAA4BC,GAKhC,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN6I,WAACA,EAAUC,QAAEA,EAAOC,IAAEA,EAAGygB,oBAAEA,GAAuBvpB,EAExD0C,EAAKwJ,OACkB,IAAnB1J,EAAErB,MAAMC,QACR,IAAM,uDACFoB,EAAErB,MAAMC,YAChB,MAAM6X,EAA8B,CAAC,EAAG,GACxCvW,EAAKwJ,OACD5I,EAAakmB,+BAA+B3gB,EAASoQ,IACrD,IACI,wEAAepQ,oBAA0BoQ,OAEjD,MAAMjQ,EAAW1F,EAAa2F,kBAC1BzG,EAAErB,MAA2CyH,EAAYC,EAAS,CAAC,EAAG,GACtEC,GAEE2gB,EAAS/pB,EAAQoC,WAAWkH,EAAS/D,SAAUzC,EAAEnC,OACjDqpB,EAAUhqB,EAAQoC,WAAWkH,EAAS/D,SAAU,SAuBtD,OArBAmkB,GACI1pB,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAChCrB,EAAQkB,UAAUC,IAAI4oB,EAAO3oB,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAI6oB,EAAQ5oB,QAAQC,GACtC7B,GAASsD,EAAEnC,OACXkpB,EACAvgB,EAASwB,UACTxB,EAASgB,WACThB,EAAS0B,SACT1B,EAAS2B,QACT3B,EAAS6B,UACT7B,EAAS8B,SACT9B,EAASa,aACTb,EAASc,YACTd,EAASmB,eACTnB,EAASkB,cACTlB,EAASkC,sBACTlC,EAASmC,qBACTnC,EAASK,QAAQC,IACjBN,EAASK,QAAQO,MAEd,CAAC6f,EAAQC,EAClB,GC/EA,IAAIC,GAqEG,MAAMC,GAA2B,CACtCtqB,WAAYuqB,GACZrqB,YAAa,OACbC,UAtEF,SAAeC,GACbiqB,GACIjqB,EAAQC,KAAKC,MAAMiqB,GAAM,KAAe,CAAC,0BAC/C,EAoEEhqB,WAlEI,SACFC,GAEF,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,EAAIe,SAAEA,GAAY1G,GACnBwC,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAC5C,IAAI4F,EAAUlE,EACVmE,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,IAAIoqB,EAAgB9jB,EACpB,GAAII,EAAoB,CACtB,MAAMoB,EAAe9H,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,GAC1DyG,IAAiB/E,IAGnBmE,EAAQN,EACRK,EAAUa,EACVsiB,EAAgBxmB,EAAa+C,iBACzByjB,EAAc1oB,OAAQwF,EAAMzF,MAAMC,QAEzC,CAEDkC,EAAawD,2BACT,OAAQgjB,EAAeljB,EAAMzF,MAAMC,QACvC,MAAO6D,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO2oB,GAClD7iB,EAAavE,EAAKC,cAAcoE,GACtC,IAAIgjB,EAAcnjB,EACE,YAAhBA,EAAMvG,QACR0pB,EACIlT,GAAK,CAACnX,UAASK,OAAQ,CAACyC,EAAGoE,GAAQ5G,MAAO,CAACK,MAAO,aACtDsG,EAAUjH,EAAQkB,UAAUC,IAAIkpB,EAAYjpB,QAAQC,IAGtD,MAAMc,EAAMnC,EAAQoC,WAAWmD,EAAU,WACzC,GAAwC,IAApCvC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChD4oB,GAAShjB,EAASM,EAAYlF,EAC/B,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAMD,MAJoB,YAAhBuD,EAAMvG,OACRX,EAAQwH,YAAY6iB,EAAYjpB,QAG3Be,CACT,GCnEA,IAAImoB,GA6DG,MAAMC,GAA0B,CACrC3qB,WAAY4qB,GACZ1qB,YAAa,OACbC,UA7DF,SAAeC,GACbsqB,GAAUtqB,EAAQC,KAAKC,MAAMsqB,GAAK,KAAe,CAC/C,SACA,SACA,SACA,UAEJ,EAuDErqB,WArDF,SAAaC,GAEX,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,EAAIe,SAAEA,GAAY1G,GACnBwC,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAC5C,IAAI4F,EAAUlE,EACVmE,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,GAAI0G,EAAoB,CACtB,MAAMoB,EAAe9H,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,GAC1DyG,IAAiB/E,IAGnBmE,EAAQN,EACRK,EAAUa,EAEb,CAED,MAAMX,EAAYD,EAAMzF,MAAMC,OAE9BkC,EAAawD,2BAA2B,MAAOd,EAAMa,GACrD,MAAO5B,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO6E,GAClDiB,EAAavE,EAAKC,cAAcoE,GAEhClF,EAAMnC,EAAQoC,WAAWmD,EAAU2B,EAAMvG,OAC/C,GAAwC,IAApCqC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDipB,GAAQrjB,EAASzH,GAASsD,EAAEnC,OAAQ4G,EAAYlF,EACjD,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAED,OAAOxB,CACT,GC/DasoB,GACTjnB,GAAyBknB,ICG7B,IAAKC,GAKL,IAAIC,IALJ,SAAKD,GACHA,EAAAA,EAAA,QAAA,GAAA,UACAA,EAAAA,EAAA,UAAA,GAAA,WACD,CAHD,CAAKA,KAAAA,GAGJ,CAAA,IA+CM,MAAME,GAAgC,CAC3CjrB,WAAYkrB,GACZhrB,YAAa,OACbK,WA9BF,SAAmBC,GAKjB,MAAOC,QAAQyC,EAACA,GAAE9C,QAAEA,EAASM,OAAOyqB,SAACA,EAAQC,KAAEA,IAAS5qB,EAElDmF,EAAWwlB,EAAS7mB,KACtB,CAACmS,EAAGpR,IAAMoR,EAAE,GAAqBvT,EAAErB,MAAMwD,GAAKoR,EAAE,KAC9CtT,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCc,EAAMnC,EAAQoC,WAAWmD,EAAUzC,EAAEnC,OACrC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAC1CwE,EAAc,IAAItD,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QAErDwoB,EAAkBF,EAAS7mB,KAAIgnB,GAAYA,EAAS,KACpDC,EAAmBJ,EAAS7mB,KAAIgnB,GAAYA,EAAS,KACrDE,EACF,IAAI7oB,WAAW,IAAIC,WAAWyoB,GAAiBxoB,QAC7C4oB,EACF,IAAI9oB,WAAW,IAAIC,WAAW2oB,GAAkB1oB,QAKpD,OAHAmoB,GACI7nB,EAAK8C,EAAa/C,EAAErB,MAAMC,OAAQlC,GAASsD,EAAEnC,OAAQyqB,EACrDC,EAAmBV,GAAkBK,GAAO3oB,GACzCF,CACT,EAMEpC,UA5CF,SAAeC,GACb4qB,GAAgB5qB,EAAQC,KAAKC,MAAM4qB,GAAW,KAAiB,CAC7D,SACA,QACA,SACA,SACA,QACA,QACA,SACA,UAEJ,GCxBA,IAAIjoB,GAYE,SAAUyoB,GACZlrB,GAEF,MAAMJ,QAACA,EAASK,QAAQkrB,OAACA,GAASjrB,OAAOghB,IAACA,IAAQlhB,EAC5C2C,EAAM/C,EAAQkB,UAAUC,IAAIoqB,EAAOnqB,QAAQC,GAC3Cc,EAAMnC,EAAQoC,WAAWmpB,EAAO9pB,MAAO8pB,EAAO5qB,OAC9C0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1CgJ,EAAWkhB,EAAO9pB,MAAM6f,GACxBe,EAAQrf,EAAKC,cAAcsoB,EAAO9pB,OAAS4I,EAGjD,OAAsC,IAAlCrH,EAAKC,cAAcd,EAAIV,QAI3BoB,GAASE,EAAKV,EAAOgI,EAAUgY,GAHtBlgB,CAKX,CAEO,MAAMqpB,GAA8B,CACzC5rB,WAAY6rB,GACZ3rB,YAAa,OACbC,UAhCF,SAAeC,GACb6C,GAAW7C,EAAQC,KAAKC,MAAMurB,GAAS,KAAiB,CACtD,SACA,SACA,SACA,UAEJ,EA0BEtrB,WAAYmrB,ICnCd,IAAII,GAoDG,MAAMC,GAAkC,CAC7C/rB,WAAYgsB,GACZ9rB,YAAa,OACbC,UAnDF,SAAeC,GACb0rB,GAAkB1rB,EAAQC,KAAKC,MAAM0rB,GAAa,KAAM,CACtD,SACA,SACA,SACA,SACA,SACA,UAEJ,EA2CEzrB,WAzCI,SAAsBC,GAK1B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3BmrB,OAACA,GAAUlrB,GACXwrB,WAACA,EAAUC,KAAEA,EAAIC,WAAEA,GAAczrB,EAEvC,GAAqB,YAAjBirB,EAAO5qB,MACT,MAAM,IAAIC,MACN,8CAA8C2qB,EAAO5qB,SAG3D,MAAMqrB,EAAgBD,EAAaR,EAASD,GAAQ,CAClDjrB,OAAQ,CAACkrB,UACTvrB,UACAM,MAAO,CAACghB,IAAKiK,EAAO9pB,MAAMC,OAAS,MAG9BoJ,EAAWmhB,GAAaD,EAAcvqB,MACvCU,EAAMnC,EAAQoC,WAAW,CAAC0I,EAAW+gB,GAAa,SAaxD,OAXAH,GACI1rB,EAAQkB,UAAUC,IAAI6qB,EAAc5qB,QAAQC,GAC5CyJ,EACAmhB,EACAJ,EACAC,EACA9rB,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,IAEjC0qB,GACH/rB,EAAQwH,YAAYwkB,EAAc5qB,QAE7Be,CACT,GCnDa+pB,GACT1oB,GAAyB2oB,ICAhBC,GACT5oB,GAAyB6oB,ICJhBC,GAA0B3pB,GAAwB4pB,ICW/C,SAAAC,GACZxsB,EAAsBysB,GACxB,MAAM9Z,EAAS,IAAInQ,WAAWxC,EAAQC,KAAKysB,OAAOjqB,OAAQgqB,EAAW,GAC/DE,EAAmBha,EAAO,GAC1Bia,EAAeja,EAAO,GACtBka,EAAkBla,EAAO,GACzBma,EAAgBna,EAAO,GAG7B,OADA3S,EAAQC,KAAK8sB,MAAMN,GACZ,CAACE,mBAAkBC,eAAcC,kBAAiBC,gBAC3D,CCjBA,IAAIjqB,GA6CG,MAAMmqB,GAA0C,CACrDptB,WAAYqtB,GACZntB,YAAa,OACbC,UA5CF,SAAeC,GACb6C,GAAW7C,EAAQC,KAAKC,MACpB+sB,GACA,SACA,CACE,SACA,SACA,SACA,SACA,UAER,EAkCE9sB,WAhCF,SAAoBC,GAKlB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B8sB,aAACA,EAAYC,cAAEA,EAAaC,eAAEA,GAAkB9sB,GAChDsc,MAACA,EAAKyQ,OAAEA,GAAUhtB,EAElB+c,EAAUpd,EAAQkB,UAAUC,IAAIyb,EAAMxb,QAAQC,GAC9CisB,EAAWttB,EAAQkB,UAAUC,IAAIksB,EAAOjsB,QAAQC,GAEhDorB,EACF5pB,GAASua,EAASkQ,EAAUH,EAAeD,EAAcE,IAEvDT,iBAACA,EAAgBC,aAAEA,EAAYC,gBAAEA,EAAeC,cAAEA,GACpDN,GAAkBxsB,EAASysB,GAS/B,OANAzsB,EAAQC,KAAK8sB,MAAMF,GACnB7sB,EAAQC,KAAK8sB,MAAMD,GAGf9sB,EAAQoC,WAAW,CAACwqB,GAAe,QAASD,EAGlD,GC3CA,IAAI9pB,GAkDG,MAAM0qB,GAA0C,CACrD3tB,WAAY4tB,GACZ1tB,YAAa,OACbC,UAhDF,SAAeC,GACb6C,GAAW7C,EAAQC,KAAKC,MACpBstB,GACA,SACA,CACE,SACA,SACA,SACA,SACA,SACA,QAER,EAqCErtB,WAnCF,SAA6BC,GAK3B,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B8sB,aAACA,EAAYC,cAAEA,EAAaC,eAAEA,EAAcK,mBAAEA,GAChDntB,GACEsc,MAACA,EAAKyQ,OAAEA,GAAUhtB,EAElB+c,EAAUpd,EAAQkB,UAAUC,IAAIyb,EAAMxb,QAAQC,GAC9CisB,EAAWttB,EAAQkB,UAAUC,IAAIksB,EAAOjsB,QAAQC,GAEhDorB,EAAY5pB,GACdua,EAASkQ,EAAUH,EAAeD,EAAcE,EAChDK,IAEEd,iBAACA,EAAgBC,aAAEA,EAAYC,gBAAEA,EAAeC,cAAEA,GACpDN,GAAkBxsB,EAASysB,GAU/B,OAPAzsB,EAAQC,KAAK8sB,MAAMF,GAOZ,CAJH7sB,EAAQoC,WAAW,CAACwqB,GAAe,QAASD,GAErB3sB,EAAQoC,WAAW,GAAI,QAAS0qB,GAG7D,GChDA,IAAIjqB,GAkDG,MAAM6qB,GAA0C,CACrD9tB,WAAY+tB,GACZ7tB,YAAa,OACbC,UAhDF,SAAeC,GACb6C,GAAW7C,EAAQC,KAAKC,MACpBytB,GACA,SACA,CACE,SACA,SACA,SACA,SACA,SACA,UAER,EAqCExtB,WAnCF,SAAoBC,GAKlB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B8sB,aAACA,EAAYC,cAAEA,EAAaC,eAAEA,EAAcQ,aAAEA,GAAgBttB,GAC9Dsc,MAACA,EAAKyQ,OAAEA,GAAUhtB,EAElB+c,EAAUpd,EAAQkB,UAAUC,IAAIyb,EAAMxb,QAAQC,GAC9CisB,EAAWttB,EAAQkB,UAAUC,IAAIksB,EAAOjsB,QAAQC,GAEhDorB,EAAY5pB,GACdua,EAASkQ,EAAUH,EAAeD,EAAcE,EAChDQ,IAEEjB,iBAACA,EAAgBC,aAAEA,EAAYC,gBAAEA,EAAeC,cAAEA,GACpDN,GAAkBxsB,EAASysB,GAW/B,OAPAzsB,EAAQC,KAAK8sB,MAAMD,GAOZ,CAJH9sB,EAAQoC,WAAW,CAACwqB,GAAe,QAASD,GAE5C3sB,EAAQoC,WAAW,CAACwqB,GAAe,UAAWC,GAGpD,GCnDagB,GACTrqB,GAAyBsqB,GAFC,EAEgC,QCA9D,IAAIC,GA+BG,MAAMC,GAA6B,CACxCpuB,WAAYquB,GACZnuB,YAAa,OACbC,UA9BF,SAAeC,GACb+tB,GAAa/tB,EAAQC,KAAKC,MAAM+tB,GAAQ,KAAiB,CACvD,SACA,SACA,SACA,SACA,UAEJ,EAuBE9tB,WArBF,SACIC,GACF,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B8jB,QAACA,GAAW7jB,GACZM,MAACA,EAAKutB,MAAEA,EAAKC,QAAEA,EAAOC,SAAEA,GAAY9tB,EAEpC6B,EAAMnC,EAAQoC,WAAW,IAAI8hB,EAAQziB,MAAOysB,GAAQvtB,GACpD0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAG1CojB,EADczkB,EAAQkB,UAAUC,IAAI+iB,EAAQ9iB,QACpBC,GAI9B,OAFA0sB,GAAWtJ,EAAWyJ,EAAOC,EAASC,EAAU/rB,GAEzCF,CACT,GCrBO,MAAMksB,GAA+B,CAC1CzuB,WAAY0uB,GACZxuB,YAAa,OACbK,WAXF,SAAkBC,GAChB,MAAOC,QAAQyC,EAACA,GAAE9C,QAAEA,GAAWI,EACzB+B,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OAG1C,OAFgBX,EAAQwE,mBAAmBrC,GACnC0f,KAAK,GACN1f,CACT,GCkCO,MAAMosB,GAA2B,CACtC3uB,WAAY4uB,GACZ1uB,YAAa,OACbK,WAzCI,SACFC,GAEF,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B6F,KAACA,GAAQ3F,EAEf,GAAsB,IAAlBD,EAAOqB,OACT,OAAO2f,GACH,CAAChhB,OAAQ,CAAC6G,MAAO7G,EAAO,IAAKL,UAASM,MAAO,CAACghB,IAAKrb,KAGzD,MAAMxE,EAAQpB,EAAO,GAAGoB,MAClBd,EAAQN,EAAO,GAAGM,MAExBN,EAAOoR,SAAQqG,IACb9U,EAAKyrB,kBACDhtB,EAAOqW,EAAErW,MACT,yDACJuB,EAAKwJ,OACD7L,IAAUmX,EAAEnX,OACZ,IAAM,yDAAwD,IAGpE,MAAM+tB,EAAwC,GAQxC/b,EAASlF,GAAO,CAACpN,OAPCA,EAAO6D,KAAI4T,IACjC,MAAM6W,EACFtN,GAAW,CAAChhB,OAAQ,CAAC6G,MAAO4Q,GAAI9X,UAASM,MAAO,CAACghB,IAAKrb,KAE1D,OADAyoB,EAAwBxpB,KAAKypB,GACtBA,CAAS,IAG8B3uB,UAASM,MAAO,CAAC2F,UAIjE,OAFAyoB,EAAwBjd,SAAQqG,GAAK9X,EAAQwH,YAAYsQ,EAAE1W,UAEpDuR,CACT,GClCA,IAAIic,GAsDG,MAAMC,GAA4B,CACvCjvB,WAAYkvB,GACZhvB,YAAa,OACbK,WAvCF,SACIC,GACF,MAAOC,QAAQyC,EAACA,GAAE9C,QAAEA,EAASM,OAAOyqB,SAACA,EAAQgE,cAAEA,IAAkB3uB,EAE3DmF,EAAWwlB,EAAS7mB,KACtB,CAACmS,EAAGpR,IAAMoR,EAAE,GAAqBvT,EAAErB,MAAMwD,GAAKoR,EAAE,KAEpD,GAAoC,IAAhCrT,EAAKC,cAAcH,EAAErB,OAGvB,OAAOogB,GAAK,CACV7hB,UACAM,MAAO,CAACmB,MAAO8D,EAAUmM,MAAOqd,EAAepuB,MAAOmC,EAAEnC,SAI5D,MAAMoC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCc,EAAMnC,EAAQoC,WAAWmD,EAAUzC,EAAEnC,OAErC0B,EADgBrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QACpBC,GAEtBwE,EAAc,IAAItD,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QAErDwoB,EAAkBF,EAAS7mB,KAAIgnB,GAAYA,EAAS,KACpDC,EAAmBJ,EAAS7mB,KAAIgnB,GAAYA,EAAS,KACrDE,EACF,IAAI7oB,WAAW,IAAIC,WAAWyoB,GAAiBxoB,QAC7C4oB,EACF,IAAI9oB,WAAW,IAAIC,WAAW2oB,GAAkB1oB,QAKpD,OAHAmsB,GACI7rB,EAAK8C,EAAa/C,EAAErB,MAAMC,OAAQlC,GAASsD,EAAEnC,OAAQyqB,EACrDC,EAAmB0D,EAAe1sB,GAC/BF,CACT,EAMEpC,UArDF,SAAeC,GACb4uB,GAAY5uB,EAAQC,KAAKC,MAAM4uB,GAAO,KAAiB,CACrD,SACA,QACA,SACA,SACA,QACA,QACA,SACA,UAEJ,GCrBaE,GACTxrB,GAAyByrB,ICE7B,IAAIC,GAkCG,MAAMC,GAA4B,CACvCvvB,WAAYwvB,GACZtvB,YAAa,OACbC,UAnCF,SAAeC,GACbkvB,GAAYlvB,EAAQC,KAAKC,MAAMkvB,GAAO,KAAiB,CACrD,SACA,SACA,UAEJ,EA8BEjvB,WA5BF,SAAeC,GACb,MAAMC,OAACA,EAAML,QAAEA,GAAWI,GACpB0C,EAACA,EAACyjB,MAAEA,GAASlmB,EACb0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCguB,EAAYrvB,EAAQkB,UAAUC,IAAIolB,EAAMnlB,QAAQC,GAEtD,IAAI4F,EAAUlE,EACd,MAAMmE,EAAQpE,EACd,IAAIunB,EAAcnjB,EACE,YAAhBA,EAAMvG,QACR0pB,EAAclT,GAAK,CAACnX,UAASK,OAAQ,CAACyC,KAAIxC,MAAO,CAACK,MAAO,aACzDsG,EAAUjH,EAAQkB,UAAUC,IAAIkpB,EAAYjpB,QAAQC,IAGtD,MAAMc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAO,WAClCY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAMhD,OALA6tB,GAAUjoB,EAASooB,EAAWhtB,GAEV,YAAhB6E,EAAMvG,OACRX,EAAQwH,YAAY6iB,EAAYjpB,QAE3Be,CACT,GC9BA,IAAImtB,GAmEG,MAAMC,GAA2B,CACtC3vB,WAAY4vB,GACZ1vB,YAAa,OACbC,UAlEF,SAAeC,GACbsvB,GAAWtvB,EAAQC,KAAKC,MAAMsvB,GAAM,KAAe,CACjD,SACA,SACA,SACA,UAEJ,EA4DErvB,WA1DF,SAAcC,GAKZ,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,EAAIe,SAAEA,GAAY1G,GACnBwC,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAC5C,IAAI4F,EAAUlE,EACVmE,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,IAAIoqB,EAAgB9jB,EACpB,GAAII,EAAoB,CACtB,MAAMoB,EAAe9H,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,GAC1DyG,IAAiB/E,IAGnBmE,EAAQN,EACRK,EAAUa,EACVsiB,EAAgBxmB,EAAa+C,iBACzByjB,EAAc1oB,OAAQwF,EAAMzF,MAAMC,QAEzC,CAEDkC,EAAawD,2BACT,OAAQgjB,EAAeljB,EAAMzF,MAAMC,QACvC,MAAO6D,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO2oB,GAClD7iB,EAAavE,EAAKC,cAAcoE,GAEhClF,EAAMnC,EAAQoC,WAAWmD,EAAU2B,EAAMvG,OAC/C,GAAwC,IAApCqC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDiuB,GAASroB,EAASM,EAAY/H,GAAS2C,EAAIxB,OAAQ0B,EACpD,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAED,OAAOxB,CACT,GCxDastB,GAA4B,CACvC7vB,WAAY8vB,GACZ5vB,YAAa,OACbK,WAdGC,IACC,MAAMJ,QAACA,EAAOM,MAAEA,GAASF,GACnB2mB,MAACA,EAAKC,KAAEA,EAAI2I,KAAEA,EAAIhvB,MAAEA,GAASL,EAC7BiP,ECPN,SACFwX,EAAeC,EAAc2I,EAC7BhvB,GAKF,GAJsBomB,IAAUC,GACID,EAAQC,GAAQ2I,EAAO,GACvB3I,EAAOD,GAAS4I,EAAO,EAIzD,OAAO3sB,EAAK4sB,oBAAoB,EAAGjvB,GAGrC,MAAMkvB,EAAc7hB,KAAK8hB,IAAI9hB,KAAK+hB,MAAM/I,EAAOD,GAAS4I,IAClDpgB,EAASvM,EAAK4sB,oBAAoBC,EAAalvB,GAEjDqmB,EAAOD,GAAkB,IAAT4I,IAGlBA,GAAQ,GAGVpgB,EAAO,GAAKwX,EACZ,IAAK,IAAI9hB,EAAI,EAAGA,EAAIsK,EAAO7N,OAAQuD,IACjCsK,EAAOtK,GAAKsK,EAAOtK,EAAI,GAAK0qB,EAE9B,OAAOpgB,CACT,CDnBqBygB,CAAajJ,EAAOC,EAAM2I,EAAMhvB,GAEzCwB,EAAMnC,EAAQoC,WAAW,CAACmN,EAAO7N,QAASf,GAGhD,OAFgBX,EAAQwE,mBAAmBrC,GACnCsC,IAAI8K,GACLpN,CAAG,GETH8tB,GACTzsB,GAAyB0sB,ICJhBC,GACTxtB,GAAwBytB,ICDfC,GAA2B1tB,GAAwB2tB,ICAnDC,GAA4B5tB,GAAwB6tB,ICIjE,IAAIC,GA4DG,MAAMC,GAAqC,CAChD9wB,WAAY+wB,GACZ7wB,YAAa,OACbC,UA1DF,SAAeC,GACbywB,GAAqBzwB,EAAQC,KAAKC,MAAMywB,GAAgB,KAAe,CACrE,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EA8CExwB,WA5CF,SAAwBC,GAKtB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAE3BwwB,OAACA,GAAUvwB,GACXwwB,aAACA,EAAYC,iBAAEA,EAAgBziB,KAAEA,GAAQ/N,GACxCywB,EAAWC,GAAY3iB,GAEvBgU,EAAO4O,EAAWC,EAAU1O,GAAeoO,EAAOnvB,MACnD8D,EAAW,CAAC8c,EAAO0O,EAAWC,EAAUxO,GAE9C,IACIvF,EADAkU,EAAQnxB,EAAQkB,UAAUC,IAAIyvB,EAAOxvB,QAErB,YAAhB+vB,EAAMxwB,QACRsc,EACI9F,GAAK,CAACnX,UAASK,OAAQ,CAACyC,EAAG8tB,GAAStwB,MAAO,CAACK,MAAO,aACvDwwB,EAAQnxB,EAAQkB,UAAUC,IAAI8b,EAAW7b,SAE3C,MAAM2B,EAAMouB,EAAM9vB,GAEZc,EAAMnC,EAAQoC,WAAWmD,EAAU,WACzC,GAAyC,IAArCvC,EAAKC,cAAc2tB,EAAOnvB,OAC5B,OAAOU,EAET,MAAME,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAUhD,OARAovB,GACI1tB,EAAKsf,EAAO4O,EAAWC,EAAU1O,EAAauO,EAAWC,EACzDH,EAAe,EAAI,EAAGC,EAAmB,EAAI,EAAGzuB,GAElC,MAAd4a,GACFjd,EAAQwH,YAAYyV,EAAW7b,QAG1Be,CACT,GC1DA,IAAIivB,GAsDG,MAAMC,GAAyC,CACpDzxB,WAAY0xB,GACZxxB,YAAa,OACbC,UArDF,SAAeC,GACboxB,GAAyBpxB,EAAQC,KAAKC,MAClCoxB,GAAoB,KACpB,CACE,SACA,SACA,SACA,QACA,QACA,WAER,EA2CEnxB,WAzCF,SAA4BC,GAI1B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3BwwB,OAACA,EAAM9kB,GAAEA,GAAMzL,GACfwwB,aAACA,GAAgBvwB,EAEjByL,EAAK/L,EAAQoC,WAAWwuB,EAAOnvB,MAAO,WAE5C,IACIwb,EADAkU,EAAQnxB,EAAQkB,UAAUC,IAAIyvB,EAAOxvB,QAwBzC,MAtBoB,YAAhB+vB,EAAMxwB,QACRsc,EAAa9F,GAAK,CAChBnX,UACAK,OAAQ,CAACyC,EAAG8tB,GACZtwB,MAAO,CAACK,MAAO,aAEjBwwB,EAAQnxB,EAAQkB,UAAUC,IAAI8b,EAAW7b,SAG3CgwB,GACIpxB,EAAQkB,UAAUC,IAAIyvB,EAAOxvB,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjC,IAAIkB,WAAW,IAAIC,WAAWouB,EAAOnvB,OAAOgB,QAC5C,IAAIF,WAAW,IAAIC,WAAWsJ,EAAGrK,OAAOgB,QACxCouB,GAGc,MAAd5T,GACFjd,EAAQwH,YAAYyV,EAAW7b,QAG1B2K,CACT,GC5CA,IAAIwlB,GAqFG,MAAMC,GAA4C,CACvD5xB,WAAY6xB,GACZ3xB,YAAa,OACbC,UA3EF,SAAeC,GACbuxB,GAA4BvxB,EAAQC,KAAKC,MACvCuxB,GACA,KACA,CACE,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAGN,EA2DEtxB,WAzDF,SAA+BC,GAK7B,MAAMJ,QAAEA,EAAOK,OAAEA,EAAMC,MAAEA,GAAUF,GAC7BwwB,OAAEA,GAAWvwB,GACbwwB,aAAEA,EAAYC,iBAAEA,EAAgBziB,KAAEA,GAAS/N,GAE1CywB,EAAWC,GAAY3iB,GAEvBgU,EAAO4O,EAAWC,EAAU1O,GAAeoO,EAAOnvB,MACnD8D,EAAW,CAAC8c,EAAO0O,EAAWC,EAAUxO,GAExCrgB,EAAMnC,EAAQoC,WAAWmD,EAAU,WACzC,GAAyC,IAArCvC,EAAKC,cAAc2tB,EAAOnvB,OAC5B,OAAOU,EAGT,IACI8a,EADAkU,EAAQnxB,EAAQkB,UAAUC,IAAIyvB,EAAOxvB,QAErB,YAAhB+vB,EAAMxwB,QACRsc,EAAa9F,GAAK,CAChBnX,UACAK,OAAQ,CAAEyC,EAAG8tB,GACbtwB,MAAO,CAAEK,MAAO,aAElBwwB,EAAQnxB,EAAQkB,UAAUC,IAAI8b,EAAW7b,SAG3C,MAAM2B,EAAMouB,EAAM9vB,GACZgB,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAmBhD,OAjBAkwB,GACExuB,EACAsf,EACA4O,EACAC,EACA1O,EACAuO,EACAC,EACAH,EAAe,EAAI,EACnBC,EAAmB,EAAI,EACvBzuB,GAGgB,MAAd4a,GACFjd,EAAQwH,YAAYyV,EAAW7b,QAG1Be,CACT,GC3FA,IAAIuvB,GAsDG,MAAMC,GAAgD,CAC3D/xB,WAAYgyB,GACZ9xB,YAAa,OACbC,UArDF,SAAeC,GACb0xB,GAAgC1xB,EAAQC,KAAKC,MACzC0xB,GAA2B,KAC3B,CACE,SACA,SACA,SACA,QACA,QACA,WAER,EA2CEzxB,WAzCF,SAAmCC,GAIjC,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3BwwB,OAACA,EAAM9kB,GAAEA,GAAMzL,GACfwwB,aAACA,GAAgBvwB,EAEjByL,EAAK/L,EAAQoC,WAAWwuB,EAAOnvB,MAAO,WAE5C,IACIwb,EADAkU,EAAQnxB,EAAQkB,UAAUC,IAAIyvB,EAAOxvB,QAwBzC,MAtBoB,YAAhB+vB,EAAMxwB,QACRsc,EAAa9F,GAAK,CAChBnX,UACAK,OAAQ,CAACyC,EAAG8tB,GACZtwB,MAAO,CAACK,MAAO,aAEjBwwB,EAAQnxB,EAAQkB,UAAUC,IAAI8b,EAAW7b,SAG3CswB,GACI1xB,EAAQkB,UAAUC,IAAIyvB,EAAOxvB,QAAQC,GACrCrB,EAAQkB,UAAUC,IAAI2K,EAAG1K,QAAQC,GACjCrB,EAAQkB,UAAUC,IAAI4K,EAAG3K,QAAQC,GACjC,IAAIkB,WAAW,IAAIC,WAAWouB,EAAOnvB,OAAOgB,QAC5C,IAAIF,WAAW,IAAIC,WAAWsJ,EAAGrK,OAAOgB,QACxCouB,GAGc,MAAd5T,GACFjd,EAAQwH,YAAYyV,EAAW7b,QAG1B2K,CACT,GCnDA,IAAI8lB,GA6CG,MAAMC,GAA8B,CACzClyB,WAAYmyB,GACZjyB,YAAa,OACbK,WAjCI,SACFC,GAEF,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN2xB,KAACA,GAAQ1xB,EAETgG,EAAOtD,EAAKqD,eAAe2rB,EAAMlvB,EAAErB,OAEzC,GAAuB,IAAnBqB,EAAErB,MAAMC,OACV,OAAO0C,GAAS,CAAC/D,OAAQ,CAACyC,KAAI9C,YAGhC,MAAMmC,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OACpCoC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCgB,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1C4wB,EAAY,IAAI1vB,WAAW,IAAIC,WAAW8D,GAAM7D,QAChDyvB,EAAgB,IAAI3vB,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QAE7DovB,GACI9uB,EAAKkvB,EAAW3rB,EAAK5E,OAAQwwB,EAAepvB,EAAErB,MAAMC,OAAQW,GAEhE,MAAM+S,EACFhJ,GAAQ,CAAC/L,OAAQ,CAACyC,EAAGX,GAAM7B,MAAO,CAACmB,MAAOqB,EAAErB,OAAQzB,YAGxD,OADAA,EAAQwH,YAAYrF,EAAIf,QACjBgU,CACT,EAMErV,UA7CF,SAAeC,GACb6xB,GAAc7xB,EAAQC,KAAKC,MAAM6xB,GAAS,KAAM,CAC9C,SACA,QACA,SACA,QACA,SACA,UAEJ,GCfA,IAAII,GAqDG,MAAMC,GAAuC,CAClDxyB,WAAYyyB,GACZvyB,YAAa,OACbK,WAnCI,SAA2BC,GAK/B,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3Buc,MAACA,GAAStc,GACViyB,QAACA,EAAOC,UAAEA,EAASC,OAAEA,GAAUlyB,EAE/B6B,EAAMnC,EAAQoC,WAAWua,EAAMlb,MAAOkb,EAAMhc,OAC5CyhB,EAAUpiB,EAAQkB,UAAUC,IAAIwb,EAAMvb,QAAQC,GAC9CgB,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,IAEzCghB,EAAOC,EAAaC,EAAYC,GAAe7F,EAAMlb,OAErDgxB,EAASC,GACZ9uB,EAAa+uB,eAAeH,EAAQlQ,EAAaC,GAK/CqQ,EAAkC,iBAAdL,EACtB,CAACA,EAAWA,EAAWA,EAJO,IAAdA,EAIgC,EAH3B,KAIrB,IAAIA,EAJiB,KAKnBM,EAAY,IAAItwB,WAAW,IAAIC,WAAWowB,GAAYnwB,QAK5D,OAHA0vB,GACI/P,EAASC,EAAOC,EAAaC,EAAYC,EAAa8P,EAASG,EAC/DC,EAASG,EAAWD,EAAWlxB,OAAQW,GACpCF,CACT,EAMEpC,UApDF,SAAeC,GACbmyB,GAAanyB,EAAQC,KAAKC,MAAMmyB,GAAkB,KAAiB,CACjE,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,QACA,SACA,UAEJ,GCrBaS,GAA4BnwB,GAAwBowB,ICDpDC,GAA4BrwB,GAAwBswB,ICIjE,IAAIC,GAmDG,MAAMC,GAAgC,CAC3CvzB,WAAYwzB,GACZtzB,YAAa,OACbC,UAjDF,SAAeC,GACbkzB,GAAgBlzB,EAAQC,KAAKC,MAAMkzB,GAAW,KAAe,CAC3D,SACA,SACA,SACA,SACA,SACA,SACA,QACA,SACA,UAEJ,EAsCEjzB,WApCF,SACIC,GAGF,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B8jB,QAACA,EAAOmP,QAAEA,GAAWhzB,GACrBoB,MAACA,GAASnB,EAEV6B,EAAMnC,EAAQoC,WAAWX,EAAO4xB,EAAQ1yB,OAC9C,GAAkC,IAA9BqC,EAAKC,cAAcxB,GACrB,OAAOU,EAGT,MAAMqiB,UAACA,EAAS8O,WAAEA,EAAU1d,UAAEA,EAASzM,QAAEA,EAAOoqB,WAAEA,GAC9CC,GAAaC,gBAAgBJ,EAASnP,EAASziB,GAG7CgjB,EADczkB,EAAQkB,UAAUC,IAAI+iB,EAAQ9iB,QACpBC,GAGxBqyB,EADc1zB,EAAQkB,UAAUC,IAAIkyB,EAAQjyB,QACpBC,GAExBqjB,EAAe,IAAIniB,WAAW,IAAIC,WAAW2G,GAAS1G,QAEtDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAKhD,OAJA6xB,GACIzO,EAAWiP,EAAWl0B,GAAS6zB,EAAQ1yB,OAAQ6jB,EAAW8O,EAC1D1d,EAAW8O,EAAc6O,EAAYlxB,GAElCF,CACT,GClDA,IAAIwxB,GAoDG,MAAMC,GAAmC,CAC9Ch0B,WAAYi0B,GACZ/zB,YAAa,OACbC,UAlDF,SAAeC,GACb2zB,GAAmB3zB,EAAQC,KAAKC,MAAM2zB,GAAc,KAAiB,CACnE,SACA,SACA,SACA,SACA,SACA,SACA,OACA,UAEJ,EAwCE1zB,WAtCF,SAAsBC,GAKpB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0zB,eAACA,EAAcvkB,OAAEA,GAAUlP,GAC3B0zB,KAACA,GAAQzzB,EAEf,GAAIwzB,EAAenzB,QAAU4O,EAAO5O,MAClC,MAAM,IAAIC,MACN,+EACIkzB,EAAenzB,aAAa4O,EAAO5O,SAG7C,MAAMwB,EAAMnC,EAAQoC,WAAWmN,EAAO9N,MAAO,SAE7C,SAAS8U,EAASzT,GAChB,OAAO9C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,EACxC,CAYD,OAXAsyB,GACIpd,EAASud,GACTvd,EAAShH,GACKukB,EAAeryB,MAAM,GAClBqyB,EAAeryB,MAAM,GACvB8N,EAAO9N,MAAM,GAClBjC,GAASs0B,EAAenzB,OACV,SAATozB,EACfxd,EAASpU,IAGNA,CACT,GCnDA,IAAI6xB,GAmCG,MAAMC,GAA6B,CACxCr0B,WAAYs0B,GACZp0B,YAAa,OACbK,WAxBF,SAAgBC,GACd,MAAMC,OAACA,EAAML,QAAEA,GAAWI,GACpB+zB,UAACA,EAASrc,EAAEA,EAACsc,EAAEA,GAAK/zB,EAEpBg0B,EAAcr0B,EAAQkB,UAAUC,IAAIgzB,EAAU/yB,QAAQC,GACtDizB,EAAMt0B,EAAQkB,UAAUC,IAAI2W,EAAE1W,QAAQC,GACtCkzB,EAAMv0B,EAAQkB,UAAUC,IAAIizB,EAAEhzB,QAAQC,GACtCc,EAAMnC,EAAQoC,WAAW0V,EAAErW,MAAOqW,EAAEnX,OACpC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAE1CmzB,EAAQL,EAAU1yB,MAAMC,OACxB+yB,EAAQ3c,EAAErW,MAAMC,OAEhB2W,EAAmB,IAAVmc,GAAeA,EAAQ,GAAe,IAAVC,EACvC,EACAzxB,EAAKC,cAAc6U,EAAErW,MAAMS,MAAM,IAGrC,OADA8xB,GAAWK,EAAaC,EAAKC,EAAKlc,EAAQhW,GACnCF,CACT,EAMEpC,UAnCF,SAAeC,GACbg0B,GAAah0B,EAAQC,KAAKC,MAAM,WAAY,KAAM,CAChD,SACA,SACA,SACA,SACA,UAEJ,GCZaw0B,GAA2B/xB,GAAwBgyB,ICAhE,IAAI9xB,GAsBG,MAAM+xB,GAA8B,CACzCh1B,WAAY,UACZE,YAAa,OACbC,UAvBF,SAAeC,GACb6C,GAAW7C,EAAQC,KAAKC,MAAM20B,GAAS,KAAiB,CAAC,SAAU,UACrE,EAsBE10B,WApBF,SAAiBC,GAEf,MAAMJ,QAACA,EAASK,QAAQyC,EAACA,IAAM1C,EACzB2C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OACpC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAGhD,OAAsC,IAAlC2B,EAAKC,cAAcd,EAAIV,QAI3BoB,GAASE,EAAKV,GAHLF,CAKX,GCpBa2yB,GAA2BnyB,GAAwBoyB,ICFnDC,GAA0BryB,GAAwBsyB,ICClDC,GAA2BvyB,GAAwBwyB,ICCnDC,GAA+BzyB,GAAwB0yB,IC4D7D,MAAMC,GAAqC,CAChD11B,WAAY21B,GACZz1B,YAAa,OACbK,WA3DF,SAAwBC,GAKtB,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GACN2U,WAACA,EAAU+V,SAAEA,GAAYzqB,EAEzB4U,EAAOlS,EAAKC,cAAc+R,GAE1BwgB,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBtwB,QAAS6lB,GAE1B,IAAK,IAAI9lB,EAAI,EAAI+P,EAAWtT,OAAQuD,EAAInC,EAAErB,MAAMC,SAAUuD,EACxDuwB,EAAiBtwB,KAAK,CAAC,EAAG,IAG5B,MAAMuwB,EAAU5G,GAAY1uB,WAAW,CACrCE,OAAQ,CAACyC,KACT9C,UACAM,MAAO,CAACyqB,SAAUyK,EAAkBzG,cAAe,KAG/C2G,EACF9xB,EAAayR,YAAYogB,EAAQh0B,MAAOuT,EAAYE,GAAM,GAExDygB,EAAoC/xB,EAAa2R,YACnDmgB,EAAoBh0B,OAAQsT,EAAWtT,QAAQ,GAE7Ck0B,EACFhyB,EAAa6R,oBAAoBggB,EAAQh0B,MAAOuT,EAAYE,GAAM,GAIhE2gB,EACFzpB,GAAQ,CAAC/L,OAHwB,CAACyC,EAAG2yB,GAGLz1B,UAASM,MAFV,CAACmB,MAAOi0B,KAOrCI,EACFjxB,GAAU,CAACxE,OAJ0B,CAACyC,EAAG+yB,GAIL71B,UAASM,MAF5B,CAACyE,KAAM4wB,KAMtBhjB,EAASvG,GACX,CAAC/L,OAHsC,CAACyC,EAAGgzB,GAGb91B,UAASM,MAFF,CAACmB,MAAOm0B,KAQjD,OAJA51B,EAAQwH,YAAYiuB,EAAQr0B,QAC5BpB,EAAQwH,YAAYquB,EAAgBz0B,QACpCpB,EAAQwH,YAAYsuB,EAAS10B,QAEtBuR,CACT,GCvDA,IAAIojB,GA4HG,MAAMC,GAA0C,CACrDp2B,WAAYq2B,GACZn2B,YAAa,OACbC,UAxHI,SAAgBC,GACpB+1B,GACI/1B,EAAQC,KAAKC,MAAM,sBAAuB,SAAU,CAClD,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,EAyGEC,WAvGI,SAA8BC,GAIlC,MAAMJ,QAACA,EAAOK,OAAEA,GAAUD,GACpB8jB,QAACA,EAAO3U,OAAEA,EAAM2mB,WAAEA,EAAUC,aAAEA,GAAgB91B,EAE9C+1B,EAAelS,EAAQziB,MAAM,GAC7BiS,EAAOwQ,EAAQziB,MAAM,GACrB40B,EAAYr2B,EAAQsE,SAAS4xB,EAAW90B,QAAQ,GAIhDk1B,EAAwB,CAACF,EAAeC,EAAW3iB,GAEnD+Q,EAAYzkB,EAAQkB,UAAUC,IAAI+iB,EAAQ9iB,QAAQC,GAClDk1B,EAAWv2B,EAAQkB,UAAUC,IAAIoO,EAAOnO,QAAQC,GAChDm1B,EAAiBx2B,EAAQkB,UAAUC,IAAIg1B,EAAa/0B,QAAQC,GAE5Do1B,EACFz2B,EAAQoC,WAAWk0B,EAAuBpS,EAAQvjB,OAChD+1B,EAAkB12B,EAAQkB,UAAUC,IAAIs1B,EAAcr1B,QAAQC,GAE9Ds1B,EACF32B,EAAQoC,WAAWk0B,EAAsBp0B,MAAM,EAAG,GAAIqN,EAAO5O,OAC3Di2B,EAAiB52B,EAAQkB,UAAUC,IAAIw1B,EAAav1B,QAAQC,GAE5Dw1B,EAAoB72B,EAAQoC,WAAW,CAACi0B,GAAY,QACpDS,EACF92B,EAAQkB,UAAUC,IAAI01B,EAAkBz1B,QAAQC,GAE9C01B,EAAkB/2B,EAAQoC,WAAW,CAACg0B,GAAelS,EAAQvjB,OAC7Dq2B,EAAoBh3B,EAAQkB,UAAUC,IAAI41B,EAAgB31B,QAAQC,GAElE41B,EAAkBj3B,EAAQoC,WAAW,CAAC,GAAI,SAC1C80B,EAAoBl3B,EAAQkB,UAAUC,IAAI81B,EAAgB71B,QAAQC,GAElE81B,EAAapB,GACftR,EAAW8R,EAAU/2B,GAAS+P,EAAO5O,OAAQy1B,EAAcC,EAC3D3iB,EAAM8iB,EAAgBE,EAAiBE,EACvCE,EAAqBE,EAAmBE,GAEtCE,EACFp3B,EAAQsE,SAAS2yB,EAAgB71B,QAErC,IAAIi2B,EACJ,OAAQD,EAAqB,IAC3B,KAAK,EACHC,EACIzzB,EAAa0zB,gDACTF,EAAqB,IAC7B,MAEF,KAAK,EACHC,EACIzzB,EAAa2zB,gDACTH,EAAqB,GAAIA,EAAqB,IACtD,MAEF,KAAK,EACHC,EACIzzB,EAAa4zB,kDACTJ,EAAqB,GAAIA,EAAqB,GAC9CA,EAAqB,IAC7B,MACF,QACEC,EAAmB,GAIvB,GADAr3B,EAAQwH,YAAYyvB,EAAgB71B,QAChCi2B,EAKF,MAJAr3B,EAAQwH,YAAYivB,EAAcr1B,QAClCpB,EAAQwH,YAAYmvB,EAAav1B,QACjCpB,EAAQwH,YAAYqvB,EAAkBz1B,QACtCpB,EAAQwH,YAAYuvB,EAAgB31B,QAC9B,IAAIR,MAAMy2B,GAGlB,IAAII,EAAiBhB,EACjBiB,EAAgBf,EAiBpB,OAfIQ,IAAeb,EAAsB,KACvCmB,EAAiBv1B,GAAM,CACrB7B,OAAQ,CAACyC,EAAG2zB,GACZn2B,MAAO,CAAC8N,MAAO,EAAGC,KAAM,CAAC8oB,EAAYzjB,IACrC1T,YAEF03B,EAAgBx1B,GAAM,CACpB7B,OAAQ,CAACyC,EAAG6zB,GACZr2B,MAAO,CAAC8N,MAAO,EAAGC,KAAM8oB,GACxBn3B,YAEFA,EAAQwH,YAAYivB,EAAcr1B,QAClCpB,EAAQwH,YAAYmvB,EAAav1B,SAG5B,CAACq2B,EAAgBC,EAAeb,EAAmBE,EAC5D,GC7HA,IAAIY,GAgHG,MAAMC,GAAoC,CAC/Ch4B,WAAYi4B,GACZ/3B,YAAa,OACbC,UA9GF,SAAeC,GACb23B,GAAoB33B,EAAQC,KAAKC,MAAM23B,GAAe,KAAe,CACnE,SACA,SACA,SACA,SACA,SACA,SACA,UAEJ,EAqGE13B,WAnGF,SAAuBC,GAIrB,MAAMJ,QAACA,EAAOK,OAAEA,GAAUD,GACpB03B,aAACA,EAAY3d,WAAEA,EAAUxW,SAAEA,GAAYtD,EAE7C,GAAkC,IAA9By3B,EAAar2B,MAAMC,OACrB,MAAM,IAAId,MAAM,gEACVk3B,EAAar2B,SAErB,GAAgC,IAA5B0Y,EAAW1Y,MAAMC,OACnB,MAAM,IAAId,MAAM,8DACVuZ,EAAW1Y,SAEnB,GAA8B,IAA1BkC,EAASlC,MAAMC,OACjB,MAAM,IAAId,MACN,sDAAsD+C,EAASlC,SAGrE,MAAMs2B,EAAiB/3B,EAAQkB,UAAUC,IAAI22B,EAAa12B,QAAQC,GAC5D22B,EAAeh4B,EAAQkB,UAAUC,IAAIgZ,EAAW/Y,QAAQC,GACxD42B,EAAaj4B,EAAQkB,UAAUC,IAAIwC,EAASvC,QAAQC,GAEpD62B,EAAMJ,EAAar2B,MAAM,GACzB02B,EAAan1B,EAAKC,cAAcU,EAASlC,OAEzC22B,EAAap4B,EAAQoC,WAAW,CAAC81B,EAAKC,GAAaL,EAAan3B,OAChE03B,EAAer4B,EAAQkB,UAAUC,IAAIi3B,EAAWh3B,QAAQC,GAExD6d,EAAclf,EAAQoC,WAAW,CAAC+1B,GAAax0B,EAAShD,OACxD23B,EAAgBt4B,EAAQkB,UAAUC,IAAI+d,EAAY9d,QAAQC,GAE1D41B,EAAkBj3B,EAAQoC,WAAW,CAAC,GAAI,SAC1C80B,EAAoBl3B,EAAQkB,UAAUC,IAAI81B,EAAgB71B,QAAQC,GAExEs2B,GACII,EAAgBC,EAAcC,EAAYC,EAAKG,EAC/CC,EAAepB,GAEnB,MAAME,EACFp3B,EAAQsE,SAAS2yB,EAAgB71B,QAErC,IAAIi2B,EACJ,OAAQD,EAAqB,IAC3B,KAAK,EACHC,EACIzzB,EAAa20B,yDACTnB,EAAqB,GAAIA,EAAqB,IACtD,MAEF,KAAK,EACHC,EACIzzB,EAAa40B,8CACTpB,EAAqB,GAAIA,EAAqB,IACtD,MAEF,KAAK,EACHC,EACIzzB,EAAa60B,uDACjB,MACF,KAAK,EAAG,CACN,MAAMC,EACFjzB,MAAMwR,KAAKjX,EAAQsE,SAAS6V,EAAW/Y,SACrCu3B,EACIlzB,MAAMwR,KAAKjX,EAAQsE,SAAS4a,EAAY9d,SAClDi2B,EACIzzB,EAAag1B,gDACTF,EAAkBC,GAC1B,KACD,CACD,KAAK,EAAG,CACN,MAAMD,EACFjzB,MAAMwR,KAAKjX,EAAQsE,SAAS6V,EAAW/Y,SACrCu3B,EACIlzB,MAAMwR,KAAKjX,EAAQsE,SAAS4a,EAAY9d,SAClDi2B,EACIzzB,EAAai1B,gDACTH,EAAkBC,GAC1B,KACD,CACD,QACEtB,EAAmB,GAIvB,GADAr3B,EAAQwH,YAAYyvB,EAAgB71B,QAChCi2B,EAGF,MAFAr3B,EAAQwH,YAAY4wB,EAAWh3B,QAC/BpB,EAAQwH,YAAY0X,EAAY9d,QAC1B,IAAIR,MAAMy2B,GAGlB,MAAO,CAACe,EAAYlZ,EACtB,GC5GA,IAAI4Z,GAKE,SAAUC,GAAM/4B,GACpB84B,GACI94B,EAAQC,KAAKC,MAAM,yBAA0B,KAAe,CAC1D,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UAER,CAEgB,SAAA84B,GACZ54B,EAIA64B,GACF,MAAMj5B,QAACA,EAAOK,OAAEA,GAAUD,GACpBqQ,KAACA,EAAIyT,QAAEA,EAAOgV,WAAEA,GAAc74B,EAE9B84B,EAAajV,EAAQziB,MAAM,GAC3B23B,EACDp5B,EAAQsE,SAAS40B,EAAW93B,OAAQ+3B,EAAa,EAAGA,GACxC,GAEXhC,EADuBgC,EAAa,EAAIC,EAAiB,EAAI,EAGnE,GAAIjC,EAAa,EACf,MAAO,IAAIv2B,MACPgD,EACKy1B,2DAGX,MAAMna,EAAczO,EAAKhP,MAAMS,QAC/Bgd,EAAY,GAAKiY,EAEjB,MAAM/1B,EAASpB,EAAQkB,UAAUC,IAAIsP,EAAKrP,QAAQC,GAC5CojB,EAAYzkB,EAAQkB,UAAUC,IAAI+iB,EAAQ9iB,QAAQC,GAClDi4B,EAAet5B,EAAQkB,UAAUC,IAAI+3B,EAAW93B,QAAQC,GAExDsP,EAAS3Q,EAAQoC,WAAW8c,EAAazO,EAAK9P,OAC9C44B,EAAWv5B,EAAQkB,UAAUC,IAAIwP,EAAOvP,QAAQC,GAEhD41B,EAAkBj3B,EAAQoC,WAAW,CAAC,GAAI,SAC1C80B,EAAoBl3B,EAAQkB,UAAUC,IAAI81B,EAAgB71B,QAAQC,GAExEy3B,GACI13B,EAAQ5B,GAASiR,EAAK9P,OAAQ8P,EAAKhP,MAAM,GAAIgjB,EAAW6U,EACxDC,EAAUrC,EAAmB+B,EAAQ,GAEzC,MAAM7B,EACFp3B,EAAQsE,SAAS2yB,EAAgB71B,QAErC,IAAIi2B,EACJ,OAAQD,EAAqB,IAC3B,KAAK,EACHC,EACIzzB,EACKy1B,0DACT,MAEF,KAAK,EACHhC,EACIzzB,EACK41B,+DACT,MAEF,KAAK,EACHnC,EACIzzB,EAAa61B,yDACTrC,EAAqB,GAAIA,EAAqB,IACtD,MACF,KAAK,EACHC,EACIzzB,EAAa81B,uDACTtC,EAAqB,GAAIA,EAAqB,GAC9CA,EAAqB,IAC7B,MACF,QACEC,EAAmB,GAIvB,GADAr3B,EAAQwH,YAAYyvB,EAAgB71B,QAChCi2B,EAEF,MADAr3B,EAAQwH,YAAYmJ,EAAOvP,QACrB,IAAIR,MAAMy2B,GAGlB,OAAO1mB,CACT,CC3FO,MAAMgpB,GAAwC,CACnD/5B,WAAYg6B,GACZ95B,YAAa,OACbC,UAAWg5B,GACX54B,WAXF,SAA2BC,GAIzB,OAAO44B,GAAuB54B,GAAM,EACtC,GCEO,MAAMy5B,GAAuC,CAClDj6B,WAAYk6B,GACZh6B,YAAa,OACbC,UAAWg5B,GACX54B,WAXF,SAA0BC,GAIxB,OAAO44B,GAAuB54B,GAAM,EACtC,GCLA,IAAI25B,GAuDG,MAAMC,GAAoC,CAC/Cp6B,WAAYq6B,GACZn6B,YAAa,OACbC,UApDF,SAAeC,GACb+5B,GAAoB/5B,EAAQC,KAAKC,MAAM+5B,GAAe,KAAe,CACnE,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,QACA,SACA,UAEJ,EAuCE95B,WArCF,SAAuBC,GAKrB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B85B,cAACA,EAAaC,aAAEA,EAAYhE,aAAEA,GAAgB91B,GAC9C6e,YAACA,GAAe5e,EAEhB6B,EAAMnC,EAAQoC,WAAW8c,EAAaiX,EAAax1B,OACzD,GAAwC,IAApCqC,EAAKC,cAAcic,GACrB,OAAO/c,EAGT,MAAMqiB,UAACA,EAAS8O,WAAEA,EAAU1d,UAAEA,EAASzM,QAAEA,EAAOoqB,WAAEA,GAC9C3vB,EAAa6vB,gBAAgB0G,EAAcD,EAAehb,GAExDkb,EAAkBp6B,EAAQkB,UAAUC,IAAI+4B,EAAc94B,QAAQC,GAC9Dg5B,EAAiBr6B,EAAQkB,UAAUC,IAAIg5B,EAAa/4B,QAAQC,GAC5Dm1B,EAAiBx2B,EAAQkB,UAAUC,IAAIg1B,EAAa/0B,QAAQC,GAE5DqjB,EAAe,IAAIniB,WAAW,IAAIC,WAAW2G,GAAS1G,QAEtDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAOhD,OALA04B,GACIK,EAAiBC,EAAgBF,EAAa14B,MAAMC,OACpD80B,EAAgBh3B,GAAS22B,EAAax1B,OAAQ6jB,EAAW8O,EACzD1d,EAAW8O,EAAc6O,EAAYlxB,GAElCF,CACT,GC/BO,MAAMm4B,GAA6B,CACxC16B,WAAY26B,GACZz6B,YAAa,OACbK,WAxBI,SACFC,GACF,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAC3B0C,EAACA,GAAKzC,GACNm6B,gBAACA,EAAev0B,KAAEA,GAAQ3F,EAE1Bm6B,EAAQz3B,EAAKqD,eAAeJ,EAAMnD,EAAErB,OAAO,GAE3Ci5B,EAAa92B,EAAa+2B,iBAAiB73B,EAAG03B,EAAiBC,GAC/DrsB,EAAQ,IAAI3I,MAAM3C,EAAErB,MAAMC,QAAQmgB,KAAK,GACvCxT,EAAOvL,EAAErB,MAAMS,QACrB,OAAOw4B,EAAWx2B,KAAI02B,IACpB,MAAMC,EAAa,IAAIxsB,GACvBwsB,EAAWJ,GAASG,EACpB,MAAME,EACF54B,GAAM,CAAC7B,OAAQ,CAACyC,KAAIxC,MAAO,CAAC8N,QAAOC,KAAMwsB,GAAa76B,YAE1D,OADAoO,EAAMqsB,IAAUG,EACTE,CAAM,GAEjB,GCvBaC,GAA2Bp4B,GAAwBq4B,ICDnDC,GAA6Bt4B,GAAwBu4B,ICArDC,GACT33B,GAAyB43B,ICG7B,IAAIC,GA0BG,MAAMC,GAA2B,CACtC17B,WAAY27B,GACZz7B,YAAa,OACbC,UA1BF,SAAeC,GACbq7B,GAAWr7B,EAAQC,KAAKC,MAAMq7B,GAAM,KAAe,CACjD,SACA,SACA,SACA,UAEJ,EAoBEp7B,WAlBF,SACIC,GAEF,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3BmmB,MAACA,GAASjmB,GACVwC,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAEtCc,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OACpC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAEhD,OADAg6B,GAASt4B,EAAKwjB,EAAO/mB,GAASsD,EAAEnC,OAAQ0B,GACjCF,CACT,GCxBA,IAAIq5B,GAmGG,MAAMC,GAAmC,CAC9C77B,WAAY87B,GACZ57B,YAAa,OACbC,UAhGF,SAAeC,GACbw7B,GAAmBx7B,EAAQC,KAAKC,MAAMw7B,GAAc,KAAe,CACjE,SACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,UAEJ,EAoFEv7B,WAlFI,SAAuBC,GAK3B,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,GAEN+N,MACJA,EAAKutB,IACLA,EAAGxyB,QACHA,EAAOyyB,UACPA,EAASC,QACTA,EAAOC,aACPA,EAAYC,YACZA,EAAWC,eACXA,GACE17B,GAEE27B,iBACJA,EAAgBC,WAChBA,EAAUC,WACVA,EAAUC,UACVA,EAASC,cACTA,EACAjuB,MAAOkuB,EACPX,IAAKY,EACLpzB,QAASqzB,GAEPjuB,EAAWkuB,UACP35B,EAAErB,MAAO2M,EAAOutB,EAAKxyB,EAASyyB,EAAWC,EAASC,EAClDC,EAAaC,GAErB,IAAIrpB,EAEJ,GAAIwpB,EAEFxpB,EAASvG,GAAQ,CAAC/L,OAAQ,CAACyC,KAAI9C,UAASM,MAAO,CAACmB,MAAOy6B,UAClD,GAAIE,GAAaC,EAAe,CAErCr5B,EAAKwJ,OACD1J,EAAErB,MAAMC,QAAU,GAClB,IAAM,yCAAyCoB,EAAErB,MAAMC,WAE3D,MAAM2M,EAAOE,EAAW7I,gBAAgB42B,EAAQC,EAAMC,GAEhDE,EAASx6B,GAAM,CAAC7B,OAAQ,CAACyC,KAAI9C,UAASM,MAAO,CAAC8N,MAAOkuB,EAAQjuB,UACnEsE,EACIvG,GAAQ,CAAC/L,OAAQ,CAACyC,EAAG45B,GAAS18B,UAASM,MAAO,CAACmB,MAAOy6B,KAC1Dl8B,EAAQwH,YAAYk1B,EAAOt7B,OAC5B,KAAM,CACL,MAAMe,EAAMnC,EAAQoC,WAAW65B,EAAkB,WAE3Cl5B,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtC8d,EACF,IAAI5c,WAAW,IAAIC,WAAWQ,EAAK0L,eAAe5L,EAAErB,QAAQgB,QAC1Dk6B,EAAa,IAAIp6B,WAAW,IAAIC,WAAW85B,GAAQ75B,QACnDm6B,EAAW,IAAIr6B,WAAW,IAAIC,WAAW+5B,GAAM95B,QAC/CiiB,EAAe,IAAIniB,WAAW,IAAIC,WAAWg6B,GAAU/5B,QAEvD2c,EACF,IAAI7c,WAAW,IAAIC,WAAWy5B,GAAkBx5B,QAC9C4c,EAAkB,IAAI9c,WACxB,IAAIC,WAAWQ,EAAK0L,eAAeutB,IAAmBx5B,QACpDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAEhDm6B,GACIz4B,EAAKoc,EAAerc,EAAErB,MAAMC,OAAQi7B,EAAYC,EAAUlY,EAC1DtF,EAAkBC,EAAiB4c,EAAiBv6B,OAAQW,GAEhEsQ,EAASvG,GAAQ,CAAC/L,OAAQ,CAACyC,EAAGX,GAAMnC,UAASM,MAAO,CAACmB,MAAOy6B,KAE5Dl8B,EAAQwH,YAAYrF,EAAIf,OACzB,CAED,OAAOuR,CACT,GChEO,MAAMkqB,GAAmC,CAC9Cj9B,WAAYk9B,GACZh9B,YAAa,OACbK,WArCF,SAAsBC,GAKpB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3BqQ,KAACA,EAAIssB,WAAEA,GAAc18B,GACrBsP,UACJA,EAASC,YACTA,EAAWC,QACXA,EAAOC,SACPA,EAAQC,SACRA,EAAQC,uBACRA,GACE1P,EAEE08B,EAAQh9B,EAAQsE,SAASmM,EAAKrP,QAC9B67B,EAAcj9B,EAAQsE,SAASy4B,EAAW37B,SAEzCiR,EAAQH,Y9HgLbzB,EAAoBssB,EAAwBptB,EAC5CC,EAAuBC,EAAiBC,EAAkBC,EAC1DC,GACF,OAAO,IAAIP,GACAE,EAAWC,EAAaC,EAASC,EAAUC,EAC3CC,GACN2B,QAAQlB,EAAMssB,EACrB,C8HvLiCG,CAC3BF,EAAOC,EAAattB,EAAWC,EAAaC,EAASC,EAAUC,EAC/DC,GAEEmtB,EAAYn9B,EAAQoC,WAAW,CAACiQ,EAAO3Q,QAAS,UAChC1B,EAAQkB,UAAUC,IAAIg8B,EAAU/7B,QACxCkS,YAAcjB,EAE5B,MAAM+qB,EAAkBp9B,EAAQoC,WAAW26B,EAAWt7B,MAAO,SAI7D,OAH4BzB,EAAQwE,mBAAmB44B,GACnC34B,IAAIyN,GAEjB,CAACirB,EAAWC,EACrB,GCDO,MAAMC,GAAkC,CAC7Cz9B,WAAY09B,GACZx9B,YAAa,OACbK,WAlCF,SAAqBC,GAKnB,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B8G,MAACA,EAAK0L,UAAEA,GAAavS,GACrBqS,UAACA,GAAapS,EAEdi9B,EAAYv9B,EAAQsE,SAAS4C,EAAM9F,QACnCo8B,EAAgBx9B,EAAQsE,SAASsO,EAAUxR,SAE1C8iB,EAAS3U,EAAQ9N,Y9H8BtByF,EAAqB0L,EACrBF,GACF,MAAM5H,EAAY5D,EAAMxF,OAGlB+7B,EAAuB,GAE7B,IAAIlK,EAAa,EACbmK,EAAgB,EACpB,MAAMvE,EAAuB,IAAI1zB,MAAMqF,GACvC,IAAK,IAAI7F,EAAI,EAAGA,EAAI6F,IAAa7F,EAAG,CAClC,MAAM04B,EAAmBF,EAAO/7B,OAChC8Q,GAAMtL,EAAMjC,GAAI2N,EAAWF,EAAW+qB,GACtC,MAAMG,EAAWH,EAAO/7B,OAASi8B,EACjCxE,EAAWl0B,GAAK24B,EAChBrK,GAAcqK,EACdF,EAAgB1vB,KAAKC,IAAIyvB,EAAeE,EACzC,CAED,MAAM1Z,EAAUlhB,EAAKmP,kBAAkB,QAAsB,EAAbohB,GAC1ChkB,EAAuB,IAAI9J,MAAM8tB,GACjC9xB,EAA0B,CAACqJ,EAAW4yB,GAE5C,IAAIG,EAAI,EACR,IAAK,IAAI54B,EAAI,EAAGA,EAAI6F,IAAa7F,EAC/B,IAAK,IAAIG,EAAI,EAAGA,EAAI+zB,EAAWl0B,KAAMG,EAEnC8e,EAAY,EAAJ2Z,GAAS54B,EACjBif,EAAY,EAAJ2Z,EAAQ,GAAKz4B,EACrBmK,EAAOsuB,GAAKJ,EAAOI,KACjBA,EAIN,MAAO,CAAC3Z,EAAS3U,EAAQ9N,EAC3B,C8HhEMq8B,CAAmBP,EAAWC,EAAc,GAAI9qB,GAC9C6gB,EAAahkB,EAAO7N,OAEpBq8B,EAAa/9B,EAAQoC,WAAW,CAACmxB,EAAY,GAAI,SAChCvzB,EAAQwE,mBAAmBu5B,GACnCt5B,IAAIyf,GAEnB,MAAM8Z,EAAYh+B,EAAQoC,WAAW,CAACmxB,GAAa,UAC7BvzB,EAAQkB,UAAUC,IAAI68B,EAAU58B,QACxCkS,YAAc/D,EAE5B,MAAM0uB,EAAWj+B,EAAQoC,WAAW,CAAC,GAAI,SAIzC,OAHqBpC,EAAQwE,mBAAmBy5B,GACnCx5B,IAAIhD,GAEV,CAACs8B,EAAYC,EAAWC,EACjC,GCVO,MAAMC,GAA6C,CACxDt+B,WAAYu+B,GACZr+B,YAAa,OACbK,WAtBF,SAAgCC,GAK9B,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B8G,MAACA,GAAS7G,GACV+9B,WAACA,GAAc99B,EAIfiP,ECdQ,SACZrI,EAAqBk3B,GACvB,MAAMztB,EAAS3N,EAAKmP,kBAAkB,QAASjL,EAAMxF,QAErD,IAAK,IAAIuD,EAAI,EAAGA,EAAIiC,EAAMxF,SAAUuD,EAClC0L,EAAO1L,GACHjC,EAAKq7B,cAAcn3B,EAAMjC,IAAIq5B,OAAOF,GAAYG,qBAGtD,OAAO5tB,CACT,CDIiB6tB,CAFGx+B,EAAQsE,SAAS4C,EAAM9F,QAEeg9B,GAElDj8B,EAAMnC,EAAQoC,WAAW8E,EAAMzF,MAAO,SAG5C,OAFgBzB,EAAQwE,mBAAmBrC,GACnCsC,IAAI8K,GACLpN,CACT,GEpBas8B,GACTj7B,GAAyBk7B,ICI7B,IAAIC,GA+DG,MAAMC,GAA0B,CACrCh/B,WAAYi/B,GACZ/+B,YAAa,OACbC,UA/DF,SAAeC,GACb2+B,GAAU3+B,EAAQC,KAAKC,MAAM2+B,GAAK,KAAe,CAC/C,SACA,SACA,SACA,UAEJ,EAyDE1+B,WAvDF,SAAaC,GAEX,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3B6F,KAACA,EAAIe,SAAEA,GAAY1G,GACnBwC,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GAC5C,IAAI4F,EAAUlE,EACVmE,EAAQpE,EAEZ,MAAM8D,WAACA,EAAUN,KAAEA,EAAIF,aAAEA,EAAYM,mBAAEA,GACnCV,GAAwBlD,EAAGmD,EAAMjG,GAErC,IAAIoqB,EAAgB9jB,EACpB,GAAII,EAAoB,CACtB,MAAMoB,EAAe9H,EAAQkB,UAAUC,IAAIyF,EAAWxF,QAAQC,GAC1DyG,IAAiB/E,IAGnBmE,EAAQN,EACRK,EAAUa,EACVsiB,EAAgBxmB,EAAa+C,iBACzByjB,EAAc1oB,OAAQwF,EAAMzF,MAAMC,QAEzC,CAEDkC,EAAawD,2BACT,MAAOgjB,EAAeljB,EAAMzF,MAAMC,QACtC,MAAO6D,EAAU8B,GACbzD,EAAa0D,0BAA0BJ,EAAMzF,MAAO2oB,GAClD7iB,EAAavE,EAAKC,cAAcoE,GAEhClF,EAAMnC,EAAQoC,WAAWmD,EAAU2B,EAAMvG,OAC/C,GAAwC,IAApCqC,EAAKC,cAAciE,EAAMzF,OAAc,CACzC,MAAMY,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAChDs9B,GAAQ13B,EAASM,EAAY/H,GAAS2C,EAAIxB,OAAQ0B,EACnD,CAOD,GALIqE,GAEF1G,EAAQwH,YAAYZ,EAAWxF,QAG7B4F,EAAU,CAEZ,MAAMrD,EAAWC,EAAa6D,qBAAqBtF,EAAIV,MAAO2E,GAC9DjE,EAAIV,MAAQkC,CACb,CAED,OAAOxB,CACT,GClEa28B,GAA0Bn8B,GAAwBo8B,ICAlDC,GAA2Br8B,GAAwBs8B,ICIhE,IAAIC,GAyDG,MAAMC,GAA0C,CACrDv/B,WAAYw/B,GACZt/B,YAAa,OACbC,UAvDF,SAAeC,GACbk/B,GACIl/B,EAAQC,KAAKC,MAAMk/B,GAAqB,KAAe,CACrD,SACA,SACA,SACA,SACA,SACA,SACA,QACA,SACA,SACA,UAER,EA0CEj/B,WAxCF,SAA6BC,GAK3B,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3BiE,OAACA,EAAM6f,QAAEA,EAAOmP,QAAEA,GAAWhzB,EAG7B8B,EAAMnC,EAAQoC,WAAWiC,EAAO5C,MAAO4C,EAAO1D,OACpD,GAAyC,IAArCqC,EAAKC,cAAcoB,EAAO5C,OAC5B,OAAOU,EAGT,MAAMqiB,UAACA,EAAS8O,WAAEA,EAAU1d,UAAEA,EAASzM,QAAEA,EAAOoqB,WAAEA,GAC9CC,GAAaC,gBAAgBJ,EAASnP,EAAS7f,EAAO5C,OAGpDgjB,EADczkB,EAAQkB,UAAUC,IAAI+iB,EAAQ9iB,QACpBC,GAGxBqyB,EADc1zB,EAAQkB,UAAUC,IAAIkyB,EAAQjyB,QACpBC,GAGxBkV,EADavW,EAAQkB,UAAUC,IAAIkD,EAAOjD,QACpBC,GAEtBqjB,EAAe,IAAIniB,WAAW,IAAIC,WAAW2G,GAAS1G,QAEtDJ,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAKhD,OAJA69B,GACIza,EAAWiP,EAAWl0B,GAAS6zB,EAAQ1yB,OAAQ6jB,EAAW8O,EAC1D1d,EAAW8O,EAAc6O,EAAYlxB,EAAOkU,GAEzCpU,CACT,GCvDA,IAAIk9B,GCDJ,IAAIC,GCDJ,IAAIC,GCQG,MCuJDC,GAAgC,CACpC7/B,GACAuD,GACAE,GACAE,GACAO,GACAE,GACA+C,GACAa,GACAM,GACAE,GACAE,GACAE,GACAE,GACAE,GACAE,GACAG,GACAkD,GACAvB,GACAiB,GACAiB,GACAiI,GACAmB,GACAO,GACAE,GACAU,GACAE,GACAG,GACAwB,GACAG,GACAa,GACAoB,GACAI,GACAK,GACAE,GACAE,GACAI,GACAkB,GACAa,GACAG,GACAI,GACAW,GACAI,GACAG,GACAK,GACAI,GACAE,GACAG,GACAG,GACAE,GACAE,GACAM,GACAE,GACAI,GACAG,GACAO,GACAE,GACAG,GACAW,GACAG,GACAG,GACAa,GACAe,GACAE,GACAnhB,GACAqhB,GACAE,GACAE,GACAE,GACAG,GACAE,GACAG,GACAS,GACAF,GACAI,GACAE,GACAE,GACAE,GACAG,GACAK,GACAG,GACAG,GACAG,GACAG,GACAG,GACAG,GACAG,GACAO,GACAK,GACAE,GACAI,GACAc,GACAO,GACAE,GACAE,GACAU,GACAO,GACAG,GACAG,GACAG,GACAK,GACAE,GACAM,GACAG,GACAG,GACAI,GACAE,GACAQ,GACAE,GACAE,GACAE,GACA7jB,GACAgkB,GACAW,GACAG,GACAG,GACAG,GACAM,GACAU,GACAE,GACAG,GACAS,GACAK,GACAS,GACAE,GACAE,GACAE,GACAE,GACAtgB,GACA4W,GACA4J,GACAE,GACAU,GACA4B,GACA+B,GACAE,GACAG,GACAM,GACAS,GACAE,GACAE,GACAG,GACAG,GACAoB,GACAQ,GACAa,GACAO,GACAG,GACAE,GACAE,GACAG,GJ9QsC,CACtCv/B,WAAY6/B,GACZ3/B,YAAa,OACbC,UApCF,SAAeC,GACbq/B,GAAWr/B,EAAQC,KAAKC,MAAMu/B,GAAM,KAAiB,CACnD,SACA,QACA,SACA,QACA,SACA,UAEJ,EA4BEt/B,WA1BF,SACIC,GACF,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3B0C,EAACA,GAAKzC,EACN0C,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,IACtCq+B,KAACA,GAAQp/B,EAETqD,EAAqB,IAAI8B,MAAM3C,EAAErB,MAAMC,QAC7C,IAAK,IAAIuD,EAAI,EAAGA,EAAItB,EAASjC,OAAQuD,IACnCtB,EAASsB,GAAKnC,EAAErB,MAAMwD,GAAKy6B,EAAKz6B,GAElC,MAAMY,EAAc,IAAItD,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QACrDk9B,EAAgB,IAAIp9B,WAAW,IAAIC,WAAWmB,GAAUlB,QAExDN,EAAMnC,EAAQoC,WAAWuB,EAAUb,EAAEnC,OACrC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAIhD,OAHAg+B,GACIt8B,EAAK8C,EAAa/C,EAAErB,MAAMC,OAAQi+B,EAAeh8B,EAASjC,OAC1DlC,GAAS2C,EAAIxB,OAAQ0B,GAClBF,CACT,GCIwC,CACtCvC,WAAYggC,GACZ9/B,YAAa,OACbC,UAtCF,SAAeC,GACbs/B,GAAWt/B,EAAQC,KAAKC,MAAM0/B,GAAM,KAAiB,CACnD,SACA,QACA,SACA,SACA,SACA,OACA,SACA,UAEJ,EA4BEz/B,WAxBkC,EAAEE,SAAQL,UAASM,YAC7C,MAAMwC,EAACA,GAAKzC,GACNqU,EAACA,EAACmrB,OAAEA,GAAUv/B,EAEdyC,EAAM/C,EAAQkB,UAAUC,IAAI2B,EAAE1B,QAAQC,GACtCwE,EAAc,IAAItD,WAAW,IAAIC,WAAWM,EAAErB,OAAOgB,QACrDyc,EAAcpc,EAAErB,MAAMS,QAC5Bgd,EAAYA,EAAYxd,OAAS,GAAKgT,EACtC,MAAMorB,EAAY9/B,EAAQoC,WAAW8c,EAAapc,EAAEnC,OAC9Co/B,EAAc//B,EAAQkB,UAAUC,IAAI2+B,EAAU1+B,QAAQC,GACtD2+B,EAAahgC,EAAQoC,WAAW8c,EAAa,SAC7C+gB,EAAejgC,EAAQkB,UAAUC,IAAI6+B,EAAW5+B,QAAQC,GAM9D,OAJAi+B,GACIv8B,EAAK8C,EAAa/C,EAAErB,MAAMC,OAAQlC,GAASsD,EAAEnC,OAAQ+T,EAAGmrB,EACxDE,EAAaE,GAEV,CAACH,EAAWE,EAAW,GCkDK,CAC3CpgC,WAAYsgC,GACZpgC,YAAa,OACbC,UAnFF,SAAeC,GACbu/B,GAAgBv/B,EAAQC,KAAKC,MAAMggC,GAAW,KAAe,CAC3D,SACA,SACA,OACA,SACA,SACA,SACA,SACA,SACA,SACA,QACA,SACA,QACA,SACA,SACA,SACA,SACA,UAEJ,EAgEE//B,WA9DF,SACIC,GAGF,MAAMJ,QAACA,EAAOK,OAAEA,EAAMC,MAAEA,GAASF,GAC3Buc,MAACA,EAAKwjB,WAAEA,GAAc9/B,GACtB+/B,cAACA,EAAaC,SAAEA,EAAQ9N,UAAEA,EAASrT,YAAEA,GAAe5e,GAEnD+hB,EAAOC,EAAaC,EAAYC,GAAe7F,EAAMlb,OACrD0J,EAAWC,GACC,MAAf8T,EAAsBA,EAAc,CAACoD,EAAaC,GAChDhd,EACF,CAAC8c,EAAOlX,EAAWC,EAClBoX,GACC8d,EACF,IAAI/9B,WAAW,IAAIC,WAAWQ,EAAK0L,eAAeiO,EAAMlb,QAAQgB,QAE9D89B,EACF,IAAIh+B,WAAW,IAAIC,WAAWQ,EAAK0L,eAAenJ,IAAW9C,QAE3DN,EAAMnC,EAAQoC,WAAWmD,EAAUoX,EAAMhc,OACzC0B,EAAQrC,EAAQkB,UAAUC,IAAIgB,EAAIf,QAAQC,GAG1C+gB,EADYpiB,EAAQkB,UAAUC,IAAIwb,EAAMvb,QACpBC,GAGpBm/B,EADiBxgC,EAAQkB,UAAUC,IAAIg/B,EAAW/+B,QACpBC,GAE9Bo/B,EAAwC,YAAlBL,EAA8B,EAAI,EAC9D,IAAIM,EACJ,OAAQL,GACN,IAAK,WAYL,QACEK,EAAa,EACb,MAXF,IAAK,UACHA,EAAa,EACb,MACF,IAAK,OACHA,EAAa,EACb,MACF,IAAK,UACHA,EAAa,EAajB,OANAnB,GACInd,EAASoe,EAAeL,EAAW1+B,MAAM,GAAK,EAAI4gB,EAAOlX,EACzDC,EAAUoX,EAAaD,EAAYD,EAAage,EAChD3jB,EAAMlb,MAAMC,OAAS,EAAG6+B,EAAeh7B,EAAS7D,OAAS,EACzD++B,EAAqBC,EAAYnO,EAAWlwB,GAEzCF,CACT,GEmOE2D,GCvSwC,CACxClG,WAAY+gC,GACZ7gC,YAAa,OACbK,WArBF,SACIC,GAEF,MAAMC,OAACA,EAAMC,MAAEA,EAAKN,QAAEA,GAAWI,GAC3B6F,KAACA,GAAQ3F,GACTwC,EAACA,GAAKzC,GAENs2B,aAACA,EAAYzX,YAAEA,EAAWgF,QAAEA,GCT9B,SACF3U,EAAuBtJ,EAAcxE,EAAiBd,GAMxD,MAAM85B,EAAQz3B,EAAKqD,eAAeJ,EAAMxE,GAAO,GAyDzCkC,EAAW,CAAC,EAAGlC,EAAM,GAAI,GAC/B,IAAK,IAAIwD,EAAI,EAAGA,EAAIw1B,EAAOx1B,IACzBtB,EAAS,IAAMlC,EAAMwD,GAEvBtB,EAAS,GAAKlC,EAAMg5B,GACpB,IAAK,IAAIx1B,EAAIw1B,EAAQ,EAAGx1B,EAAIxD,EAAMC,OAAQuD,IACxCtB,EAAS,IAAMlC,EAAMwD,GAKvB,MAAM27B,EAAiB,IAAIC,IAGrB3c,EAAU,IAAI1hB,WAAWf,EAAMg5B,IAE/BqG,EAAc,IAAIC,EAAap9B,EAAUhD,EAAO4O,GAGhDyxB,EAA0B,GAC1BC,EAA6B,IAAhBt9B,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAAK,IAAIsB,EAAI,EAAGA,EAAIxD,EAAMg5B,GAAQx1B,IAAK,CAErC,IAAIi8B,EACJ,GAAID,EAEFC,EAAU3xB,EAAOtK,GAAGk8B,eACf,CACL,MAAMC,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAI19B,EAAS,GAAI09B,IAC/B,IAAK,IAAIjwB,EAAI,EAAGA,EAAIzN,EAAS,GAAIyN,IAC/BgwB,EAAWl8B,KAAK47B,EAAY3/B,IAAIkgC,EAAGp8B,EAAGmM,IAG1C8vB,EAAUE,EAAWE,KAAK,IAC3B,CAGD,MAAMC,EAAgBX,EAAez/B,IAAI+/B,GACzC,GAAqB,MAAjBK,EACFrd,EAAQjf,GAAKs8B,MACR,CACL,MAAMC,EAAcZ,EAAevyB,KACnCuyB,EAAen8B,IAAIy8B,EAASM,GAC5Btd,EAAQjf,GAAKu8B,EACbR,EAAc97B,KAAKD,EACpB,CACF,CAKD,MAAMw8B,EAAiB99B,EAASzB,QAChCu/B,EAAe,GAAKb,EAAevyB,KACnC,MAAMqzB,EAAe,IAAIX,EAAaU,EAAgB9gC,GACtDqgC,EAAcvvB,SAAQ,CAACkwB,EAAoB18B,KACzC,IAAK,IAAIo8B,EAAI,EAAGA,EAAI19B,EAAS,GAAI09B,IAC/B,IAAK,IAAIjwB,EAAI,EAAGA,EAAIzN,EAAS,GAAIyN,IAC/BswB,EAAaj9B,IAAIq8B,EAAY3/B,IAAIkgC,EAAGM,EAAoBvwB,GAAIiwB,EAAGp8B,EAAGmM,EAErE,IAKH,MAAM8N,EAAczd,EAAMS,QAG1B,OAFAgd,EAAYub,GAASgH,EAAe,GAE7B,CACL9K,aAAc+K,EAAanyB,OAC3B2P,cACAgF,UAEJ,CD/HM0d,CAAc5hC,EAAQsE,SAASxB,EAAE1B,QAAS6E,EAAMnD,EAAErB,MAAOqB,EAAEnC,OAE/D,MAAO,CACLX,EAAQoC,WACJ8c,EAAapc,EAAEnC,WAAwBuW,EAAWyf,GACtD32B,EAAQoC,WACJ,CAAC8hB,EAAQxiB,QAAS,aAA0BwV,EAAWgN,GAE/D,GEiB0C,CACxCtkB,WAAYiiC,GACZ/hC,YAAa,OACbK,WAlCF,SACIC,GAEF,MAAMC,OAACA,EAAML,QAAEA,EAAOM,MAAEA,GAASF,GAC3BsR,MAACA,GAASrR,EAChB,IAAI4F,KAACA,GAAQ3F,EAET2F,EAAO,IACTA,GAAQyL,EAAMjQ,MAAMC,QAGtB,MAAMogC,EAAapwB,EAAMjQ,MAAMwE,GACzByN,EAAOhC,EAAMjQ,MAAMC,OACnB6D,EAAqB,IAAIE,MAAMiO,EAAO,GAC5C,IAAIquB,EAAW,EACf,IAAK,IAAI98B,EAAI,EAAGA,EAAIyO,EAAMzO,IACpBA,IAAMgB,IACRV,EAASw8B,KAAcrwB,EAAMjQ,MAAMwD,IAGvC,MAAM+8B,EAAqB,IAAIv8B,MAAMq8B,GAC/B1zB,EAAQ,IAAI3I,MAAMiO,GAAMmO,KAAK,GAC7BxT,EAAOqD,EAAMjQ,MAAMS,QACzBmM,EAAKpI,GAAQ,EACb,IAAK,IAAIhB,EAAI,EAAGA,EAAI+8B,EAAKtgC,OAAQuD,IAC/BmJ,EAAMnI,GAAQhB,EACd+8B,EAAK/8B,GAAK/C,GAAM,CAAC7B,OAAQ,CAACyC,EAAG4O,GAAQpR,MAAO,CAAC8N,QAAOC,QAAOrO,YAE7D,OAAOgiC,EAAK99B,KAAI,EAAE9C,SAAQT,aAAaS,SAAQT,QAAOc,MAAO8D,KAC/D,GJvB6C,CAC3C3F,WAAYqiC,GACZniC,YAAa,OACbK,WAXF,SAAmBC,GACjB,MAAOC,QAAQyC,EAACA,GAAE9C,QAAEA,GAAWI,EACzB+B,EAAMnC,EAAQoC,WAAWU,EAAErB,MAAOqB,EAAEnC,OAG1C,OAFgBX,EAAQwE,mBAAmBrC,GACnC0f,KAAK,GACN1f,CACT,ICyTA,IAAK,MAAM+/B,KAAgB1C,GACzB2C,GAAeD,GIlUjB,MAAME,GAAMC,KAMZD,GAAIE,aAAa,yBAAyBC,UACxC,IAIE,OAAOC,YAAYC,SAAS,IAAIlgC,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAK,GAAI,EAAI,EAAG,EACpD,EAAG,EAAI,EAAK,GAAK,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,IAAK,GAAI,GAAI,KAIpD,CAFC,MAAO6xB,GACP,OAAO,CACR,KAOHgO,GAAIE,aAAa,gCAAgCC,UAG/C,GAAIH,GAAIjhC,IAAI,WACV,OAAO,EAGT,IAME,OAHA,IAAIuhC,gBAAiBC,MAAMC,YAAY,IAAIC,kBAAkB,IAGtDL,YAAYC,SAAS,IAAIlgC,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,KAInE,CAFC,MAAO6xB,GACP,OAAO,CACR,mSC7DH,IACM0O,EADFC,GACED,EAAiC,oBAAbE,UAA4BA,SAASC,cAAgBD,SAASC,cAAcC,SAAMhsB,EAChF,oBAAfisB,aAA4BL,EAAaA,GAAcK,YAClE,SACOJ,GAGT,SAASK,IAA+F,OAAzEC,EAAW5gC,QAAQA,GAAQ6gC,EAA2BD,EAAW5gC,QAAe8gC,CAAK,CAAC,SAASC,IAA+F,OAAzEH,EAAW5gC,QAAQA,GAAQ6gC,EAA2BD,EAAW5gC,QAAeiqB,CAAM,CAAwH,SAAS+W,IAAgG,OAAzEJ,EAAW5gC,QAAQA,GAAQ6gC,EAA2BD,EAAW5gC,QAAeihC,CAAM,CAAC,SAASC,IAAgG,OAAzEN,EAAW5gC,QAAQA,GAAQ6gC,EAA2BD,EAAW5gC,QAAemhC,CAAO,CAAyH,SAASC,IAAgG,OAAzER,EAAW5gC,QAAQA,GAAQ6gC,EAA2BD,EAAW5gC,QAAeqhC,CAAO,CAAC,IAAkGC,EAAoBC,EAAoIC,EAAtPC,EAA6C,oBAFh3BnB,EAAgCA,GAAiC,IAE2zBA,EAA8B,CAAE,EAA4CmB,EAAc,MAAE,IAAIC,SAAQ,SAASC,EAAQC,GAAQN,EAAoBK,EAAQJ,EAAmBK,CAAM,IAA2C,oBAAVC,SAAuBA,QAAQC,YAAWN,EAAgB,CAACO,kBAAkBF,QAAQC,UAAU,qBAAqBE,mBAAmBH,QAAQC,UAAU,wBAAuB,IAAilBG,EAAMC,EAAUC,EAA7lBC,EAAgBC,OAAOC,OAAO,CAAA,EAAGb,GAA+Dc,EAAM,CAACC,EAAOC,KAAW,MAAMA,GAAaC,EAAkC,iBAARC,OAAqBC,EAA4C,mBAAfC,cAA8BC,EAAoC,iBAATjB,SAA4C,iBAAlBA,QAAQkB,UAAkD,iBAAvBlB,QAAQkB,SAASC,KAAmBC,EAAuBxB,EAA+B,yBAAG,EAAUyB,EAAgB,GAAG,SAASC,EAAWC,GAAM,OAAG3B,EAAmB,WAAUA,EAAmB,WAAE2B,EAAKF,GAAwBA,EAAgBE,CAAI,CAAoK,GAAGN,EAAoB,CAAC,IAAIO,EAAGC,GAAkBC,EAASC,GAAojC,IAAIC,EAA9gCP,EAAvBN,EAAuCW,EAASG,QAAQR,GAAiB,IAAyBS,UAAU,IAAI1B,EAAM,CAAC2B,EAASC,KAAUD,EAASE,GAAUF,GAAU,IAAIG,IAAIH,GAAUL,EAASS,UAAUJ,GAAiBP,EAAGY,aAAaL,EAASC,OAAOpvB,EAAU,SAAS0tB,EAAWyB,IAAW,IAAIM,EAAIjC,EAAM2B,GAAS,GAA8C,OAApCM,EAAIlkC,SAAQkkC,EAAI,IAAIpkC,WAAWokC,IAAYA,GAAKhC,EAAU,CAAC0B,EAASO,EAAOC,KAAWR,EAASE,GAAUF,GAAU,IAAIG,IAAIH,GAAUL,EAASS,UAAUJ,GAAUP,EAAGgB,SAAST,GAAS,SAASU,EAAIt2B,GAASs2B,EAAIF,EAAQE,GAAUH,EAAOn2B,EAAKhO,OAAO,GAAE,EAAK6hC,QAAc,KAAE5iC,OAAO,GAAe4iC,QAAc,KAAE,GAAG0C,QAAQ,MAAM,KAAgB1C,QAAc,KAAEpiC,MAAM,GAAGoiC,QAAY,GAAE,qBAAoB,SAAS2C,GAAI,KAAKA,aAAcC,IAAa,MAAMD,CAAG,IAAG3C,QAAY,GAAE,sBAAqB,SAAS6C,GAAQ,MAAMA,CAAM,IAAGnC,EAAM,CAACC,EAAOC,KAAW,GAAGkC,IAA+C,MAA3B9C,QAAkB,SAAEW,EAAaC,EAArmC,IAA4B9Q,KAAomC8Q,aAAjlCgC,IAA8BH,EAAI,6BAAN3S,GAA8jCkQ,QAAc,KAAEW,IAASf,EAAgB,QAAE,WAAW,MAAM,4BAA4B,EAAwB,IAAIgC,EAAkBmB,QAAQ,iBAA2J,CAAzI,MAAMjT,GAA4H,MAAzHkT,QAAQC,MAAM,2GAAiHnT,CAAC,CAACoT,GAAOC,OAAOvB,EAAkBuB,MAAM,MAAStC,GAAoBE,KAA0BA,EAAuBM,EAAgB+B,KAAKC,SAASC,KAA8B,oBAAV5E,UAAuBA,SAASC,gBAAe0C,EAAgB3C,SAASC,cAAcC,KAA6B,oBAAfJ,GAA8BA,IAAY6C,EAAgB7C,GAAoD6C,EAAH,IAAnCA,EAAgB7yB,QAAQ,SAA8B6yB,EAAgBkC,OAAO,EAAElC,EAAgBqB,QAAQ,SAAS,IAAIc,YAAY,KAAK,GAAwB,GAAOvC,IAAqBb,EAAMqD,IAAM,IAAIC,EAAI,IAAIC,eAAwD,OAAzCD,EAAIE,KAAK,MAAMH,GAAI,GAAOC,EAAIG,KAAK,MAAaH,EAAII,cAAiB/C,IAAuBT,EAAWmD,IAAM,IAAIC,EAAI,IAAIC,eAAuF,OAAxED,EAAIE,KAAK,MAAMH,GAAI,GAAOC,EAAIK,aAAa,cAAcL,EAAIG,KAAK,MAAa,IAAI5lC,WAAWylC,EAAIM,SAAQ,GAAG3D,EAAU,CAACoD,EAAInB,EAAOC,KAAW,IAAImB,EAAI,IAAIC,eAAeD,EAAIE,KAAK,MAAMH,GAAI,GAAMC,EAAIK,aAAa,cAAcL,EAAIpB,OAAO,KAAoB,KAAZoB,EAAI/C,QAAyB,GAAZ+C,EAAI/C,QAAW+C,EAAIM,SAAU1B,EAAOoB,EAAIM,UAAiBzB,GAAO,EAAImB,EAAInB,QAAQA,EAAQmB,EAAIG,KAAK,SAA2D5C,GAA4C,oBAAbgD,cAA0Bf,GAAOe,YAAYC,GAAsBD,aAAa,IAAIE,EAAanB,QAAQoB,IAAIC,KAAKrB,SAAasB,EAAgBtB,QAAQuB,KAAKF,KAAKrB,SAAY/B,IAAqBkD,EAAaj3B,GAAKs0B,EAAGgD,UAAU,EAAEt3B,EAAI,MAAMo3B,EAAgBp3B,GAAKs0B,EAAGgD,UAAU,EAAEt3B,EAAI,OAAM,IAA8au3B,EAA1a5mC,EAAI+hC,EAAc,OAAGuE,EAAiB1B,EAAI7C,EAAiB,UAAG0E,EAAgB9D,OAAOC,OAAOb,EAAOW,GAAiBA,EAAgB,KAAQX,EAAkB,WAAaA,EAAkB,UAAKA,EAAoB,aAAcA,EAAoB,YAAKA,EAAa,OAAEc,EAAMd,EAAa,MAAyJA,EAAmB,aAAE6E,EAAW7E,EAAmB,YAAE,IAA8Hb,EAAe2F,EAAzIC,EAAc/E,EAAsB,gBAAG,EAA4B,iBAAb1B,aAAuB0G,EAAM,mCAAiE,IAAoBC,EAAs8D1mC,EAAO8gC,EAAM7W,EAAsBgX,EAAOE,EAAgBE,EAAhhEsF,GAAM,EAAqFC,EAAgC,oBAAbC,YAAyB,IAAIA,YAAY,aAAQpyB,EAAU,SAASqyB,EAAkBC,EAAYn6B,EAAIo6B,GAAsE,IAA7C,IAAIC,GAAbr6B,KAAO,GAAiBo6B,EAAmBE,EAAOt6B,EAAUm6B,EAAYG,MAAWA,GAAQD,MAAUC,EAAO,GAAGA,EAAOt6B,EAAI,IAAIm6B,EAAY/mC,QAAQ4mC,EAAa,OAAOA,EAAYO,OAAOJ,EAAY/mC,kBAAkBogC,kBAAkB2G,EAAYtnC,MAAMmN,EAAIs6B,GAAQH,EAAY36B,SAASQ,EAAIs6B,IAAoB,IAAX,IAAIn4B,EAAI,GAASnC,EAAIs6B,GAAO,CAAC,IAAIE,EAAGL,EAAYn6B,KAAO,GAAQ,IAAHw6B,EAAL,CAAoD,IAAIC,EAAsB,GAAnBN,EAAYn6B,KAAU,GAAa,MAAN,IAAHw6B,GAAJ,CAAmE,IAAIE,EAAsB,GAAnBP,EAAYn6B,KAA0G,IAA9Ew6B,EAAL,MAAN,IAAHA,IAAqB,GAAHA,IAAQ,GAAGC,GAAI,EAAEC,GAAe,EAAHF,IAAO,GAAGC,GAAI,GAAGC,GAAI,EAAqB,GAAnBP,EAAYn6B,MAAgB,MAAOmC,GAAKw4B,OAAOC,aAAaJ,OAAQ,CAAC,IAAIK,EAAGL,EAAG,MAAMr4B,GAAKw4B,OAAOC,aAAa,MAAMC,GAAI,GAAG,MAAS,KAAHA,EAAQ,CAAjP,MAAhD14B,GAAKw4B,OAAOC,cAAiB,GAAHJ,IAAQ,EAAEC,EAApF,MAArCt4B,GAAKw4B,OAAOC,aAAaJ,EAA8V,CAAC,OAAOr4B,CAAG,CAAunC,SAAS8xB,EAA2B6G,GAAK1nC,EAAO0nC,EAAIjG,EAAc,MAAEX,EAAM,IAAI6G,UAAUD,GAAKjG,EAAe,OAAS,IAAImG,WAAWF,GAAKjG,EAAe,OAAER,EAAO,IAAIlhC,WAAW2nC,GAAKjG,EAAe,OAAExX,EAAO,IAAInqB,WAAW4nC,GAAKjG,EAAgB,QAAU,IAAIoG,YAAYH,GAAKjG,EAAgB,QAAEN,EAAQ,IAAI2G,YAAYJ,GAAKjG,EAAgB,QAAU,IAAIsG,aAAaL,GAAKjG,EAAgB,QAAEJ,EAAQ,IAAI2G,aAAaN,EAAI,CAA9czE,IAAwBjjC,EAAOyhC,EAAe,QAAia,IAAu2BwG,EAAn2BC,EAAezG,EAAuB,gBAAG,SAAS,GAAGwB,EAAwBrC,EAAWa,EAAmB,WAAEzhC,EAAOyhC,EAAe,YAAO,GAAGA,EAAmB,WAAGb,EAAWa,EAAmB,gBAAoH,MAA7Gb,EAAW,IAAIb,YAAYoI,OAAO,CAACC,QAAUF,EAAe,MAAMG,QAAU,MAAiBC,QAAS,KAAuBtoC,kBAAkBogC,mBAAgY,MAA5WkE,EAAI,+NAAkOxB,GAAqBwB,EAAI,6GAAmHnmC,MAAM,cAAmByiC,IAAY5gC,EAAO4gC,EAAW5gC,QAAOkoC,EAAeloC,EAAOuoC,WAAW1H,EAA2B7gC,GAAsB,IAAIwoC,EAAa,GAAOC,EAAW,GAAOC,EAAc,GAAgC,SAAS/D,IAAmB,OAAO6B,CAAa,CAA4N,SAASmC,IAAyC1F,GAA8B2F,GAAqBH,EAAW,CAA0Z,IAA6/BI,EAAz/BC,EAAgB,EAAoCC,EAAsB,KAAif,SAAStC,EAAMuC,GAASvH,EAAgB,SAAGA,EAAgB,QAAEuH,GAA+B1E,EAAzB0E,EAAK,WAAWA,EAAK,KAAcrC,GAAM,EAAKD,EAAW,EAAEsC,GAAM,2CAA2C,IAAIrX,EAAE,IAAIoO,YAAYkJ,aAAaD,GAA4B,MAAtBzH,EAAmB5P,GAASA,CAAC,CAA2D,SAASuX,GAAUtF,GAAU,OAAOA,EAASuF,WAArF,wCAA8G,CAAC,SAASrF,GAAUF,GAAU,OAAOA,EAASuF,WAAW,UAAU,CAAmJ,SAASC,GAAUC,GAAM,IAAI,GAAGA,GAAMR,GAAgBvC,EAAY,OAAO,IAAIxmC,WAAWwmC,GAAY,GAAGnE,EAAY,OAAOA,EAAWkH,GAAM,KAAK,iDAAuE,CAArB,MAAM/E,GAAKmC,EAAMnC,EAAI,CAAC,CAA7R4E,GAA1DL,EAAe,0CAAsEA,EAAe1F,EAAW0F,IAA8uF,IAAIS,GAAW,GAAG,SAAS7E,GAAWjC,GAAQh1B,KAAK+7B,KAAK,aAAa/7B,KAAKg8B,QAAQ,gCAAgChH,EAAO,IAAIh1B,KAAKg1B,OAAOA,CAAM,CAA4X,SAASiH,GAAcC,GAAa,IAA5iRC,EAAgjRC,EAAOC,GAAQC,SAASJ,GAAoBE,GAAvkRnD,EAAMkD,GAAykRE,GAAQE,mBAAmBH,EAAO,CAAC,SAASI,GAAYC,GAAc,IAAIL,EAAOC,GAAQK,eAAe,IAAIN,EAAQ,OAAO,EAAEC,GAAQM,eAAe1nC,KAAKmnC,GAAQC,GAAQC,SAASG,EAAaP,aAAaE,EAAOA,EAAOF,YAAYO,EAAaP,YAAY,IAAIU,EAAI,CAACC,IAAM,MAAMC,cAAgBL,EAAaM,aAAaC,IAAMP,EAAaO,IAAId,YAAcO,EAAaP,aAA2L,OAA9KE,EAAOa,WAAW,KAAQ3H,GAAqB8G,EAAOc,MAAMd,EAAOzJ,YAAYiK,EAAIH,EAAaU,qBAAqBf,EAAOa,YAAeb,EAAOgB,QAAQhB,EAAOa,aAAoB,CAAC,CAAgM,SAASI,GAAWC,GAAM,GAAG7H,EAAuB,OAAO8H,GAAoC,EAAE,EAAED,GAAMpE,EAAWoE,EAASnG,MAAoBkF,GAAQmB,sBAAyBvJ,EAAe,QAAEA,EAAe,OAAEqJ,GAAMnE,GAAM,GAAKpE,EAAMuI,EAAK,IAAIrG,GAAWqG,GAAM,CAA8J,IAAIG,GAAjK,SAAgBzI,EAAO0I,GAA4B,GAAlBxE,EAAWlE,GAAW0I,GAAajI,EAAiD,MAAzBkI,GAAiB3I,GAAa,SAAgBqI,GAAWrI,EAAO,EAAwHqH,GAAQ,CAACuB,cAAc,GAAGjB,eAAe,GAAGkB,iBAAiB,GAAGvB,SAAS,GAAGwB,KAAK,WAAcrI,EAAwB4G,GAAQ0B,aAAkB1B,GAAQ2B,gBAAiB,EAAEA,eAAe,WAAiC,IAAtB,IAAIC,EAAgB,EAAQA,KAAmB5B,GAAQ6B,sBAAuB,EAAEH,WAAW,WAAW/E,GAAc,CAAK,EAAEmF,cAAc,SAASnJ,GAAQkE,EAAWlE,CAAM,EAAEwI,oBAAoB,WAAW,IAAI,IAAIpB,KAAUvH,OAAOv1B,OAAO+8B,GAAQC,UAAWD,GAAQE,mBAAmBH,GAAQ,IAAI,IAAIA,KAAUC,GAAQuB,cAAexB,EAAOgC,YAAY/B,GAAQuB,cAAc,EAAE,EAAErB,mBAAmB,SAASH,GAAQ,IAAIF,EAAYE,EAAOF,mBAAmBG,GAAQC,SAASJ,GAAaG,GAAQuB,cAAc3oC,KAAKmnC,GAAQC,GAAQM,eAAeprB,OAAO8qB,GAAQM,eAAe95B,QAAQu5B,GAAQ,GAAGA,EAAOF,YAAY,EAAK5G,GAAqB8G,EAAOiC,QAAQC,GAA8BpC,EAAY,EAAEqC,sBAAsB,SAAS/9B,KAAQg+B,cAAc,WAAWnC,GAAQwB,iBAAiBr8B,SAAQoB,GAAGA,KAAI,EAAE67B,uBAAuB,SAASrC,EAAOsC,GAAmBtC,EAAOuC,UAAUxa,IAAI,IAA1/E+X,EAA8/E0C,EAAEza,EAAQ,KAAM0Y,EAAI+B,EAAO,IAAuF,GAAlFxC,EAAOF,cAAYG,GAAQwC,oCAAoCzC,EAAOF,aAAe0C,EAAgB,cAAGA,EAAgB,cAAGE,KAAgB,CAAC,IAAIC,EAAa1C,GAAQC,SAASsC,EAAEI,cAA0Q,OAAzPD,EAAcA,EAAapM,YAAYiM,EAAEA,EAAgB,cAAQ9H,EAAI,0CAA0C+F,EAAI,uBAAuB+B,EAAgB,aAAE,4CAAuCvC,GAAQwC,yCAAoC53B,EAAgB,CAAU,yBAAN41B,EAA8BoC,GAA6BL,EAAS,OAAiB,gBAAN/B,EAAqBL,GAAYoC,GAAiB,kBAAN/B,EAAuBZ,GAAc2C,EAAU,QAAiB,eAAN/B,EAAv7G,SAAoBX,GAAa,IAAIE,EAAOC,GAAQC,SAASJ,UAAoBG,GAAQC,SAASJ,GAAaE,EAAOgC,YAAYE,GAA8BpC,GAAaG,GAAQM,eAAeprB,OAAO8qB,GAAQM,eAAe95B,QAAQu5B,GAAQ,GAAGA,EAAOF,YAAY,CAAC,CAAksGgD,CAAWN,EAAU,QAAiB,iBAAN/B,GAA3sGX,EAA8uG0C,EAAU,OAAhuGvC,GAAQC,SAASJ,GAAoBvJ,YAAY,CAACkK,IAAM,YAAyrG,WAANA,GAAgBT,EAAOgB,QAAO,EAAQ9H,GAAqB8G,EAAOiC,QAAWK,GAAkBA,EAAkBtC,GAAWA,EAAOa,YAAYb,EAAOa,cAA4B,UAANJ,EAAe3qC,EAAI,UAAU0sC,EAAY,SAAE,KAAKA,EAAQ,MAAiB,aAAN/B,EAAkB/F,EAAI,UAAU8H,EAAY,SAAE,KAAKA,EAAQ,MAAiB,UAAN/B,EAAesC,MAAM,UAAUP,EAAY,SAAE,KAAKA,EAAQ,MAAsB,iBAAXA,EAAEQ,OAAyBhD,EAAOzJ,YAAYiM,GAAiB,gBAAN/B,EAAqB5I,EAAO2K,EAAW,YAAMA,EAAQ,MAAW/B,GAAK/F,EAAI,kCAAkC+F,GAAKR,GAAQwC,yCAAoC53B,CAAS,EAAEm1B,EAAOxF,QAAQzS,IAAgG,MAAxD2S,EAAIkF,yBAAY7X,EAAEiS,SAAS,IAAIjS,EAAEkb,OAAO,KAAKlb,EAAE6X,SAAe7X,GAAMmR,IAAqB8G,EAAOkD,GAAG,WAAU,SAAS9+B,GAAM47B,EAAOuC,UAAU,CAACn+B,KAAKA,GAAM,IAAG47B,EAAOkD,GAAG,SAAQ,SAASnb,GAAGiY,EAAOxF,QAAQzS,EAAE,IAAGiY,EAAOkD,GAAG,gBAAe,gBAAc,IAAIC,EAAS,GAA6D,IAAI,IAAIC,IAAhD,CAAC,SAAS,UAAU,QAAQ,YAAiDvL,EAAOwL,eAAeD,IAAUD,EAAStqC,KAAKuqC,GAAUpD,EAAOzJ,YAAY,CAACkK,IAAM,OAAO0C,SAAWA,EAASG,UAAYzL,EAA4B,qBAAGpB,EAAWO,WAAaA,EAAW2F,WAAaA,GAAY,EAAEmF,qBAAqB,WAAW,IAAI9B,EAAWuD,EAAchK,EAAW,6CAA6CyG,EAAO,IAAI5E,OAAOmI,GAAetD,GAAQuB,cAAc3oC,KAAKmnC,EAAO,EAAEM,aAAa,WAAuI,OAA3F,GAA9BL,GAAQuB,cAAcnsC,SAAW4qC,GAAQ6B,uBAAuB7B,GAAQoC,uBAAuBpC,GAAQuB,cAAc,KAAWvB,GAAQuB,cAAcgC,KAAK,GAA6B,SAASxE,GAAqByE,GAAW,KAAMA,EAAUpuC,OAAO,GAAGouC,EAAUC,OAAVD,CAAkB5L,EAAQ,CAAoU,SAAS0J,GAAiBoC,GAAY,GAAGtK,EAAuB,OAAO8H,GAAoC,EAAE,EAAEwC,GAAY,IAAItC,GAAMsC,EAAuC,CAA3B,MAAM5b,IAArjI,SAAyBA,GAAG,GAAGA,aAAa8S,IAAe,UAAH9S,EAAa,OAAO+U,EAAWnE,EAAM,EAAE5Q,EAAE,CAAu9H6b,CAAgB7b,EAAE,CAAC,CAAxmB8P,EAAgB,QAAEoI,GAAuXpI,EAA4B,oBAA7S,WAA+B,IAAIiI,EAAY4C,KAAoBmB,EAASzM,IAAoB0I,EAAY,KAAK,GAAOgE,EAAU1M,IAAoB0I,EAAY,KAAK,GAAmCiE,GAA6BF,EAAhDA,EAASC,GAA0DE,GAAaH,EAAS,EAAiO,IAAsqGI,GAAlqGC,GAAgB,GAAqyB,SAASC,GAAqBrE,EAAYsE,EAAKzD,EAAaC,GAAK,OAAGvH,EAA8B8H,GAAoC,EAAE,EAAErB,EAAYsE,EAAKzD,EAAaC,GAAYyD,GAAqBvE,EAAYsE,EAAKzD,EAAaC,EAAI,CAAC,SAASyD,GAAqBvE,EAAYsE,EAAKzD,EAAaC,GAAK,GAA6B,oBAAnBpK,kBAA2H,OAA3FkE,EAAI,uFAA8F,EAAE,IAAIqG,EAAa,GAAe,GAAG1H,GAA+C,IAAtB0H,EAAa1rC,OAAoB,OAAO8uC,GAAqBrE,EAAYsE,EAAKzD,EAAaC,GAA2B,IAAIP,EAAa,CAACM,aAAaA,EAAab,YAAYA,EAAYc,IAAIA,EAAIG,aAAaA,GAAc,OAAG1H,GAAwBgH,EAAaI,IAAI,cAAclK,YAAY8J,EAAaU,GAAqB,GAASX,GAAYC,EAAa,CAA4J,SAASwC,GAA6ByB,GAAOC,QAAQC,MAAMpN,IAAoBkN,GAAO,EAAE,GAAM5B,MAAiB+B,GAAsCH,GAAOC,QAAQG,gBAAgBtN,IAAoBkN,GAAO,EAAE,EAAE,EAAE,CAAimB,SAASK,GAAS5E,GAAU4E,GAASC,QAAMD,GAASC,MAAM,CAAE,GAAKD,GAASC,MAAM7E,KAAO4E,GAASC,MAAM7E,GAAM,EAAK7G,IAAoB6G,EAAK,YAAYA,GAAKrF,EAAIqF,GAAM,CAA40B,SAAS8E,GAAcr+B,GAAG,IAAIs+B,EAAMC,KAAgBzK,EAAI9zB,IAAwB,OAApBw9B,GAAac,GAAcxK,CAAG,CAAC,SAAS6G,GAAoCvoB,EAAMosB,GAAM,IAAIC,EAAYC,UAAU7vC,OAAO,EAAM8vC,EAAUD,UAAU,OAAOL,IAAc,KAAsG,IAAjG,IAAIO,EAAsBH,EAAgBlxC,EAAKsxC,GAAiC,EAAtBD,GAA6BjxC,EAAEJ,GAAM,EAAU6E,EAAE,EAAEA,EAAEqsC,EAAYrsC,IAAI,CAAC,IAAIgoC,EAAIuE,EAAU,EAAEvsC,GAAG4+B,IAAoBrjC,EAAEyE,IAAI,GAAGgoC,CAAG,CAAC,OAAO0E,GAA0C1sB,EAAMwsB,EAAsBrxC,EAAKixC,EAAI,GAAG,CAAlsHnN,EAAyB,iBAA/L,SAA0B0N,EAAI3E,GAAK,IAA7N4E,EAAaC,EAAoNn/B,IAApNm/B,EAAKvB,GAAlBsB,EAA0PD,MAAlMC,GAAStB,GAAgB7uC,SAAO6uC,GAAgB7uC,OAAOmwC,EAAQ,GAAEtB,GAAgBsB,GAASC,EAAKpH,EAAUvpC,IAAI0wC,IAAgBC,GAA0E7E,GAAQ7F,IAAoBkF,GAAQ8B,cAAcz7B,GAAao/B,GAAyBp/B,EAAQ,EAAwnDuxB,EAAqC,6BAAEgL,GAAkqCoB,GAArB/K,EAAyC,KAAK,IAAIztB,EAAEwsB,QAAgB,SAAI,OAAY,IAALxsB,EAAE,GAAOA,EAAE,GAAG,KAA8B,IAAIywB,YAAYyJ,WAAWzJ,YAAY0J,MAAsvB,IAAIC,GAA+C,GAAgb,SAASC,GAA0B9jC,GAAM,IAAqG,OAAjGg1B,EAAW+O,KAAK/jC,EAAK5L,EAAOuoC,WAAW,QAAQ,IAAI1H,EAA2BD,EAAW5gC,QAAe,CAAU,CAAR,MAAM2xB,GAAE,CAAE,CAAmrB,SAASie,GAAUC,GAAI,OAAG5M,EAA8B8H,GAAoC,EAAE,EAAE8E,GAAW,EAAE,CAAC,SAASC,GAASD,EAAGE,EAAWC,EAAYC,EAAOC,GAAW,OAAGjN,EAA8B8H,GAAoC,EAAE,EAAE8E,EAAGE,EAAWC,EAAYC,EAAOC,GAAkB,EAAE,CAAC,IAAIC,GAAiB,CAAC,KAAK,GAAG,IAAI,SAASC,GAAUC,EAAOC,GAAM,IAAItwC,EAAOmwC,GAAiBE,GAAkB,IAAPC,GAAiB,KAAPA,IAAqB,IAATD,EAAW3wC,EAAI4kC,GAAKwC,EAAkB9mC,EAAO,IAAIA,EAAOf,OAAO,GAAOe,EAAOyC,KAAK6tC,EAAM,CAAC,SAASC,GAAUV,EAAGW,EAAIC,EAAOC,GAAM,GAAGzN,EAAuB,OAAO8H,GAAoC,EAAE,EAAE8E,EAAGW,EAAIC,EAAOC,GAAgB,IAAV,IAAIlsB,EAAI,EAAUhiB,EAAE,EAAEA,EAAEiuC,EAAOjuC,IAAI,CAAC,IAAI2sC,EAAIjO,IAAoBsP,IAAM,GAAOG,EAAIzP,IAAoBsP,EAAI,IAAI,GAAGA,GAAK,EAAE,IAAI,IAAI7tC,EAAE,EAAEA,EAAEguC,EAAIhuC,IAAKytC,GAAUP,EAAG9O,IAAmBoO,EAAIxsC,IAAI,IAAI6hB,GAAKmsB,CAAG,CAAmC,OAAlCzP,IAAoBwP,IAAO,GAAGlsB,EAAW,CAAC,CAAC,SAASosB,GAASC,GAAkC,OAAlBpP,EAAO,IAAIoP,EAAkB,CAAoF,SAASC,GAAMD,EAAME,EAAWC,EAASrzC,EAAKszC,GAAM,IAAIC,EAAI,CAACC,OAASpiC,IAAM,IAAIm1B,EAAI,EAAE,GAAGn1B,SAAmC,IAANA,EAAQ,CAAC,IAAI4hC,EAAoB,GAAf5hC,EAAI9P,QAAQ,IAA5llB,SAAsB8P,EAAIqiC,EAAOC,IAA1yB,SAA2BtiC,EAAIuiC,EAAKC,EAAOF,GAA6B,KAAKA,EAAgB,GAAG,OAAO,EAA3CE,KAAU,EAA2F,IAAxD,IAAwBtK,EAAOsK,EAAOF,EAAgB,EAAU7uC,EAAE,EAAEA,EAAEuM,EAAI9P,SAASuD,EAAE,CAAC,IAAIgvC,EAAEziC,EAAI0iC,WAAWjvC,GAAoF,GAA9EgvC,GAAG,OAAOA,GAAG,QAAkCA,EAAE,QAAU,KAAFA,IAAS,IAAO,KAA9CziC,EAAI0iC,aAAajvC,IAAqCgvC,GAAG,IAAI,CAAC,GAAGD,GAAQtK,EAAO,MAAMqK,EAAKC,MAAW,GAAGC,CAAC,MAAM,GAAGA,GAAG,KAAK,CAAC,GAAGD,EAAO,GAAGtK,EAAO,MAAMqK,EAAKC,MAAW,GAAG,IAAIC,GAAG,EAAEF,EAAKC,MAAW,GAAG,IAAM,GAAFC,CAAI,MAAM,GAAGA,GAAG,MAAM,CAAC,GAAGD,EAAO,GAAGtK,EAAO,MAAMqK,EAAKC,MAAW,GAAG,IAAIC,GAAG,GAAGF,EAAKC,MAAW,GAAG,IAAIC,GAAG,EAAE,GAAGF,EAAKC,MAAW,GAAG,IAAM,GAAFC,CAAI,KAAK,CAAC,GAAGD,EAAO,GAAGtK,EAAO,MAAMqK,EAAKC,MAAW,GAAG,IAAIC,GAAG,GAAGF,EAAKC,MAAW,GAAG,IAAIC,GAAG,GAAG,GAAGF,EAAKC,MAAW,GAAG,IAAIC,GAAG,EAAE,GAAGF,EAAKC,MAAW,GAAG,IAAM,GAAFC,CAAI,CAAC,CAACF,EAAKC,IAAS,GAAG,CAAwB,CAA0DG,CAAkB3iC,EAAIgyB,IAAmBqQ,EAAOC,EAAgB,CAA4/kBM,CAAa5iC,EAAjCm1B,EAAI+K,GAAW0B,GAA0BA,EAAI,CAAC,OAAOzM,GAAK0N,MAAQC,IAAM,IAAI3N,EAAI+K,GAAW4C,EAAI5yC,QAAoC,OAA/W,SAA4B2yC,EAAM5xC,GAAQ2gC,IAAmB3+B,IAAI4vC,EAAM5xC,IAAS,EAAE,CAAiQ8xC,CAAmBD,EAAI3N,GAAYA,IAAM,SAAS6N,EAAmB7N,GAAK,MAAgB,WAAb6M,GAAlonB5B,EAA6qnBjL,GAAzpnBiL,KAAO,GAAarI,EAAkB/F,IAAmBoO,EAAInI,GAAgB,IAAimnB,YAAb+J,EAA8BiB,QAAQ9N,GAAYA,EAA7vnB,IAAsBiL,EAAInI,CAAsunB,CAAC,IAAIqI,EAAKuB,GAASC,GAAWoB,EAAM,GAAOvD,EAAM,EAAE,GAAG/wC,EAAM,IAAI,IAAI6E,EAAE,EAAEA,EAAE7E,EAAKsB,OAAOuD,IAAI,CAAC,IAAI0vC,EAAUhB,EAAIF,EAASxuC,IAAO0vC,GAAsB,IAARxD,IAAUA,EAAMC,MAAYsD,EAAMzvC,GAAG0vC,EAAUv0C,EAAK6E,KAASyvC,EAAMzvC,GAAG7E,EAAK6E,EAAG,CAAE,IAAI0hC,EAAImL,EAAK8C,MAAM,KAAKF,GAA4G,OAAhB/N,EAArF,SAAgBA,GAAsC,OAAtB,IAARwK,GAAUd,GAAac,GAAcqD,EAAmB7N,EAAI,CAAKkO,CAAOlO,EAAe,CAAuT2F,GAAQyB,OAAO,IAAI+G,GAAqB,CAAC,KAAKxH,GAAWM,GAAiB4C,GAAqB6B,GAAUE,GAASS,IAAe+B,GAAc,CAACC,iCAA1mO,SAA2CC,GAAIC,GAAyBD,GAAI5P,EAAsB,GAAGF,GAAoBmH,GAAQmC,eAAe,EAA+hO0G,4BAA9hO,SAAsCC,GAAY1P,EAAkD9C,YAAY,CAACkK,IAAM,gBAAgBsI,OAASA,IAAvElJ,GAAckJ,EAAiE,EAAi8NC,oBAAsB3E,GAAqB4E,uCAA5oM,WAAmD,OAAO,KAAK,EAA8pMC,iCAAroM,WAA6C,OAAlD,CAAuE,EAAwoMC,8BAA72L,SAAwCC,EAAeC,EAAaC,EAAahF,GAAO,GAAG8E,GAAgBC,EAAcE,YAAW,IAAI1G,GAA6ByB,UAAa,GAAGjL,EAAwB9C,YAAY,CAACqM,aAAewG,EAAe3I,IAAM,uBAAuB6D,MAAQA,QAAY,CAAC,IAAItE,EAAOC,GAAQC,SAASkJ,GAAgB,IAAIpJ,EAAQ,OAAOA,EAAOzJ,YAAY,CAACkK,IAAM,uBAAuB6D,MAAQA,GAAO,CAAC,OAAO,CAAC,EAA0/KkF,qCAAz/K,SAA+CxG,EAAOyG,EAAMC,GAAQ,OAAO,CAAC,EAA0/K7M,MAAz/K,WAAkBA,EAAM,GAAG,EAA6+K8M,kCAAt0K,WAAiDzQ,GAA8BF,GAA6B2L,GAAS,2IAA2I,EAA6oKiF,oBAA5oK,WAAgC,OAAOC,KAAKjE,KAAK,EAAsoKkE,wBAA7lK,WAAoC,OAA/C,UAAkE,EAAylKC,mBAAqB9F,GAAoB+F,sBAA97J,SAAgCC,EAAKpT,EAAIjc,GAAKuc,IAAmB+S,WAAWD,IAAO,EAAEpT,IAAM,EAAEA,EAAIjc,IAAM,EAAE,EAAo4JuvB,6BAAn4J,WAAyC,OAAGjR,EAA2BkR,GAAcC,OAAOh1C,OAAci1C,UAA+B,mBAAC,EAAszJC,qCAApwI,SAA+C3xB,EAAMqsB,EAAYlxC,GAAM8xC,GAA+CxwC,OAAO4vC,EAA0B,IAAd,IAAI9wC,EAAEJ,GAAM,EAAU6E,EAAE,EAAEA,EAAEqsC,EAAYrsC,IAAKitC,GAA+CjtC,GAAG4+B,IAAoBrjC,EAAEyE,IAAI,GAAoG,OAAhFggB,EAAM,EAAqD8mB,IAAY9mB,EAAM,GAA9C6vB,GAAqB7vB,IAAwC2vB,MAAM,KAAK1C,GAA+C,EAAq6H2E,uBAAlwH,SAAiCC,GAAe,IAAIC,EAAQvT,IAAmB9hC,OAAuC,IAAhCo1C,KAA8B,IAAoBC,EAAS,OAAO,EAAM,IAAqFj0C,EAAEk0C,EAAnFC,EAA7xD,WAAszD,GAAGH,EAAcG,EAAa,OAAO,EAAiE,IAAI,IAAIC,EAAQ,EAAEA,GAAS,EAAEA,GAAS,EAAE,CAAC,IAAIC,EAAkBJ,GAAS,EAAE,GAAGG,GAA6N,GAApNC,EAAkBnpC,KAAKsC,IAAI6mC,EAAkBL,EAAc,WAAsH3E,GAA/FnkC,KAAKsC,IAAI2mC,GAA/Nn0C,EAAmPkL,KAAKC,IAAI6oC,EAAcK,MAAxQH,EAA2R,OAApQl0C,EAAEk0C,GAAUA,IAAmU,OAAO,CAAK,CAAC,OAAO,CAAK,EAA+rGI,mCAA9rG,WAA+C,KAAK,QAAQ,EAA2sGC,KAAO3J,GAAM4J,SAAWjF,GAAUkF,QAAUhF,GAASiF,SAAWxE,GAAUyE,OAASpU,GAAYa,EAAmB,aAAp7gB,WAAsB,IAAIwT,EAAK,CAACrV,IAAM0S,GAAc4C,uBAAyB5C,IAAe,SAAS6C,EAAgBC,EAASC,GAAQ,IAA6jQC,EAAzuUC,EAAgrEC,EAAQJ,EAASI,QAA0M,GAAlM/T,EAAY,IAAE+T,EAAkhQF,EAA1/P7T,EAAY,IAAwB,qBAAm+PoI,GAAQwB,iBAAiB5oC,KAAK6yC,GAA9/PrN,EAAUxG,EAAY,IAA6B,0BAAz0E8T,EAAq1E9T,EAAY,IAAqB,kBAAl3EgH,EAAWgN,QAAQF,GAAk2EhP,EAAW8O,GAAWpS,EAAuB,CAAC,IAAIyS,EAAiB7L,GAAQuB,cAAcnsC,OAAO4qC,GAAQuB,cAAcp8B,SAAQ,SAAS2mC,GAAG9L,GAAQoC,uBAAuB0J,GAAE,aAAiBD,GAA3wE,SAA6B92C,GAA6G,GAAzGkqC,IAAqBrH,EAA+B,wBAAGA,EAA+B,uBAAEqH,GAAqC,GAAjBA,GAAqHC,EAAsB,CAAC,IAAI6M,EAAS7M,EAAsBA,EAAsB,KAAK6M,GAAU,CAAE,CAAy7DC,EAAuC,GAAE,GAAE,CAAC,CAAkE,SAASC,EAA2B5lC,GAAQilC,EAAgBjlC,EAAiB,SAAEA,EAAe,OAAE,CAAC,SAAS6lC,EAAuBC,GAAU,OAA54C,WAA4B,IAAI1P,IAAa5D,GAAoBE,GAAuB,CAAC,GAAiB,mBAAPqT,QAAoBnS,GAAU+E,GAAiB,OAAOoN,MAAMpN,EAAe,CAACqN,YAAY,gBAAgBC,MAAK,SAAStQ,GAAU,IAAIA,EAAa,GAAG,KAAK,uCAAuCgD,EAAe,IAAI,OAAOhD,EAAsB,aAAG,IAAGuQ,OAAM,WAAW,OAAOhN,GAAUP,EAAe,IAAQ,GAAG3G,EAAW,OAAO,IAAIR,SAAQ,SAASC,EAAQC,GAAQM,EAAU2G,GAAe,SAAShD,GAAUlE,EAAQ,IAAI7hC,WAAW+lC,GAAU,GAAEjE,EAAO,GAAI,CAAC,OAAOF,QAAQC,UAAUwU,MAAK,WAAW,OAAO/M,GAAUP,EAAe,GAAE,CAAiyBwN,GAAmBF,MAAK,SAAStS,GAAQ,OAAO9D,YAAYuW,YAAYzS,EAAOoR,EAAK,IAAGkB,MAAK,SAASf,GAAU,OAAOA,CAAQ,IAAGe,KAAKH,GAAS,SAAStR,GAAQJ,EAAI,0CAA0CI,GAAQ+B,EAAM/B,EAAO,GAAE,CAAknB,GAAtiCzB,IAAv7E6F,IAAqBrH,EAA+B,wBAAGA,EAA+B,uBAAEqH,IAAw4GrH,EAAwB,gBAAG,IAAgE,OAAhDA,EAAwB,gBAAEwT,EAAKE,EAA2H,CAA3F,MAAMxjB,GAAG2S,EAAI,sDAAsD3S,GAAG4P,EAAmB5P,EAAE,EAAzxB2U,GAAqD,mBAAlCvG,YAAYwW,sBAAmCrN,GAAUL,IAAkB/E,GAAU+E,IAAkB/F,GAAmC,mBAAPmT,MAAuYF,EAAuBD,GAApYG,MAAMpN,EAAe,CAACqN,YAAY,gBAAgBC,MAAK,SAAStQ,GAAqE,OAAhD9F,YAAYwW,qBAAqB1Q,EAASoP,GAAoBkB,KAAKL,GAA2B,SAASpR,GAAuG,OAA/FJ,EAAI,kCAAkCI,GAAQJ,EAAI,6CAAoDyR,EAAuBD,EAA2B,GAAE,KAAgSM,MAAM7U,EAA4B,CAAykdiV,GAAoC/U,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAA+BrN,EAAiC,yBAAE,WAAW,OAAgCA,EAAiC,yBAAEA,EAAY,IAA2B,yBAAG0Q,MAAM,KAAKrD,UAAU,EAAyBrN,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAuBrN,EAAyB,iBAAE,WAAW,OAAwBA,EAAyB,iBAAEA,EAAY,IAAmB,iBAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAA8BrN,EAAgC,wBAAE,WAAW,OAA+BA,EAAgC,wBAAEA,EAAY,IAA0B,wBAAG0Q,MAAM,KAAKrD,UAAU,EAA6BrN,EAA+B,uBAAE,WAAW,OAA8BA,EAA+B,uBAAEA,EAAY,IAAyB,uBAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAA6BrN,EAA+B,uBAAE,WAAW,OAA8BA,EAA+B,uBAAEA,EAAY,IAAyB,uBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAgCrN,EAAkC,0BAAE,WAAW,OAAiCA,EAAkC,0BAAEA,EAAY,IAA4B,0BAAG0Q,MAAM,KAAKrD,UAAU,EAA+BrN,EAAiC,yBAAE,WAAW,OAAgCA,EAAiC,yBAAEA,EAAY,IAA2B,yBAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAsBrN,EAAwB,gBAAE,WAAW,OAAuBA,EAAwB,gBAAEA,EAAY,IAAkB,gBAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAA4BrN,EAA8B,sBAAE,WAAW,OAA6BA,EAA8B,sBAAEA,EAAY,IAAwB,sBAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAyBrN,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAsBrN,EAAwB,gBAAE,WAAW,OAAuBA,EAAwB,gBAAEA,EAAY,IAAkB,gBAAG0Q,MAAM,KAAKrD,UAAU,EAA0BrN,EAA4B,oBAAE,WAAW,OAA2BA,EAA4B,oBAAEA,EAAY,IAAsB,oBAAG0Q,MAAM,KAAKrD,UAAU,EAA6BrN,EAA+B,uBAAE,WAAW,OAA8BA,EAA+B,uBAAEA,EAAY,IAAyB,uBAAG0Q,MAAM,KAAKrD,UAAU,EAAiCrN,EAAmC,2BAAE,WAAW,OAAkCA,EAAmC,2BAAEA,EAAY,IAA6B,2BAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAwBrN,EAA0B,kBAAE,WAAW,OAAyBA,EAA0B,kBAAEA,EAAY,IAAoB,kBAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAA8BrN,EAAgC,wBAAE,WAAW,OAA+BA,EAAgC,wBAAEA,EAAY,IAA0B,wBAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAyBrN,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAA4BrN,EAA8B,sBAAE,WAAW,OAA6BA,EAA8B,sBAAEA,EAAY,IAAwB,sBAAG0Q,MAAM,KAAKrD,UAAU,EAAE,IAAIxC,GAAc7K,EAAsB,cAAE,WAAW,OAAO6K,GAAc7K,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAwBrN,EAA0B,kBAAE,WAAW,OAAyBA,EAA0B,kBAAEA,EAAY,IAAoB,kBAAG0Q,MAAM,KAAKrD,UAAU,EAAE,IAAI2D,GAAyBhR,EAAiC,yBAAE,WAAW,OAAOgR,GAAyBhR,EAAiC,yBAAEA,EAAY,IAA2B,yBAAG0Q,MAAM,KAAKrD,UAAU,EAAkCrN,EAAoC,4BAAE,WAAW,OAAmCA,EAAoC,4BAAEA,EAAY,IAA8B,4BAAG0Q,MAAM,KAAKrD,UAAU,EAAmDrN,EAAqD,6CAAE,WAAW,OAAoDA,EAAqD,6CAAEA,EAAY,IAA+C,6CAAG0Q,MAAM,KAAKrD,UAAU,EAAyCrN,EAA2C,mCAAE,WAAW,OAA0CA,EAA2C,mCAAEA,EAAY,IAAqC,mCAAG0Q,MAAM,KAAKrD,UAAU,EAAE,IAAII,GAA0CzN,EAAkD,0CAAE,WAAW,OAAOyN,GAA0CzN,EAAkD,0CAAEA,EAAY,IAA4C,0CAAG0Q,MAAM,KAAKrD,UAAU,EAAsCrN,EAAwC,gCAAE,WAAW,OAAuCA,EAAwC,gCAAEA,EAAY,IAAkC,gCAAG0Q,MAAM,KAAKrD,UAAU,EAAE,IAAyyD2H,GAA+1BC,GAAiWC,GAAr+FtI,GAAsC5M,EAA8C,sCAAE,WAAW,OAAO4M,GAAsC5M,EAA8C,sCAAEA,EAAY,IAAwC,sCAAG0Q,MAAM,KAAKrD,UAAU,EAAMhD,GAA8BrK,EAAsC,8BAAE,WAAW,OAAOqK,GAA8BrK,EAAsC,8BAAEA,EAAY,IAAgC,8BAAG0Q,MAAM,KAAKrD,UAAU,EAAMQ,GAAyB7N,EAAiC,yBAAE,WAAW,OAAO6N,GAAyB7N,EAAiC,yBAAEA,EAAY,IAA2B,yBAAG0Q,MAAM,KAAKrD,UAAU,EAAMnB,GAA6BlM,EAAqC,6BAAE,WAAW,OAAOkM,GAA6BlM,EAAqC,6BAAEA,EAAY,IAA+B,6BAAG0Q,MAAM,KAAKrD,UAAU,EAAMH,GAAUlN,EAAkB,UAAE,WAAW,OAAOkN,GAAUlN,EAAkB,UAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAMlB,GAAanM,EAAqB,aAAE,WAAW,OAAOmM,GAAanM,EAAqB,aAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAMG,GAAWxN,EAAmB,WAAE,WAAW,OAAOwN,GAAWxN,EAAmB,WAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAslB,SAAS8H,GAAIj5C,GAA4B,KAAGmrC,EAAgB,GAAnB,CAA6B,GAAG7F,EAAsF,OAA9D3B,EAAoBG,GAAQkH,SAAckO,YAAYpV,IAA3+0C,WAAkB,GAAGA,EAAe,OAA8E,IAA/C,mBAAlBA,EAAe,SAAcA,EAAe,OAAE,CAACA,EAAe,SAASA,EAAe,OAAExiC,QAA6ds2C,EAAzc9T,EAAe,OAAE6L,QAA4b9E,EAAaiN,QAAQF,GAA9C,IAAqBA,EAA9a3M,GAAqBJ,EAAa,CAAgy0CsO,GAAYhO,EAAgB,IAAiOrH,EAAkB,WAAGA,EAAkB,UAAE,cAAc0R,YAAW,WAAWA,YAAW,WAAW1R,EAAkB,UAAE,GAAG,GAAE,GAAGsV,GAAO,GAAE,IAAQA,IAA9e,CAAuI,SAASA,IAAWN,KAAiBA,IAAU,EAAKhV,EAAkB,WAAE,EAAQkF,IAAagC,IAAcrH,EAAoBG,GAAWA,EAA6B,sBAAEA,EAA6B,uBAA150C,WAAmB,IAAGwB,EAAH,CAAiC,GAAGxB,EAAgB,QAAiF,IAAjD,mBAAnBA,EAAgB,UAAcA,EAAgB,QAAE,CAACA,EAAgB,UAASA,EAAgB,QAAExiC,QAA2Ms2C,EAAtL9T,EAAgB,QAAE6L,QAAwK5E,EAAc+M,QAAQF,GAAhD,IAAsBA,EAA1J3M,GAAqBF,EAAzM,CAAuN,CAA0p0CsO,IAAS,CAA4J,CAAC,GAA3nCvV,EAAyB,iBAAE,WAAW,OAAwBA,EAAyB,iBAAEA,EAAY,IAAoB,kBAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAErN,EAAyB,iBAAEkD,EAAiBlD,EAAmB,WAAEb,EAAWa,EAAc,MAA3jxB,SAAeoP,EAAME,EAAWC,EAASC,GAA4B,IAAIgG,GAA1BjG,EAASA,GAAU,IAA4BkG,OAAM5/B,GAAa,WAAPA,GAAwB,YAAPA,IAAuD,MAAT,WAAby5B,GAAqCkG,IAAchG,EAAaL,GAASC,GAAc,WAAW,OAAOC,GAAMD,EAAME,EAAWC,EAASlC,UAAe,CAAC,EAA8wwBrN,EAAmB,WAAEgD,GAAWhD,EAAgB,QAAEoI,GAAsBd,EAAsB,SAASoO,IAAgBV,IAAUG,KAAUH,KAAU1N,EAAsBoO,EAAS,EAAikB1V,EAAgB,QAAiF,IAAjD,mBAAnBA,EAAgB,UAAcA,EAAgB,QAAE,CAACA,EAAgB,UAASA,EAAgB,QAAExiC,OAAO,GAAGwiC,EAAgB,QAAE2L,KAAlB3L,GAAmZ,GAAxXmV,KAA4BpV,IAAiBkV,GAAe,CAAC3U,kBAAkBF,QAAQC,UAAU,qBAAqBtsB,QAAO,SAAS4hC,GAAU,OAAO5V,EAAgBO,kBAAkB1xB,QAAQ+mC,IAAW,CAAC,IAAGpV,mBAAmBH,QAAQC,UAAU,sBAAsBtsB,QAAO,SAAS4hC,GAAU,OAAO5V,EAAgBQ,mBAAmB3xB,QAAQ+mC,IAAW,CAAC,MAAmD,oBAApBC,kBAAiCV,GAAaU,sBAAuB,IAA0C,oBAAhC/W,EAA6F,MAAM,IAAIniC,MAAM,yCAAhEw4C,GAAarW,CAA2F,CAAC,GAAGoW,GAAe,CAAC,IAAIY,GAAWX,GAAuB,SAAEA,GAAuB,SAAE,WAAWW,KAAaZ,GAAe3U,kBAAkB/yB,SAAQ,SAASooC,GAAUvV,QAAQ0V,eAAe,oBAAoBH,EAAS,IAAGV,GAAe1U,mBAAmBhzB,SAAQ,SAASooC,GAAUvV,QAAQ0V,eAAe,qBAAqBH,EAAS,GAAE,CAAC,CAGnypD,OAAO9W,EAA8BkX,KAErC,GAGAnC,EAAAG,QAAiBlV,2EChBcmX,GAAG,siGCCpC,IACMpX,EADFgX,GACEhX,EAAiC,oBAAbE,UAA4BA,SAASC,cAAgBD,SAASC,cAAcC,SAAMhsB,EAChF,oBAAfisB,aAA4BL,EAAaA,GAAcK,YAClE,SACO2W,GAGT,IAA0E/V,EAAoBC,EAAoIC,EAA9NC,EAAiC,oBAFnC4V,EAAoBA,GAAqB,IAEMA,EAAkB,CAAA,EAA8C5V,EAAc,MAAE,IAAIC,SAAQ,SAASC,EAAQC,GAAQN,EAAoBK,EAAQJ,EAAmBK,CAAM,IAA2C,oBAAVC,SAAuBA,QAAQC,YAAWN,EAAgB,CAACO,kBAAkBF,QAAQC,UAAU,qBAAqBE,mBAAmBH,QAAQC,UAAU,wBAAuB,IAA8gBG,EAAMC,EAAUC,EAA1hBC,EAAgBC,OAAOC,OAAO,CAAE,EAACb,GAA2GiB,EAAkC,iBAARC,OAAqBC,EAA4C,mBAAfC,cAA8BC,EAAoC,iBAATjB,SAA4C,iBAAlBA,QAAQkB,UAAkD,iBAAvBlB,QAAQkB,SAASC,KAAmBE,EAAgB,GAAuS,GAAGJ,EAAoB,CAAC,IAAIO,EAAGC,GAAkBC,EAASC,GAA0CN,EAAvBN,EAAuCW,EAASG,QAAQR,GAAiB,IAAyBS,UAAU,IAAI1B,EAAM,CAAC2B,EAASC,KAAUD,EAASE,EAAUF,GAAU,IAAIG,IAAIH,GAAUL,EAASS,UAAUJ,GAAiBP,EAAGY,aAAaL,EAASC,OAAOpvB,EAAU,SAAS0tB,EAAWyB,IAAW,IAAIM,EAAIjC,EAAM2B,GAAS,GAA8C,OAApCM,EAAIlkC,SAAQkkC,EAAI,IAAIpkC,WAAWokC,IAAYA,GAAKhC,EAAU,CAAC0B,EAASO,EAAOC,KAAWR,EAASE,EAAUF,GAAU,IAAIG,IAAIH,GAAUL,EAASS,UAAUJ,GAAUP,EAAGgB,SAAST,GAAS,SAASU,EAAIt2B,GAASs2B,EAAIF,EAAQE,GAAUH,EAAOn2B,EAAKhO,OAAO,GAAE,EAAK6hC,QAAc,KAAE5iC,OAAO,GAAe4iC,QAAc,KAAE,GAAG0C,QAAQ,MAAM,KAAgB1C,QAAc,KAAEpiC,MAAM,GAAGoiC,QAAY,GAAE,qBAAoB,SAAS2C,GAAI,KAAKA,aAAcC,GAAa,MAAMD,CAAG,IAAG3C,QAAY,GAAE,sBAAqB,SAAS6C,GAAQ,MAAMA,CAAM,IAAiJjD,EAAgB,QAAE,WAAW,MAAM,4BAA4B,CAAC,MAASiB,GAAoBE,KAA0BA,EAAuBM,EAAgB+B,KAAKC,SAASC,KAA8B,oBAAV5E,UAAuBA,SAASC,gBAAe0C,EAAgB3C,SAASC,cAAcC,KAAOJ,IAAY6C,EAAgB7C,GAAoD6C,EAAH,IAAnCA,EAAgB7yB,QAAQ,SAA8B6yB,EAAgBkC,OAAO,EAAElC,EAAgBqB,QAAQ,SAAS,IAAIc,YAAY,KAAK,GAAwB,GAAIpD,EAAMqD,IAAM,IAAIC,EAAI,IAAIC,eAAwD,OAAzCD,EAAIE,KAAK,MAAMH,GAAI,GAAOC,EAAIG,KAAK,MAAaH,EAAII,cAAiB/C,IAAuBT,EAAWmD,IAAM,IAAIC,EAAI,IAAIC,eAAuF,OAAxED,EAAIE,KAAK,MAAMH,GAAI,GAAOC,EAAIK,aAAa,cAAcL,EAAIG,KAAK,MAAa,IAAI5lC,WAAWylC,EAAIM,SAAQ,GAAG3D,EAAU,CAACoD,EAAInB,EAAOC,KAAW,IAAImB,EAAI,IAAIC,eAAeD,EAAIE,KAAK,MAAMH,GAAI,GAAMC,EAAIK,aAAa,cAAcL,EAAIpB,OAAO,KAAoB,KAAZoB,EAAI/C,QAAyB,GAAZ+C,EAAI/C,QAAW+C,EAAIM,SAAU1B,EAAOoB,EAAIM,UAAiBzB,GAAS,EAAEmB,EAAInB,QAAQA,EAAQmB,EAAIG,KAAK,KAAK,GAAmD,IAAoVY,EAAiM1F,EAAjhBlhC,EAAI+hC,EAAc,OAAGoD,QAAQoB,IAAIC,KAAKrB,SAAaP,EAAI7C,EAAiB,UAAGoD,QAAQuB,KAAKF,KAAKrB,SAASxC,OAAOC,OAAOb,EAAOW,GAAiBA,EAAgB,KAAQX,EAAkB,WAAaA,EAAkB,UAAKA,EAAoB,aAAcA,EAAoB,YAAKA,EAAa,MAAQA,EAAa,KAAuCA,EAAmB,aAAE6E,EAAW7E,EAAmB,YAAoBA,EAAsB,cAA+B,iBAAb1B,aAAuB0G,EAAM,mCAAkD,IAAo3DzmC,EAAO8gC,EAAM7W,EAA6BkX,EAA15DwF,GAAM,EAAqFC,EAAgC,oBAAbC,YAAyB,IAAIA,YAAY,aAAQpyB,EAAU,SAASqyB,EAAkBC,EAAYn6B,EAAIo6B,GAAsE,IAA7C,IAAIC,GAAbr6B,KAAO,GAAiBo6B,EAAmBE,EAAOt6B,EAAUm6B,EAAYG,MAAWA,GAAQD,MAAUC,EAAO,GAAGA,EAAOt6B,EAAI,IAAIm6B,EAAY/mC,QAAQ4mC,EAAa,OAAOA,EAAYO,OAAOJ,EAAY36B,SAASQ,EAAIs6B,IAAoB,IAAX,IAAIn4B,EAAI,GAASnC,EAAIs6B,GAAO,CAAC,IAAIE,EAAGL,EAAYn6B,KAAO,GAAQ,IAAHw6B,EAAL,CAAoD,IAAIC,EAAsB,GAAnBN,EAAYn6B,KAAU,GAAa,MAAN,IAAHw6B,GAAJ,CAAmE,IAAIE,EAAsB,GAAnBP,EAAYn6B,KAA0G,IAA9Ew6B,EAAL,MAAN,IAAHA,IAAqB,GAAHA,IAAQ,GAAGC,GAAI,EAAEC,GAAe,EAAHF,IAAO,GAAGC,GAAI,GAAGC,GAAI,EAAqB,GAAnBP,EAAYn6B,MAAgB,MAAOmC,GAAKw4B,OAAOC,aAAaJ,OAAQ,CAAC,IAAIK,EAAGL,EAAG,MAAMr4B,GAAKw4B,OAAOC,aAAa,MAAMC,GAAI,GAAG,MAAS,KAAHA,EAAQ,CAAjP,MAAhD14B,GAAKw4B,OAAOC,cAAiB,GAAHJ,IAAQ,EAAEC,EAApF,MAArCt4B,GAAKw4B,OAAOC,aAAaJ,EAA8V,CAAC,OAAOr4B,CAAG,CAA4iC,SAAS8xB,EAA2B6G,GAAK1nC,EAAO0nC,EAAIjG,EAAc,MAAEX,EAAM,IAAI6G,UAAUD,GAAKjG,EAAe,OAAS,IAAImG,WAAWF,GAAKjG,EAAe,OAAS,IAAI1hC,WAAW2nC,GAAKjG,EAAe,OAAExX,EAAO,IAAInqB,WAAW4nC,GAAKjG,EAAgB,QAAU,IAAIoG,YAAYH,GAAKjG,EAAgB,QAAEN,EAAQ,IAAI2G,YAAYJ,GAAKjG,EAAgB,QAAU,IAAIsG,aAAaL,GAAKjG,EAAgB,QAAU,IAAIuG,aAAaN,EAAI,CAAoBjG,EAAuB,eAA0B,IAAyyDoH,EAAplOzF,EAA+yKoF,EAAa,GAAOC,EAAW,GAAOC,EAAc,GAAwvBI,EAAgB,EAAoCC,EAAsB,KAAif,SAAStC,EAAMuC,GAASvH,EAAgB,SAAGA,EAAgB,QAAEuH,GAA+B1E,EAAzB0E,EAAK,WAAWA,EAAK,KAAcrC,GAAM,EAAkBqC,GAAM,2CAA2C,IAAIrX,EAAE,IAAIoO,YAAYkJ,aAAaD,GAA4B,MAAtBzH,EAAmB5P,GAASA,CAAC,CAA2D,SAASuX,EAAUtF,GAAU,OAAOA,EAASuF,WAArF,wCAA8G,CAAC,SAASrF,EAAUF,GAAU,OAAOA,EAASuF,WAAW,UAAU,CAAqI,SAASC,EAAUC,GAAM,IAAI,GAAGA,GAAMR,GAAgBvC,EAAY,OAAO,IAAIxmC,WAAWwmC,GAAY,GAAGnE,EAAY,OAAOA,EAAWkH,GAAM,KAAK,iDAAuE,CAArB,MAAM/E,GAAKmC,EAAMnC,EAAI,CAAC,CAAiyE,SAASG,EAAWjC,GAAQh1B,KAAK+7B,KAAK,aAAa/7B,KAAKg8B,QAAQ,gCAAgChH,EAAO,IAAIh1B,KAAKg1B,OAAOA,CAAM,CAAC,SAASoG,EAAqByE,GAAW,KAAMA,EAAUpuC,OAAO,GAAGouC,EAAUC,OAAVD,CAAkB5L,EAAQ,CAA2N,SAASiO,EAA0B9jC,GAAM,IAAqG,OAAjGg1B,EAAW+O,KAAK/jC,EAAK5L,EAAOuoC,WAAW,QAAQ,IAAI1H,EAA2BD,EAAW5gC,QAAe,CAAY,CAAV,MAAM2xB,GAAI,CAAA,CAArpGuX,EAA5CL,EAAe,4BAAlnOzF,EAAosOyF,EAA1BA,EAAjqOpH,EAAmB,WAAUA,EAAmB,WAAE2B,EAAKF,GAAwBA,EAAgBE,GAAyhW,IAAI+M,EAAiB,CAAC,KAAK,GAAG,IAAI,SAASC,EAAUC,EAAOC,GAAM,IAAItwC,EAAOmwC,EAAiBE,GAAkB,IAAPC,GAAiB,KAAPA,IAAqB,IAATD,EAAW3wC,EAAI4kC,GAAKwC,EAAkB9mC,EAAO,IAAIA,EAAOf,OAAO,GAAOe,EAAOyC,KAAK6tC,EAAM,CAAsO,SAASM,EAASC,GAAkC,OAAlBpP,EAAO,IAAIoP,EAAkB,CAAuE,SAASC,EAAMD,EAAME,EAAWC,EAASrzC,EAAKszC,GAAM,IAAIC,EAAI,CAACC,OAASpiC,IAAM,IAAIm1B,EAAI,EAAE,GAAGn1B,SAAmC,IAANA,EAAQ,CAAC,IAAI4hC,EAAoB,GAAf5hC,EAAI9P,QAAQ,IAApsO,SAAsB8P,EAAIqiC,EAAOC,IAA1yB,SAA2BtiC,EAAIuiC,EAAKC,EAAOF,GAA6B,KAAKA,EAAgB,GAAG,OAAO,EAA3CE,KAAU,EAA2F,IAAxD,IAAwBtK,EAAOsK,EAAOF,EAAgB,EAAU7uC,EAAE,EAAEA,EAAEuM,EAAI9P,SAASuD,EAAE,CAAC,IAAIgvC,EAAEziC,EAAI0iC,WAAWjvC,GAAoF,GAA9EgvC,GAAG,OAAOA,GAAG,QAAkCA,EAAE,QAAU,KAAFA,IAAS,IAAO,KAA9CziC,EAAI0iC,aAAajvC,IAAqCgvC,GAAG,IAAI,CAAC,GAAGD,GAAQtK,EAAO,MAAMqK,EAAKC,MAAW,GAAGC,CAAC,MAAM,GAAGA,GAAG,KAAK,CAAC,GAAGD,EAAO,GAAGtK,EAAO,MAAMqK,EAAKC,MAAW,GAAG,IAAIC,GAAG,EAAEF,EAAKC,MAAW,GAAG,IAAM,GAAFC,CAAI,MAAM,GAAGA,GAAG,MAAM,CAAC,GAAGD,EAAO,GAAGtK,EAAO,MAAMqK,EAAKC,MAAW,GAAG,IAAIC,GAAG,GAAGF,EAAKC,MAAW,GAAG,IAAIC,GAAG,EAAE,GAAGF,EAAKC,MAAW,GAAG,IAAM,GAAFC,CAAI,KAAK,CAAC,GAAGD,EAAO,GAAGtK,EAAO,MAAMqK,EAAKC,MAAW,GAAG,IAAIC,GAAG,GAAGF,EAAKC,MAAW,GAAG,IAAIC,GAAG,GAAG,GAAGF,EAAKC,MAAW,GAAG,IAAIC,GAAG,EAAE,GAAGF,EAAKC,MAAW,GAAG,IAAM,GAAFC,CAAI,CAAC,CAACF,EAAKC,IAAS,GAAG,CAAwB,CAA0DG,CAAkB3iC,EAAIkb,EAAOmnB,EAAOC,EAAgB,CAAgnOM,CAAa5iC,EAAjCm1B,EAAI+K,EAAW0B,GAA0BA,EAAI,CAAC,OAAOzM,GAAK0N,MAAQC,IAAM,IAAI3N,EAAI+K,EAAW4C,EAAI5yC,QAAoC,OAAlW,SAA4B2yC,EAAM5xC,GAAQ8gC,EAAM9+B,IAAI4vC,EAAM5xC,IAAS,EAAE,CAAiQ8xC,CAAmBD,EAAI3N,GAAYA,IAAM,SAAS6N,EAAmB7N,GAAK,MAAgB,WAAb6M,GAA9tQ5B,EAAywQjL,GAArvQiL,KAAO,GAAarI,EAAkB7c,EAAOklB,EAAInI,GAAgB,IAAysQ,YAAb+J,EAA8BiB,QAAQ9N,GAAYA,EAAz1Q,IAAsBiL,EAAInI,CAAk0Q,CAAC,IAAIqI,EAAKuB,EAASC,GAAWoB,EAAM,GAAOvD,EAAM,EAAE,GAAG/wC,EAAM,IAAI,IAAI6E,EAAE,EAAEA,EAAE7E,EAAKsB,OAAOuD,IAAI,CAAC,IAAI0vC,EAAUhB,EAAIF,EAASxuC,IAAO0vC,GAAsB,IAARxD,IAAUA,EAAMC,KAAYsD,EAAMzvC,GAAG0vC,EAAUv0C,EAAK6E,KAASyvC,EAAMzvC,GAAG7E,EAAK6E,EAAG,CAAE,IAAI0hC,EAAImL,EAAK8C,MAAM,KAAKF,GAA4G,OAAhB/N,EAArF,SAAgBA,GAAsC,OAAtB,IAARwK,GAAUd,EAAac,GAAcqD,EAAmB7N,EAAI,CAAKkO,CAAOlO,EAAe,CAAuT,IAAIoO,EAAc,CAAC7L,MAAn4F,WAAkBA,EAAM,GAAG,EAAu3FiN,wBAA90F,WAAoC,OAA/C,UAAkE,EAA00FE,sBAAz0F,SAAgCC,EAAKpT,EAAIjc,GAAKyF,EAAO6pB,WAAWD,IAAO,EAAEpT,IAAM,EAAEA,EAAIjc,IAAM,EAAE,EAA2xF4vB,uBAAxnF,SAAiCC,GAAe,IAA+Ih0C,EAAEk0C,EAA7ID,EAAQrqB,EAAOhrB,OAA2Cu1C,EAAjb,WAA0c,IAA7DH,KAA8B,GAAgDG,EAAa,OAAO,EAAiE,IAAI,IAAIC,EAAQ,EAAEA,GAAS,EAAEA,GAAS,EAAE,CAAC,IAAIC,EAAkBJ,GAAS,EAAE,GAAGG,GAA6N,GAApNC,EAAkBnpC,KAAKsC,IAAI6mC,EAAkBL,EAAc,WAAsH3E,EAA/FnkC,KAAKsC,IAAI2mC,GAA/Nn0C,EAAmPkL,KAAKC,IAAI6oC,EAAcK,MAAxQH,EAA2R,OAApQl0C,EAAEk0C,GAAUA,IAAmU,OAAO,CAAK,CAAC,OAAO,CAAK,EAAymEM,SAAt7D,SAAmBhF,GAAI,OAAO,EAAE,EAA26DiF,QAA16D,SAAkBjF,EAAGE,EAAWC,EAAYC,EAAOC,GAAW,OAAO,EAAE,EAAs3D6E,SAA7pD,SAAmBlF,EAAGW,EAAIC,EAAOC,GAAgB,IAAV,IAAIlsB,EAAI,EAAUhiB,EAAE,EAAEA,EAAEiuC,EAAOjuC,IAAI,CAAC,IAAI2sC,EAAIhO,EAAQqP,IAAM,GAAOG,EAAIxP,EAAQqP,EAAI,IAAI,GAAGA,GAAK,EAAE,IAAI,IAAI7tC,EAAE,EAAEA,EAAEguC,EAAIhuC,IAAKytC,EAAUP,EAAG5lB,EAAOklB,EAAIxsC,IAAI,IAAI6hB,GAAKmsB,CAAG,CAAuB,OAAtBxP,EAAQuP,IAAO,GAAGlsB,EAAW,CAAC,IAA7hH,WAAsB,IAAIywB,EAAK,CAACrV,IAAM0S,EAAc4C,uBAAyB5C,GAAe,SAAS6C,EAAgBC,EAASC,GAAQ,IAA9pEE,EAAkqEC,EAAQJ,EAASI,QAAQ/T,EAAY,IAAE+T,EAA2C3U,GAAnCD,EAAWa,EAAY,IAAU,QAAwCzhC,QAAkByhC,EAAY,IAA6B,0BAAr1E8T,EAAi2E9T,EAAY,IAAqB,kBAA93EgH,EAAWgN,QAAQF,GAAmR,SAA6B32C,GAA6G,GAAzGkqC,IAAqBrH,EAA+B,wBAAGA,EAA+B,uBAAEqH,GAAqC,GAAjBA,GAAqHC,EAAsB,CAAC,IAAI6M,EAAS7M,EAAsBA,EAAsB,KAAK6M,GAAU,CAAE,CAAwvDC,EAAuC,CAAsC,SAASC,EAA2B5lC,GAAQilC,EAAgBjlC,EAAiB,SAAE,CAAC,SAAS6lC,EAAuBC,GAAU,OAAvqC,WAA4B,IAAI1P,IAAa5D,GAAoBE,GAAuB,CAAC,GAAiB,mBAAPqT,QAAoBnS,EAAU+E,GAAiB,OAAOoN,MAAMpN,EAAe,CAACqN,YAAY,gBAAgBC,MAAK,SAAStQ,GAAU,IAAIA,EAAa,GAAG,KAAK,uCAAuCgD,EAAe,IAAI,OAAOhD,EAAsB,aAAG,IAAGuQ,OAAM,WAAW,OAAOhN,EAAUP,EAAe,IAAQ,GAAG3G,EAAW,OAAO,IAAIR,SAAQ,SAASC,EAAQC,GAAQM,EAAU2G,GAAe,SAAShD,GAAUlE,EAAQ,IAAI7hC,WAAW+lC,GAAU,GAAEjE,EAAO,GAAI,CAAC,OAAOF,QAAQC,UAAUwU,MAAK,WAAW,OAAO/M,EAAUP,EAAe,GAAE,CAA4jBwN,GAAmBF,MAAK,SAAStS,GAAQ,OAAO9D,YAAYuW,YAAYzS,EAAOoR,EAAK,IAAGkB,MAAK,SAASf,GAAU,OAAOA,CAAQ,IAAGe,KAAKH,GAAS,SAAStR,GAAQJ,EAAI,0CAA0CI,GAAQ+B,EAAM/B,EAAO,GAAE,CAAknB,GAA1uGoE,IAAqBrH,EAA+B,wBAAGA,EAA+B,uBAAEqH,GAAqpGrH,EAAwB,gBAAG,IAAgE,OAAhDA,EAAwB,gBAAEwT,EAAKE,EAA2H,CAA3F,MAAMxjB,GAAG2S,EAAI,sDAAsD3S,GAAG4P,EAAmB5P,EAAE,EAAzxB2U,GAAqD,mBAAlCvG,YAAYwW,sBAAmCrN,EAAUL,IAAkB/E,EAAU+E,IAAkB/F,GAAmC,mBAAPmT,MAAuYF,EAAuBD,GAApYG,MAAMpN,EAAe,CAACqN,YAAY,gBAAgBC,MAAK,SAAStQ,GAAqE,OAAhD9F,YAAYwW,qBAAqB1Q,EAASoP,GAAoBkB,KAAKL,GAA2B,SAASpR,GAAuG,OAA/FJ,EAAI,kCAAkCI,GAAQJ,EAAI,6CAAoDyR,EAAuBD,EAA2B,GAAE,KAAgSM,MAAM7U,EAA4B,CAAm2GiV,GAAoC/U,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAA+BrN,EAAiC,yBAAE,WAAW,OAAgCA,EAAiC,yBAAEA,EAAY,IAA2B,yBAAG0Q,MAAM,KAAKrD,UAAU,EAAyBrN,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAuBrN,EAAyB,iBAAE,WAAW,OAAwBA,EAAyB,iBAAEA,EAAY,IAAmB,iBAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAA8BrN,EAAgC,wBAAE,WAAW,OAA+BA,EAAgC,wBAAEA,EAAY,IAA0B,wBAAG0Q,MAAM,KAAKrD,UAAU,EAA6BrN,EAA+B,uBAAE,WAAW,OAA8BA,EAA+B,uBAAEA,EAAY,IAAyB,uBAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAA6BrN,EAA+B,uBAAE,WAAW,OAA8BA,EAA+B,uBAAEA,EAAY,IAAyB,uBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAgCrN,EAAkC,0BAAE,WAAW,OAAiCA,EAAkC,0BAAEA,EAAY,IAA4B,0BAAG0Q,MAAM,KAAKrD,UAAU,EAA+BrN,EAAiC,yBAAE,WAAW,OAAgCA,EAAiC,yBAAEA,EAAY,IAA2B,yBAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAsBrN,EAAwB,gBAAE,WAAW,OAAuBA,EAAwB,gBAAEA,EAAY,IAAkB,gBAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAA4BrN,EAA8B,sBAAE,WAAW,OAA6BA,EAA8B,sBAAEA,EAAY,IAAwB,sBAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAyBrN,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAe,aAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAkBrN,EAAoB,YAAE,WAAW,OAAmBA,EAAoB,YAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAsBrN,EAAwB,gBAAE,WAAW,OAAuBA,EAAwB,gBAAEA,EAAY,IAAkB,gBAAG0Q,MAAM,KAAKrD,UAAU,EAA0BrN,EAA4B,oBAAE,WAAW,OAA2BA,EAA4B,oBAAEA,EAAY,IAAsB,oBAAG0Q,MAAM,KAAKrD,UAAU,EAA6BrN,EAA+B,uBAAE,WAAW,OAA8BA,EAA+B,uBAAEA,EAAY,IAAyB,uBAAG0Q,MAAM,KAAKrD,UAAU,EAAiCrN,EAAmC,2BAAE,WAAW,OAAkCA,EAAmC,2BAAEA,EAAY,IAA6B,2BAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAwBrN,EAA0B,kBAAE,WAAW,OAAyBA,EAA0B,kBAAEA,EAAY,IAAoB,kBAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAarN,EAAe,OAAE,WAAW,OAAcA,EAAe,OAAEA,EAAY,IAAS,OAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAerN,EAAiB,SAAE,WAAW,OAAgBA,EAAiB,SAAEA,EAAY,IAAW,SAAG0Q,MAAM,KAAKrD,UAAU,EAAgBrN,EAAkB,UAAE,WAAW,OAAiBA,EAAkB,UAAEA,EAAY,IAAY,UAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAA8BrN,EAAgC,wBAAE,WAAW,OAA+BA,EAAgC,wBAAEA,EAAY,IAA0B,wBAAG0Q,MAAM,KAAKrD,UAAU,EAAqBrN,EAAuB,eAAE,WAAW,OAAsBA,EAAuB,eAAEA,EAAY,IAAiB,eAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAyBrN,EAA2B,mBAAE,WAAW,OAA0BA,EAA2B,mBAAEA,EAAY,IAAqB,mBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAWrN,EAAa,KAAE,WAAW,OAAYA,EAAa,KAAEA,EAAY,IAAO,KAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAA2BrN,EAA6B,qBAAE,WAAW,OAA4BA,EAA6B,qBAAEA,EAAY,IAAuB,qBAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAiBrN,EAAmB,WAAE,WAAW,OAAkBA,EAAmB,WAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAoBrN,EAAsB,cAAE,WAAW,OAAqBA,EAAsB,cAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAcrN,EAAgB,QAAE,WAAW,OAAeA,EAAgB,QAAEA,EAAY,IAAU,QAAG0Q,MAAM,KAAKrD,UAAU,EAAYrN,EAAc,MAAE,WAAW,OAAaA,EAAc,MAAEA,EAAY,IAAQ,MAAG0Q,MAAM,KAAKrD,UAAU,EAAwBrN,EAA0B,kBAAE,WAAW,OAAyBA,EAA0B,kBAAEA,EAAY,IAAoB,kBAAG0Q,MAAM,KAAKrD,UAAU,EAAE,IAAyvB2H,EAA+vBC,EAAiWC,EAAr1DhI,EAAUlN,EAAkB,UAAE,WAAW,OAAOkN,EAAUlN,EAAkB,UAAEA,EAAY,IAAa,WAAG0Q,MAAM,KAAKrD,UAAU,EAAMlB,EAAanM,EAAqB,aAAE,WAAW,OAAOmM,EAAanM,EAAqB,aAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAMG,EAAWxN,EAAmB,WAAE,WAAW,OAAOwN,EAAWxN,EAAmB,WAAEA,EAAY,IAAc,YAAG0Q,MAAM,KAAKrD,UAAU,EAAgd,SAAS8H,EAAIj5C,GAA+F,SAASo5C,IAAWN,IAAiBA,GAAU,EAAKhV,EAAkB,WAAE,EAAQkF,IAA523BiC,EAAqBH,GAAk33BnH,EAAoBG,GAAWA,EAA6B,sBAAEA,EAA6B,uBAAj83B,WAAmB,GAAGA,EAAgB,QAAiF,IAAjD,mBAAnBA,EAAgB,UAAcA,EAAgB,QAAE,CAACA,EAAgB,UAASA,EAAgB,QAAExiC,QAA2Ms2C,EAAtL9T,EAAgB,QAAE6L,QAAwK5E,EAAc+M,QAAQF,GAAhD,IAAsBA,EAA1J3M,EAAqBF,EAAc,CAAku3BsO,IAAS,CAAnRlO,EAAgB,IAAt/3B,WAAkB,GAAGrH,EAAe,OAA8E,IAA/C,mBAAlBA,EAAe,SAAcA,EAAe,OAAE,CAACA,EAAe,SAASA,EAAe,OAAExiC,QAA2Zs2C,EAAvY9T,EAAe,OAAE6L,QAA0X9E,EAAaiN,QAAQF,GAA9C,IAAqBA,EAA5W3M,EAAqBJ,EAAa,CAAsy3BsO,GAAYhO,EAAgB,IAAiOrH,EAAkB,WAAGA,EAAkB,UAAE,cAAc0R,YAAW,WAAWA,YAAW,WAAW1R,EAAkB,UAAE,GAAG,GAAE,GAAGsV,GAAO,GAAE,IAAQA,KAAQ,CAAC,GAAr5BtV,EAAyB,iBAAE,WAAW,OAAwBA,EAAyB,iBAAEA,EAAY,IAAoB,kBAAG0Q,MAAM,KAAKrD,UAAU,EAAmBrN,EAAqB,aAAE,WAAW,OAAoBA,EAAqB,aAAEA,EAAY,IAAgB,cAAG0Q,MAAM,KAAKrD,UAAU,EAAErN,EAAc,MAAvwpB,SAAeoP,EAAME,EAAWC,EAASC,GAA4B,IAAIgG,GAA1BjG,EAASA,GAAU,IAA4BkG,OAAM5/B,GAAa,WAAPA,GAAwB,YAAPA,IAAuD,MAAT,WAAby5B,GAAqCkG,IAAchG,EAAaL,EAASC,GAAc,WAAW,OAAOC,EAAMD,EAAME,EAAWC,EAASlC,UAAe,CAAC,EAAw+oB/F,EAAsB,SAASoO,IAAgBV,GAAUG,IAAUH,IAAU1N,EAAsBoO,EAAS,EAAie1V,EAAgB,QAAiF,IAAjD,mBAAnBA,EAAgB,UAAcA,EAAgB,QAAE,CAACA,EAAgB,UAASA,EAAgB,QAAExiC,OAAO,GAAGwiC,EAAgB,QAAE2L,KAAlB3L,GAAmZ,GAAxXmV,IAA4BpV,IAAiBkV,EAAe,CAAC3U,kBAAkBF,QAAQC,UAAU,qBAAqBtsB,QAAO,SAAS4hC,GAAU,OAAO5V,EAAgBO,kBAAkB1xB,QAAQ+mC,IAAW,CAAC,IAAGpV,mBAAmBH,QAAQC,UAAU,sBAAsBtsB,QAAO,SAAS4hC,GAAU,OAAO5V,EAAgBQ,mBAAmB3xB,QAAQ+mC,IAAW,CAAC,MAAmD,oBAApBC,EAAiCV,EAAaU,MAAuB,IAA0C,oBAAhC/W,8BAA6F,MAAM,IAAIniC,MAAM,yCAAhEw4C,EAAarW,6BAA2F,CAAC,GAAGoW,EAAe,CAAC,IAAIY,GAAWX,EAAuB,SAAEA,EAAuB,SAAE,WAAWW,KAAaZ,EAAe3U,kBAAkB/yB,SAAQ,SAASooC,GAAUvV,QAAQ0V,eAAe,oBAAoBH,EAAS,IAAGV,EAAe1U,mBAAmBhzB,SAAQ,SAASooC,GAAUvV,QAAQ0V,eAAe,qBAAqBH,EAAS,GAAE,CAAC,CAG7unC,OAAOC,EAAkBG,KAEzB,GAGAnC,EAAAG,QAAiB6B,mCCenB,MAAMK,GAA2BC,IACAC,GAE3BC,GAAeC,yCAef,MAAOC,WAAoBC,GAK/B/qC,YAAmBzP,GACjBy6C,QADiBzqC,KAAIhQ,KAAJA,EAHXgQ,KAAgB0qC,iBAAG,EAKzB1qC,KAAKhQ,KAAK26C,KAAKC,qBAAqBC,IACpCC,GAAqB9qC,KAAKhQ,KAAK26C,KAAKI,kBACpC/qC,KAAK/O,UAAY,IAAI+5C,GAAYhrC,KAAMirC,KACxC,CAEQC,MACL5rC,EAAyC9N,EACzCd,GACF,MAAMS,EAAS,CAACC,GAAI4O,KAAK0qC,oBAEzB,OADA1qC,KAAKmrC,KAAKh6C,EAAQmO,EAAQ9N,EAAOd,EAAO,GACjCS,CACR,CAEQi6C,aACP,OAAOprC,KAAK/O,UAAUm6C,YACvB,CAEQ9Y,WAAW1vB,GAClB,MAAMkU,EAAQ/jB,EAAKivC,MACnBp/B,IAEA,MAAO,CAACyoC,SADSt4C,EAAKivC,MAAQlrB,EAE/B,CAEQq0B,KACLh6C,EAAgBmO,EAAyC9N,EACzDd,EAAiB46C,GACnB,MAAMl6C,EAAK4O,KAAK0qC,mBAChB,GAAc,WAAVh6C,EAAoB,CACtB,MAAM2S,EAAc/D,EAIpB,YAHAU,KAAK/O,UAAUuD,IACXrD,EACA,CAACC,KAAIiS,cAAa7R,QAAOd,QAAO66C,aAAc,KAAMD,YAEzD,CAED,MAAMltC,EAAOrL,EAAKC,cAAcxB,GAC1Bg6C,EAAWptC,EAAOrL,EAAK04C,gBAAgB/6C,GAKvC66C,EAAevrC,KAAKhQ,KAAK07C,QAAQF,KAAc,EAErDxrC,KAAK/O,UAAUuD,IAAIrD,EAAQ,CAACC,KAAIm6C,eAAc/5C,QAAOd,QAAO46C,aAE5DtrC,KAAKhQ,KAAK26C,KAAKgB,eAAev6C,EAAIgN,EAAMmtC,GAE1B,MAAVjsC,GACFU,KAAKhQ,KAAKysB,OAAOjoB,IACb,IAAIlC,WACCgN,EAAmC9M,OACnC8M,EAAmCssC,WAAYJ,GACpDD,EAEP,CAEQjZ,WAAWnhC,GAClB,OAAO6O,KAAK3L,SAASlD,EACtB,CAEQkD,SAASlD,EAAgB2lB,EAAgB4U,GAEhD,MAAM6f,aAACA,EAAY76C,MAAEA,EAAKc,MAAEA,EAAK6R,YAAEA,GAC/BrD,KAAK/O,UAAUC,IAAIC,GACvB,GAAc,WAAVT,EAEF,OAAc,MAATomB,GAA2B,IAAVA,KACV,MAAP4U,GAAeA,GAAOroB,EAAY5R,QAGhC4R,EAAYpR,MAAM6kB,EAAO4U,GAFvBroB,EAIXyT,EAAQA,GAAS,EACjB4U,EAAMA,GAAO34B,EAAKC,cAAcxB,GAChC,MAAMi6C,EAAkB14C,EAAK04C,gBAAgB/6C,GAI7C,OA2QJ,SACI8B,EAAqB9B,GACvB,OAAQA,GACN,IAAK,UACH,OAAO,IAAI6pC,aAAa/nC,GAC1B,IAAK,QACH,OAAO,IAAID,WAAWC,GACxB,IAAK,OACH,OAAO,IAAIF,WAAWE,GACxB,QACE,MAAM,IAAI7B,MAAM,iBAAiBD,KAEvC,CAvRWm7C,CAHO7rC,KAAKhQ,KAAKysB,OAAOxqB,MAC3Bs5C,EAAez0B,EAAQ20B,EACvBF,EAAe7f,EAAM+f,GACSj5C,OAAQ9B,EAC3C,CAQQ6G,YAAYpG,EAAgB26C,GAAQ,GAC3C,GAAI9rC,KAAK/O,UAAU86C,IAAI56C,GAAS,CAC9B,MAAMqP,EAAOR,KAAK/O,UAAUC,IAAIC,GAEhC,GADAqP,EAAK8qC,YACAQ,GAAStrC,EAAK8qC,SAAW,EAC5B,OAAO,EAGTtrC,KAAKhQ,KAAK8sB,MAAMtc,EAAK+qC,cACrBvrC,KAAKhQ,KAAK26C,KAAKpzC,YAAYiJ,EAAKpP,IAChC4O,KAAK/O,UAAU+6C,OAAO76C,EACvB,CACD,OAAO,CACR,CAGQm6C,SAASn6C,GAChB,GAAI6O,KAAK/O,UAAU86C,IAAI56C,GAAS,CAE9B,OADmB6O,KAAK/O,UAAUC,IAAIC,GACpBm6C,QACnB,CACD,OAAO,CACR,CAEQ9uC,OAAOrL,GACd,MAAMqP,EAAOR,KAAK/O,UAAUC,IAAIC,GACpB,MAARqP,GACFA,EAAK8qC,UAER,CAEQW,iBACP,OAAO,EACR,CAIDC,gBAAgB/6C,GACd,OAAO6O,KAAK/O,UAAUC,IAAIC,GAAQo6C,YACnC,CAEQY,UACPnsC,KAAKhQ,KAAK26C,KAAKwB,UACX,YAAansC,KAAKhQ,MACpBgQ,KAAKhQ,KAAKqsC,QAAQmB,sBAEpBx9B,KAAKhQ,KAAO,IACb,CAEQw3C,SACP,MAAO,CAAC4E,YAAY,EACrB,CAQDj6C,WACIX,EAAiBd,EAAiB66C,EAClCjsC,GACF,IAAInO,EACJ,GAAoB,MAAhBo6C,EACFp6C,EAAS6O,KAAKkrC,MAAM5rC,QAAAA,EAAU,KAAM9N,EAAOd,OACtC,CACL,MAAMU,EAAK4O,KAAK0qC,mBAChBv5C,EAAS,CAACC,MACV4O,KAAK/O,UAAUuD,IAAIrD,EAAQ,CAACC,KAAIm6C,eAAc/5C,QAAOd,QAAO46C,SAAU,IACtE,MAAMltC,EAAOrL,EAAKC,cAAcxB,GAChCwO,KAAKhQ,KAAK26C,KAAKgB,eAAev6C,EAAIgN,EAAMmtC,EACzC,CACD,MAAO,CAACp6C,SAAQK,QAAOd,QACxB,CAED6D,oBAAmB/C,MAACA,EAAKd,MAAEA,EAAKS,OAAEA,IAEhC,MAAMqB,EAASwN,KAAKhQ,KAAKysB,OAAOjqB,QAC1B+4C,aAACA,GAAgBvrC,KAAK/O,UAAUC,IAAIC,GACpCiN,EAAOrL,EAAKC,cAAcxB,GAChC,OAAQd,GACN,IAAK,UACH,OAAO,IAAI6pC,aAAa/nC,EAAQ+4C,EAAcntC,GAChD,IAAK,QACH,OAAO,IAAI7L,WAAWC,EAAQ+4C,EAAcntC,GAC9C,IAAK,OACH,OAAO,IAAI9L,WAAWE,EAAQ+4C,EAAcntC,GAC9C,QACE,MAAM,IAAIzN,MAAM,iBAAiBD,KAEtC,EA4BH,SAAS27C,GACLC,EAAwBC,EACxBC,GACF,GAAgB,MAAZC,GAGF,OAAOA,GAGT,IAAI7W,EAAuB,yBAO3B,OANI0W,GAAiBC,EACnB3W,EAAO,uCACE0W,IACT1W,EAAO,+BAGU,MAAf8W,IACuB,MAArBA,GAAY9W,GACP8W,GAAY9W,GAIhB4W,EAAmB5W,CAC5B,CASOtD,eAAewL,KACpB,MAAOwO,EAAeC,SAA0BrY,QAAQyY,IAAI,CAC1Dva,KAAMwa,SAAS,yBACfxa,KAAMwa,SAAS,kCAGjB,OAAO,IAAI1Y,SAAQ,CAACC,EAASC,KAC3B,MAAMyY,EAAmC,CAAA,EAhE7C,IAAmCjX,EAuE/BiX,EAAclX,WAAa,CAACC,EAAMkX,KAChC,GAAIlX,EAAKmX,SAAS,cAAe,CAI/B,MAAM1U,EAAY4R,GAA8BlT,QAAQ,MAAO,OACzDiW,EAAO,IAAIC,KAAK,CAAC5U,GAAW,CAACvuB,KAAM,2BACzC,OAAOysB,IAAI2W,gBAAgBF,EAC5B,CAED,OAAIpX,EAAKmX,SAAS,SACTV,GACHC,EAA0BC,EACR,MAAlBY,GAAyBA,GAAiBL,GAEzCA,EAASlX,CAAI,EAMlBwX,KACFP,EAAcQ,iBA7FezX,EA8FCyW,GACtBC,EAA0BC,EACR,MAAlBY,GAAyBA,GAAiB,IA5F/C,CAACG,EAAclF,KACpBr1C,EAAK01C,MAAM7S,EAAM,CAAC8S,YAAa,gBAAgBC,MAAMtQ,IAC9CA,EAAa,IAChBiV,EAAQlb,IAAI9hC,EAAE,uCAAuCslC,MAEvDyC,EAASkV,cAAc5E,MAAKtS,IAC1B9D,YAAYuW,YAAYzS,EAAQiX,GAAS3E,MAAKjoC,IAC5C0nC,EAAS1nC,EAAOknC,SAAUlnC,EAAOmnC,OAAO,GACxC,GACF,IAEG,MAoFP,IAkBI73C,EAlBAw9C,GAAc,EAClBX,EAAcY,QAAU,KACtB,GAAID,EAEF,OAEF,GAAIE,GAGF,OAEFA,IAAc,EAIdtZ,EAAO,CAAC4H,QAFJ,mMAEwB,EAK1BuQ,GAAoBD,GAA6B,MAAZG,IACvCI,EAAcc,oBAAsB,IAAIV,KACpC,CAAC,uCACA/C,GAAwBhZ,YACzB,CAACpnB,KAAM,oBACX9Z,EAAOk6C,GAAwB2C,IAG/B78C,EAAOq6C,GAAYwC,GASrB78C,EAAK24C,MAAMd,IACL2F,GAAc,EACdE,IAAc,EAId7F,EAAO8C,KAAO,CACZ7M,KAAM+J,EAAO53C,MAAM,OAAQ,KAAM,IACjC26C,qBACI/C,EAAO53C,MAAM,0BAA2B,KAAM,CAAC,WACnD86C,gBAAiBlD,EAAO53C,MAAM,oBAAqB,SAAU,IAC7D07C,eAAgB9D,EAAO53C,MACnB,kBAAmB,KACnB,CACE,SACA,SACA,WAENsH,YACIswC,EAAO53C,MAAM,eAfY,KAeoB,CAAC,WAClDk8C,QAAStE,EAAO53C,MAAM,UAhBO,KAgBoB,KAGnDkkC,EAAQ,CAACnkC,KAAM63C,GAAQ,IAExBe,MAAMxU,EAAO,GAEtB,CAgBA,MAAMwZ,GAAkB,CACtB,yBAA0B,8BAC1B,wCAIF,IAAInB,GAAmB,KACnBU,GAAyB,KACzBT,GAAkD,CAAA,EAClDgB,IAAc,EACdN,IAAc,WAcFS,GAAYjY,EAAckY,GAAmB,GAI3D,GAHAC,GACI,qGAEAL,GACF,MAAM,IAAI/8C,MACN,kIAGN87C,GAAW7W,EACXwX,GAAcU,CAChB,UA2BgBE,GACZC,EACAH,GAAmB,GACrB,GAAIJ,GACF,MAAM,IAAI/8C,MACN,mIAKN,GAA+B,iBAApBs9C,EACTd,GAAiBc,MACZ,CACLvB,GAAcuB,EACd,MAAMC,EACFN,GAAgB5lC,QAAO+zB,GAA6B,MAArB2Q,GAAY3Q,KAC/C,GAAImS,EAAaz8C,OAAS,EACxB,MAAM,IAAId,MAEN,2DAAGu9C,EAAa7c,KAAK,oKAI5B,CAED+b,GAAcU,CAChB,CAWA,IAAIjD,IAAgB,EAChBC,IAAsB,EAQpB,SAAUqD,GAAgBC,GAC9BvD,GAAeuD,CACjB,UAOgBrD,KACd,IAA4B,IAAxBD,GACF,MAAM,IAAIn6C,MAAM,iCAElB,OAAOm6C,EACT,CCvhBM,MAAAuD,GAAU,SCwBhBC,GAAgB,QAAQhc,UACtB,MAAMtiC,KAACA,SAAc8tC,KACrB,OAAO,IAAIyM,GAAYv6C,EAAK,GAHR"}